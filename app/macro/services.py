# app/macro/services.py
import pandas as pd
from pathlib import Path
import logging
from datetime import datetime, timedelta
import os
import numpy as np
from flask import current_app
from app.utils import (
    BaseService, 
    STATUS_ATIVO, 
    STATUS_CRITICO, 
    STATUS_CONCLUIDO, 
    STATUS_ATENDIMENTO,
    COLUNAS_OBRIGATORIAS,
    COLUNAS_NUMERICAS,
    COLUNAS_TEXTO
)
import unicodedata
from .. import db
import time
from typing import Dict, Any, Optional

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Inst√¢ncia global do leitor de tipos de servi√ßo
type_service_reader = None

# Constantes de status atualizadas
STATUS_NAO_ATIVOS = ['FECHADO', 'ENCERRADO', 'RESOLVIDO', 'CANCELADO']
STATUS_EM_ANDAMENTO = ['NOVO', 'AGUARDANDO', 'BLOQUEADO', 'EM ATENDIMENTO']
STATUS_ATRASADO = ['ATRASADO']
STATUS_ATIVO = ['ATIVO']

# üöÄ CACHE AGRESSIVO PARA CONTAINERS: TTLs aumentados drasticamente
_MACRO_CACHE = {
    'dados': None,
    'timestamp': None,
    'ttl_seconds': 300,  # üöÄ CACHE AGRESSIVO: 5 minutos (era 2min)
    'project_details_cache': {},
    'project_cache_ttl': 600,  # üöÄ CACHE AGRESSIVO: 10 minutos (era 5min)
    'api_cache': {},  # ‚ö° NOVO: Cache para resultados de APIs
    'api_cache_ttl': 180,  # üöÄ Cache de APIs: 3 minutos
    'processing_lock': False  # üîí NOVO: Evita carregamento simult√¢neo
}

def _is_cache_valid():
    """Verifica se o cache de dados est√° v√°lido."""
    if _MACRO_CACHE['dados'] is None or _MACRO_CACHE['timestamp'] is None:
        return False
    
    elapsed = time.time() - _MACRO_CACHE['timestamp']
    return elapsed < _MACRO_CACHE['ttl_seconds']

def _get_cached_dados():
    """Retorna dados do cache se v√°lido, sen√£o None."""
    if _is_cache_valid():
        return _MACRO_CACHE['dados']
    return None

def _set_cached_dados(dados):
    """Define dados no cache com timestamp atual."""
    _MACRO_CACHE['dados'] = dados.copy() if dados is not None and not dados.empty else pd.DataFrame()
    _MACRO_CACHE['timestamp'] = time.time()

def _get_cached_project_details(project_id):
    """Retorna detalhes do projeto do cache se v√°lido."""
    cache_key = str(project_id)
    cache_data = _MACRO_CACHE['project_details_cache'].get(cache_key)
    
    if cache_data is None:
        return None
    
    # Verifica se o cache do projeto ainda √© v√°lido
    elapsed = time.time() - cache_data['timestamp']
    if elapsed < _MACRO_CACHE['project_cache_ttl']:
        return cache_data['details']
    else:
        # Remove cache expirado
        del _MACRO_CACHE['project_details_cache'][cache_key]
        return None

def _set_cached_project_details(project_id, details):
    """Cacheia detalhes espec√≠ficos de um projeto."""
    cache_key = str(project_id)
    _MACRO_CACHE['project_details_cache'][cache_key] = {
        'details': details,
        'timestamp': time.time()
    }

# ‚ö° NOVO: Cache para APIs espec√≠ficas
def _get_cached_api_result(api_key):
    """Retorna resultado da API do cache se v√°lido."""
    cache_data = _MACRO_CACHE['api_cache'].get(api_key)
    
    if cache_data is None:
        return None
    
    elapsed = time.time() - cache_data['timestamp']
    if elapsed < _MACRO_CACHE['api_cache_ttl']:
        return cache_data['result']
    else:
        # Remove cache expirado
        del _MACRO_CACHE['api_cache'][api_key]
        return None

def _set_cached_api_result(api_key, result):
    """Cacheia resultado de uma API espec√≠fica."""
    _MACRO_CACHE['api_cache'][api_key] = {
        'result': result,
        'timestamp': time.time()
    }

# üîí NOVO: Sistema de lock para evitar carregamentos simult√¢neos
def _is_processing_locked():
    """Verifica se h√° carregamento em andamento."""
    return _MACRO_CACHE['processing_lock']

def _set_processing_lock(locked):
    """Define/remove lock de processamento."""
    _MACRO_CACHE['processing_lock'] = locked

def _normalize_key(key):
    """Normaliza uma chave de dicion√°rio para min√∫sculo, sem acentos e com underscores."""
    if not isinstance(key, str):
        return key
    # Remove acentos
    nfkd_form = unicodedata.normalize('NFKD', key)
    only_ascii = nfkd_form.encode('ASCII', 'ignore').decode('utf-8')
    # Substitui espa√ßos por underscore e converte para min√∫sculo
    return only_ascii.lower().replace(' ', '_')

class MacroService(BaseService):
    def __init__(self):
        super().__init__()
        self.logger = logging.getLogger(__name__)
        
        # Configura√ß√£o de status - Todos em UPPERCASE para consist√™ncia
        self.status_ativos = ['NOVO', 'AGUARDANDO', 'EM ATENDIMENTO', 'BLOQUEADO']
        self.status_concluidos = ['FECHADO', 'ENCERRADO', 'RESOLVIDO', 'CANCELADO']
        self.status_proximos_conclusao = ['NOVO', 'AGUARDANDO', 'EM ATENDIMENTO']
        
        # Para debug, registra os status considerados
        logger.info(f"Status ativos considerados: {self.status_ativos}")
        logger.info(f"Status conclu√≠dos considerados: {self.status_concluidos}")
        
        # Labels
        self.nao_alocado_label = 'N√£o Alocado'
        
        # Configura√ß√£o de caminhos - Aponta diretamente para dadosr.csv
        base_dir = Path(__file__).resolve().parent.parent.parent
        data_dir = base_dir / 'data'
        self.csv_path = data_dir / 'dadosr.csv'
        logger.info(f"Caminho do CSV definido para: {self.csv_path}")
        
        # Inicializa o leitor de tipos de servi√ßo
        global type_service_reader
        if type_service_reader is None:
            from .typeservice_reader import TypeServiceReader
            type_service_reader = TypeServiceReader()
            logger.info("TypeServiceReader inicializado no MacroService")

    def carregar_dados(self, fonte=None):
        """
        ‚ö° OTIMIZADO: Carrega dados com cache agressivo e sistema de lock para containers.
        
        Args:
            fonte (str, optional): Nome espec√≠fico do arquivo ou None para dadosr.csv
        
        Returns:
            pd.DataFrame: DataFrame com os dados processados
        """
        start_time = time.time()
        
        # üöÄ CACHE HIT: Verificar cache primeiro (fonte=None usa cache)
        if fonte is None:
            cached_dados = _get_cached_dados()
            if cached_dados is not None:
                cache_time = (time.time() - start_time) * 1000
                logger.info(f"‚ö° CACHE HIT: Dados carregados em {cache_time:.1f}ms ({len(cached_dados)} registros)")
                return cached_dados
        
        # üîí LOCK: Evita carregamentos simult√¢neos para dados principais
        if fonte is None and _is_processing_locked():
            logger.info("üîí AGUARDANDO: Outro processo carregando dados principais...")
            # Aguarda at√© 3 segundos pelo lock
            for _ in range(30):  # 30 x 100ms = 3s
                time.sleep(0.1)
                if not _is_processing_locked():
                    break
                cached_dados = _get_cached_dados()
                if cached_dados is not None:
                    lock_time = (time.time() - start_time) * 1000
                    logger.info(f"‚ö° CACHE AP√ìS LOCK: Dados dispon√≠veis em {lock_time:.1f}ms")
                    return cached_dados
        
        # üîí DEFINE LOCK para dados principais
        if fonte is None:
            _set_processing_lock(True)
        
        try:
            # üìÅ DETERMINA ARQUIVO
            if fonte:
                data_dir = self.csv_path.parent
                if not fonte.endswith('.csv'):
                    fonte = fonte + '.csv'
                csv_path = data_dir / fonte
                logger.info(f"üìÅ Fonte espec√≠fica: {fonte}")
            else:
                csv_path = self.csv_path
                logger.info(f"üìÅ Fonte principal: dadosr.csv")
            
            if not csv_path.is_file():
                logger.error(f"‚ùå Arquivo n√£o encontrado: {csv_path}")
                return pd.DataFrame()
            
            # üìä CARREGAMENTO DO CSV
            read_start = time.time()
            dados = pd.read_csv(
                csv_path,
                dtype=str,
                sep=';',
                encoding='latin1',
            )
            read_time = (time.time() - read_start) * 1000
            logger.info(f"üìä CSV lido em {read_time:.1f}ms ({len(dados)} linhas)")
            
            # üîÑ PROCESSAMENTO
            process_start = time.time()
            dados_processados = self._processar_dados_otimizado(dados, csv_path)
            process_time = (time.time() - process_start) * 1000
            
            # üíæ CACHE apenas dados principais
            if fonte is None:
                _set_cached_dados(dados_processados)
                cache_set_time = (time.time() - process_start - process_time/1000) * 1000
                logger.info(f"üíæ Cache atualizado em {cache_set_time:.1f}ms")
            
            total_time = (time.time() - start_time) * 1000
            logger.info(f"‚úÖ DADOS CARREGADOS: {total_time:.1f}ms total (CSV: {read_time:.1f}ms, Proc: {process_time:.1f}ms)")
            
            return dados_processados
            
        except Exception as e:
            logger.error(f"‚ùå ERRO ao carregar: {str(e)}")
            return pd.DataFrame()
        finally:
            # üîì REMOVE LOCK sempre
            if fonte is None:
                _set_processing_lock(False)

    def _processar_dados_otimizado(self, dados, csv_path):
        """
        Processa dados com logs m√≠nimos para evitar spam.
        OTIMIZA√á√ÉO: Vers√£o silenciosa do processamento original.
        """
        try:
            # --- Passo 1.2: Tratamento Inicial (SEM LOGS EXCESSIVOS) ---
            
            # 1.2.1 Convers√£o de Datas (silenciosa)
            colunas_data_simples = ['Aberto em', 'Resolvido em', 'Data da √∫ltima a√ß√£o']
            for col in colunas_data_simples:
                if col in dados.columns:
                    original_col = dados[col].copy()
                    # Tenta primeiro formato com horas, depois sem horas
                    dados[col] = pd.to_datetime(original_col, format='%d/%m/%Y %H:%M', errors='coerce')
                    # Se falhar, tenta formato sem horas
                    mask_failed = dados[col].isna() & original_col.notna() & (original_col != '')
                    if mask_failed.any():
                        dados.loc[mask_failed, col] = pd.to_datetime(original_col[mask_failed], format='%d/%m/%Y', errors='coerce')
                    # OTIMIZA√á√ÉO: Logs removidos para evitar spam

            # Tratamento especial para 'Vencimento em' (silencioso)
            if 'Vencimento em' in dados.columns:
                col_vencimento = 'Vencimento em'
                original_vencimento = dados[col_vencimento].copy()
                dados[col_vencimento] = pd.to_datetime(original_vencimento, format='%d/%m/%Y %H:%M', errors='coerce')
                mask_nat = dados[col_vencimento].isna()
                mask_retry = mask_nat & original_vencimento.notna() & (original_vencimento != '')
                if mask_retry.any():
                    dados.loc[mask_retry, col_vencimento] = pd.to_datetime(original_vencimento[mask_retry], format='%d/%m/%Y', errors='coerce')

            # 1.2.2 Convers√£o Num√©rica (silenciosa)
            if 'N√∫mero' in dados.columns:
                dados['N√∫mero'] = pd.to_numeric(dados['N√∫mero'], errors='coerce').astype('Int64')

            if 'Esfor√ßo estimado' in dados.columns:
                dados['Esfor√ßo estimado'] = dados['Esfor√ßo estimado'].str.replace(',', '.', regex=False)
                dados['Esfor√ßo estimado'] = pd.to_numeric(dados['Esfor√ßo estimado'], errors='coerce').fillna(0.0)
            else:
                dados['Esfor√ßo estimado'] = 0.0

            if 'Andamento' in dados.columns:
                dados['Andamento'] = dados['Andamento'].str.rstrip('%').str.replace(',', '.', regex=False)
                dados['Andamento'] = pd.to_numeric(dados['Andamento'], errors='coerce').fillna(0.0)
                dados['Andamento'] = dados['Andamento'].clip(lower=0, upper=100)
            else:
                dados['Andamento'] = 0.0
            
            # 1.2.3 Convers√£o de Tempo para Horas Decimais (silenciosa)
            if 'Tempo trabalhado' in dados.columns:
                dados['Tempo trabalhado'] = dados['Tempo trabalhado'].apply(self.converter_tempo_para_horas)
            else:
                dados['Tempo trabalhado'] = 0.0

            # --- Passo 1.3: Renomea√ß√£o (SEM LOGS EXCESSIVOS) ---
            rename_map_new_to_old = {
                'N√∫mero': 'Numero',
                'Cliente (Completo)': 'Cliente',
                'Assunto': 'Projeto',
                'Servi√ßo (2¬∫ N√≠vel)': 'Squad',
                'Servi√ßo (3¬∫ N√≠vel)': 'TipoServico',
                'Status': 'Status',
                'Esfor√ßo estimado': 'Horas',
                'Tempo trabalhado': 'HorasTrabalhadas',
                'Andamento': 'Conclusao',
                'Data da √∫ltima a√ß√£o': 'UltimaInteracao',
                'Tipo de faturamento': 'Faturamento',
                'Respons√°vel': 'Especialista',
                'Account Manager ': 'Account Manager',
                'Aberto em': 'DataInicio',
                'Resolvido em': 'DataTermino',
                'Vencimento em': 'VencimentoEm'
            }
            
            colunas_para_renomear = {k: v for k, v in rename_map_new_to_old.items() if k in dados.columns}
            dados.rename(columns=colunas_para_renomear, inplace=True)
            
            # --- Passo 1.3.1: Fallback para coluna Projeto (NOVO) ---
            # Se Assunto est√° vazio ou n√£o existe, usa Cliente como fallback
            if 'Projeto' in dados.columns and 'Cliente' in dados.columns:
                mask_projeto_vazio = dados['Projeto'].isna() | (dados['Projeto'] == '') | (dados['Projeto'] == 'nan')
                if mask_projeto_vazio.any():
                    dados.loc[mask_projeto_vazio, 'Projeto'] = dados.loc[mask_projeto_vazio, 'Cliente']
                    # Log apenas se houver fallbacks aplicados
                    num_fallbacks = mask_projeto_vazio.sum()
                    if num_fallbacks > 0:
                        logger.info(f"Aplicado fallback Cliente‚ÜíProjeto em {num_fallbacks} registros")
            elif 'Cliente' in dados.columns and 'Projeto' not in dados.columns:
                # Se a coluna Assunto n√£o existe ainda, cria Projeto copiando de Cliente
                dados['Projeto'] = dados['Cliente']
                logger.info("Criada coluna 'Projeto' usando dados de 'Cliente' (coluna Assunto n√£o encontrada)")
            
            # OTIMIZA√á√ÉO: Log removido para evitar spam

            # --- Passo 1.4: Padroniza√ß√£o Final (SEM LOGS EXCESSIVOS) ---
            
            # 1.4.1 Padroniza√ß√£o de Status (silenciosa)
            if 'Status' in dados.columns:
                dados['Status'] = dados['Status'].astype(str).str.strip().str.upper()

            # 1.4.2 Padroniza√ß√£o de Faturamento (silenciosa)
            faturamento_map = {
                "PRIME": "PRIME",
                "Descontar do PLUS no inicio do projeto": "PLUS",
                "Faturar no inicio do projeto": "INICIO",
                "Faturar no final do projeto": "TERMINO",
                "Faturado em outro projeto": "FEOP",
                "Engajamento": "ENGAJAMENTO"
            }
            if 'Faturamento' in dados.columns:
                dados['Faturamento'] = dados['Faturamento'].astype(str).str.strip()
                dados['Faturamento'] = dados['Faturamento'].str.rstrip('. ').str.strip()
                dados['Faturamento_Original'] = dados['Faturamento']
                dados['Faturamento'] = dados['Faturamento'].map(faturamento_map)
                nao_mapeados = dados['Faturamento'].isna()
                if nao_mapeados.any():
                    dados['Faturamento'] = dados['Faturamento'].fillna('NAO_MAPEADO')

            # 1.4.3 Padroniza√ß√£o de outras colunas de texto (silenciosa)
            colunas_texto_padrao = ['Projeto', 'Squad', 'Especialista', 'Account Manager']
            for col in colunas_texto_padrao:
                if col in dados.columns:
                    dados[col] = dados[col].astype(str).str.strip()
                    dados[col] = dados[col].fillna('')
            
            # C√°lculo de HorasRestantes (silencioso)
            if 'Horas' in dados.columns and 'HorasTrabalhadas' in dados.columns:
                dados['HorasRestantes'] = (dados['Horas'] - dados['HorasTrabalhadas']).round(1)
            else:
                dados['HorasRestantes'] = 0.0

            # OTIMIZA√á√ÉO: Log m√≠nimo apenas quando necess√°rio
            # logger.info(f"Dados processados: {len(dados)} registros")
            return dados
            
        except Exception as e:
            logger.error(f"Erro ao processar dados: {str(e)}")
            return pd.DataFrame()

    def obter_dados_e_referencia_atual(self):
        """
        Carrega os dados atuais (dadosr.csv) e define o m√™s de refer√™ncia como o m√™s atual do sistema.
        
        A Vis√£o Atual sempre usa:
        - Dados: dadosr.csv (dados correntes do m√™s atual)
        - M√™s de refer√™ncia: M√™s atual do sistema (hoje = 04/Junho/2025 -> Junho/2025)
        - Compara√ß√µes: Com dados hist√≥ricos dos meses anteriores (Maio, Abril, Mar√ßo)

        Returns:
            tuple: (pd.DataFrame, datetime.datetime) contendo os dados carregados
                   e o m√™s de refer√™ncia (primeiro dia do m√™s atual). Retorna (DataFrame vazio, None)
                   se os dados n√£o puderem ser carregados.
        """
        logger.info("Obtendo dados atuais (dadosr.csv) para Vis√£o Atual...")
        
        # SEMPRE usa dadosr.csv para a vis√£o atual
        dados_atuais = self.carregar_dados(fonte=None)  # Carrega dadosr.csv

        if dados_atuais.empty:
            logger.warning("N√£o foi poss√≠vel carregar dados atuais (dadosr.csv).")
            return pd.DataFrame(), None

        # Para a Vis√£o Atual, SEMPRE usa o m√™s atual do sistema
        mes_referencia_atual = datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        logger.info(f"Vis√£o Atual - M√™s de refer√™ncia definido como m√™s atual: {mes_referencia_atual.strftime('%B/%Y')}")
        
        # Log informativo sobre as datas nos dados (apenas para debug)
        if 'UltimaInteracao' in dados_atuais.columns:
            datas_interacao = pd.to_datetime(dados_atuais['UltimaInteracao'], errors='coerce')
            datas_validas = datas_interacao.dropna()
            if not datas_validas.empty:
                data_maxima = datas_validas.max()
                data_minima = datas_validas.min()
                logger.info(f"Dados carregados: datas de {data_minima.strftime('%d/%m/%Y')} at√© {data_maxima.strftime('%d/%m/%Y')} ({len(dados_atuais)} registros)")

        return dados_atuais, mes_referencia_atual

    def converter_tempo_para_horas(self, tempo_str):
        """Converte string de tempo (HH:MM:SS) para horas decimais"""
        try:
            if pd.isna(tempo_str) or tempo_str == '':
                return 0.0
            if isinstance(tempo_str, (int, float)):
                return float(tempo_str)
            # Remove espa√ßos e converte para string
            tempo_str = str(tempo_str).strip()
            # Se j√° for um n√∫mero, retorna como float
            if tempo_str.replace('.', '').isdigit():
                return float(tempo_str)
            # Converte formato HH:MM:SS para horas
            partes = tempo_str.split(':')
            if len(partes) == 3:
                horas = int(partes[0])
                minutos = int(partes[1])
                segundos = int(partes[2])
                return horas + (minutos/60) + (segundos/3600)
            elif len(partes) == 2:
                horas = int(partes[0])
                minutos = int(partes[1])
                return horas + (minutos/60)
            return 0.0
        except Exception as e:
            logger.error(f"Erro ao converter tempo '{tempo_str}': {str(e)}")
            return 0.0

    def obter_metricas_macro(self, dados):
        """Obt√©m m√©tricas para o dashboard macro"""
        try:
            if dados is None or dados.empty:
                return {}
                
            metricas = {
                'total_projetos': len(dados),
                'projetos_ativos': len(dados[dados['Status'] == STATUS_ATIVO]),
                'projetos_criticos': len(dados[dados['Status'] == STATUS_CRITICO]),
                'projetos_concluidos': len(dados[dados['Status'] == STATUS_CONCLUIDO]),
                'projetos_em_atendimento': len(dados[dados['Status'] == STATUS_ATENDIMENTO])
            }
            
            return metricas
            
        except Exception as e:
            logger.error(f"Erro ao obter m√©tricas macro: {str(e)}")
            return {}
            
    def obter_projetos_por_especialista(self, dados, nome_especialista):
        """Obt√©m projetos por especialista"""
        try:
            if dados is None or dados.empty:
                return []
                
            projetos = dados[dados['Especialista'] == nome_especialista].copy()
            
            # Adiciona verifica√ß√£o de backlog usando a fun√ß√£o auxiliar
            projetos = self._adicionar_verificacao_backlog(projetos)
            
            return self._formatar_projetos(projetos)
            
        except Exception as e:
            logger.error(f"Erro ao obter projetos por especialista: {str(e)}")
            return []
            
    def obter_projetos_por_account(self, dados, nome_account):
        """Obt√©m projetos por account manager"""
        try:
            if dados is None or dados.empty:
                return []
                
            projetos = dados[dados['Account Manager'] == nome_account].copy()
            
            # Adiciona verifica√ß√£o de backlog usando a fun√ß√£o auxiliar  
            projetos = self._adicionar_verificacao_backlog(projetos)
            
            return self._formatar_projetos(projetos)
            
        except Exception as e:
            logger.error(f"Erro ao obter projetos por account: {str(e)}")
            return []
            
    def obter_projetos_ativos(self, dados):
        """Obt√©m projetos ativos"""
        try:
            if dados is None or dados.empty:
                 logger.warning("DataFrame vazio fornecido para obter_projetos_ativos.")
                 return []
            
            if 'Status' not in dados.columns:
                 logger.error("Coluna 'Status' n√£o encontrada no DataFrame.")
                 return []

            # CORRE√á√ÉO: Usar isin com a lista self.status_ativos
            filtro_status = dados['Status'].isin(self.status_ativos)
            projetos = dados[filtro_status]
            logger.info(f"Filtrando por status ativos: {self.status_ativos}. Encontrados: {len(projetos)}")
            
            return self._formatar_projetos(projetos)
            
        except Exception as e:
            # Log do erro completo para melhor diagn√≥stico
            logger.error(f"Erro ao obter projetos ativos: {str(e)}", exc_info=True)
            return []

    def obter_projetos_criticos(self, dados):
        """Obt√©m projetos cr√≠ticos"""
        try:
            if dados is None or dados.empty:
                return []
                
            projetos = dados[dados['Status'] == STATUS_CRITICO]
            return self._formatar_projetos(projetos)
            
        except Exception as e:
            logger.error(f"Erro ao obter projetos cr√≠ticos: {str(e)}")
            return []
            
    def obter_projetos_concluidos(self, dados):
        """Obt√©m projetos conclu√≠dos"""
        try:
            if dados is None or dados.empty:
                return []
                
            projetos = dados[dados['Status'] == STATUS_CONCLUIDO]
            return self._formatar_projetos(projetos)
            
        except Exception as e:
            logger.error(f"Erro ao obter projetos conclu√≠dos: {str(e)}")
            return []
            
    def obter_projetos_eficiencia(self, dados):
        """Obt√©m projetos ordenados por efici√™ncia"""
        try:
            if dados is None or dados.empty:
                return []
                
            # Calcular efici√™ncia (conclus√£o / horas trabalhadas)
            dados['Eficiencia'] = dados['Conclusao'] / dados['HorasTrabalhadas']
            
            # Ordenar por efici√™ncia
            projetos = dados.sort_values('Eficiencia', ascending=False)
            return self._formatar_projetos(projetos)
            
        except Exception as e:
            logger.error(f"Erro ao obter projetos por efici√™ncia: {str(e)}")
            return []

    def _formatar_projetos(self, projetos):
        """Formata dados dos projetos para retorno usando os nomes RENOMEADOS."""
        # Nomes das colunas AP√ìS renomea√ß√£o em carregar_dados
        col_numero = 'Numero' # Ou 'N√∫mero' se a renomea√ß√£o falhar/n√£o ocorrer
        col_projeto = 'Projeto'
        col_status = 'Status'
        col_squad = 'Squad'
        col_especialista = 'Especialista'
        col_account = 'Account Manager' # Aten√ß√£o ao espa√ßo no final se n√£o foi removido na renomea√ß√£o
        col_data_inicio = 'DataInicio'
        col_data_vencimento = 'VencimentoEm'
        col_conclusao = 'Conclusao'
        col_horas_trab = 'HorasTrabalhadas'
        col_horas_rest = 'HorasRestantes' # Calculado em preparar_dados_base
        col_horas_prev = 'Horas' # Nome ap√≥s renomea√ß√£o de 'Esfor√ßo estimado'

        # Importa o leitor de tipos de servi√ßo
        from .typeservice_reader import type_service_reader
        
        resultados = []
        hoje = datetime.now().date()
        
        try:
            for _, row in projetos.iterrows():
                # Usa .get(col_name, default_value) para evitar KeyError se uma coluna n√£o existir
                numero_val = row.get(col_numero, '')
                # Fallback para 'N√∫mero' original se 'Numero' n√£o existir
                if numero_val == '' and 'N√∫mero' in row:
                    numero_val = row.get('N√∫mero', '')
                
                # Trata Account Manager com e sem espa√ßo no final
                account_val = row.get(col_account, row.get('Account Manager ', ''))
                
                # CORRE√á√ÉO 1: Cliente real (n√£o projeto)
                cliente_val = row.get('Cliente', 'N/A')
                projeto_val = row.get(col_projeto, 'N/A')
                
                # CORRE√á√ÉO 2: Categoria do tipo de servi√ßo
                # Busca o tipo de servi√ßo em v√°rias colunas poss√≠veis (incluindo nomes pr√© e p√≥s renomea√ß√£o)
                colunas_tipo_servico = [
                    'TipoServico', 'Tipo de Servi√ßo', 'Tipo de servico',   # Nomes poss√≠veis no CSV atual
                    'Servi√ßo (2¬∫ N√≠vel)', 'Servico 2 Nivel',               # Nomes nos CSVs hist√≥ricos  
                    'Servi√ßo (3¬∫ N√≠vel)', 'Servico 3 Nivel',               # Nomes alternativos
                    'Projeto'                                               # Nome ap√≥s renomea√ß√£o (pode conter o tipo)
                ]
                tipo_servico_raw = ''
                for col in colunas_tipo_servico:
                    if col in row.index and pd.notna(row[col]) and str(row[col]).strip():
                        valor = str(row[col]).strip()
                        # Se for a coluna 'Projeto' e cont√©m apenas categoria simples (M365, Azure, etc.), usa
                        if col == 'Projeto' and valor in ['M365', 'Azure', 'Data e Power', 'Outros']:
                            tipo_servico_raw = valor
                            break
                        elif col != 'Projeto':  # Para outras colunas, usa diretamente
                            tipo_servico_raw = valor
                            break
                
                categoria_servico = type_service_reader.obter_categoria(tipo_servico_raw) if tipo_servico_raw else 'N/A'
                
                # CORRE√á√ÉO 3: C√°lculo do tempo de vida do projeto
                tempo_vida_dias = 0
                data_abertura = None
                
                # Tenta encontrar data de abertura em diferentes colunas poss√≠veis
                colunas_abertura = ['DataInicio', 'DataAbertura', 'Data Abertura', 'data_abertura', 'Aberto em']
                for col in colunas_abertura:
                    if col in row.index and pd.notna(row[col]):
                        data_abertura = row[col]
                        break
                
                if data_abertura and pd.notna(data_abertura):
                    try:
                        if isinstance(data_abertura, str):
                            # Tenta converter string para data
                            data_abertura = pd.to_datetime(data_abertura, errors='coerce')
                        
                        if pd.notna(data_abertura):
                            data_abertura_date = data_abertura.date() if hasattr(data_abertura, 'date') else data_abertura
                            tempo_vida_dias = (hoje - data_abertura_date).days
                    except Exception as e:
                        logger.debug(f"Erro ao calcular tempo de vida para projeto {numero_val}: {str(e)}")
                        tempo_vida_dias = 0
                
                # Formata as datas com verifica√ß√£o
                data_inicio_str = row.get(col_data_inicio, pd.NaT)
                data_inicio_fmt = data_inicio_str.strftime('%d/%m/%Y') if pd.notna(data_inicio_str) else ''
                
                # CORRE√á√ÉO 4: Vencimento com "-" se vazio
                data_vencimento_str = row.get(col_data_vencimento, pd.NaT)
                data_vencimento_fmt = data_vencimento_str.strftime('%d/%m/%Y') if pd.notna(data_vencimento_str) else '-'
                
                # CORRE√á√ÉO 5: Data resolvido com "-" se vazio
                # Nota: 'Resolvido em' √© renomeado para 'DataTermino' no processamento
                data_resolvido = row.get('DataTermino', row.get('Resolvido em', pd.NaT))
                data_resolvido_fmt = data_resolvido.strftime('%d/%m/%Y') if pd.notna(data_resolvido) else '-'
                
                # Outros dados
                faturamento_val = row.get('Faturamento', row.get('TipoFaturamento', 'N/A'))
                
                # Dicion√°rio base do projeto
                projeto_dict = {
                    'numero': numero_val,
                    'projeto': projeto_val,  # Nome do projeto
                    'status': row.get(col_status, 'N/A'),
                    'squad': row.get(col_squad, 'N/A'),
                    'especialista': row.get(col_especialista, 'N/A'),
                    'account': account_val,
                    'data_inicio': data_inicio_fmt,
                    'dataPrevEnc': data_vencimento_fmt,  # CORRIGIDO: usar "-" se vazio
                    'conclusao': float(row.get(col_conclusao, 0.0)) if pd.notna(row.get(col_conclusao)) else 0.0,
                    'horas_trabalhadas': float(row.get(col_horas_trab, 0.0)) if pd.notna(row.get(col_horas_trab)) else 0.0,
                    'horasRestantes': float(row.get(col_horas_rest, 0.0)) if pd.notna(row.get(col_horas_rest)) else 0.0,
                    'Horas': float(row.get(col_horas_prev, 0.0)) if pd.notna(row.get(col_horas_prev)) else 0.0,
                    'backlog_exists': row.get('backlog_exists', False),
                    # Campos corrigidos para o relat√≥rio geral
                    'cliente': cliente_val,  # CORRIGIDO: cliente real
                    'servico': categoria_servico,  # CORRIGIDO: categoria do tipo de servi√ßo
                    'tipo_faturamento': faturamento_val,
                    'data_resolvido': data_resolvido_fmt,  # CORRIGIDO: "-" se vazio
                    'account_manager': account_val,
                    'tempo_vida': tempo_vida_dias  # CORRIGIDO: dias calculados
                }
                
                # Adiciona campos auxiliares se existirem (para relat√≥rios evolutivo, comparativo, etc.)
                if '_fonte_periodo' in row.index:
                    projeto_dict['_fonte_periodo'] = row.get('_fonte_periodo', 'N/A')
                
                if '_ordem_periodo' in row.index:
                    projeto_dict['_ordem_periodo'] = row.get('_ordem_periodo', 0)
                
                if '_mudancas' in row.index:
                    projeto_dict['_mudancas'] = row.get('_mudancas', '')
                
                if '_status_anterior' in row.index:
                    projeto_dict['_status_anterior'] = row.get('_status_anterior', '')
                
                resultados.append(projeto_dict)
            
            logger.info(f"Formatados {len(resultados)} projetos para relat√≥rio geral")
            return resultados
            
        except Exception as e:
            # Log mais detalhado do erro e da linha onde ocorreu (se poss√≠vel)
            logger.error(f"Erro ao formatar projetos: {str(e)}", exc_info=True)
            # Tenta retornar o que foi processado at√© agora
            return resultados if resultados else []

    def calcular_horas_restantes(self, dados):
        """Calcula horas restantes para cada projeto."""
        try:
            if 'HorasTrabalhadas' not in dados.columns or 'Horas' not in dados.columns:
                return dados
                
            # Converte horas previstas para num√©rico
            dados['Horas'] = pd.to_numeric(dados['Horas'].str.replace(',', '.'), errors='coerce')
            
            # Calcula horas restantes
            dados['HorasRestantes'] = dados['Horas'] - dados['HorasTrabalhadas']
            dados['HorasRestantes'] = dados['HorasRestantes'].clip(lower=0)
            
            return dados
            
        except Exception as e:
            logger.error(f"Erro ao calcular horas restantes: {str(e)}")
            return dados

    def calcular_projetos_ativos(self, dados):
        """
        Calcula especificamente os projetos ativos e suas m√©tricas.
        Retorna um dicion√°rio com:
        - total: n√∫mero total de projetos ativos
        - dados: DataFrame com os projetos ativos (incluindo backlog_exists)
        - metricas: m√©tricas espec√≠ficas dos projetos ativos
        """
        try:
            logger.info("Calculando projetos ativos...")
            
            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)
            
            # Filtra apenas projetos ativos (n√£o conclu√≠dos) e exclui CDB DATA SOLUTIONS
            projetos_ativos_df = dados_base[
                (~dados_base['Status'].isin(self.status_concluidos)) &
                (dados_base['Squad'] != 'CDB DATA SOLUTIONS')
            ].copy()
            
            # Calcula m√©tricas espec√≠ficas (antes de adicionar backlog_exists)
            metricas = {
                'total': len(projetos_ativos_df),
                'por_squad': projetos_ativos_df.groupby('Squad').size().to_dict(),
                'media_conclusao': round(projetos_ativos_df['Conclusao'].mean(), 1),
                'media_horas_restantes': round(projetos_ativos_df['HorasRestantes'].mean(), 1)
            }
            
            # Prepara dados para o modal (colunas base)
            colunas_modal = ['Numero', 'Projeto', 'Status', 'Squad', 'Conclusao', 'HorasRestantes', 'VencimentoEm', 'Horas']
            
            # Certifica-se de que a coluna Numero existe
            if 'Numero' not in projetos_ativos_df.columns and 'N√∫mero' in projetos_ativos_df.columns:
                projetos_ativos_df['Numero'] = projetos_ativos_df['N√∫mero']
            elif 'Numero' not in projetos_ativos_df.columns:
                logger.warning("Coluna 'Numero' n√£o encontrada nos projetos ativos. Criando coluna vazia.")
                projetos_ativos_df['Numero'] = ''
            else:
                 # Garante que 'Numero' seja string para a consulta do backlog
                 projetos_ativos_df['Numero'] = projetos_ativos_df['Numero'].astype(str)

            # <<< IN√çCIO: Adicionar verifica√ß√£o de backlog >>>
            if not projetos_ativos_df.empty and 'Numero' in projetos_ativos_df.columns:
                # Pega todos os IDs de projeto (n√∫meros) √∫nicos e n√£o vazios
                project_ids = projetos_ativos_df['Numero'].dropna().unique().tolist()
                project_ids = [pid for pid in project_ids if pid] # Remove vazios

                if project_ids:
                     # Consulta o banco para ver quais IDs t√™m backlog
                    try:
                        # Importa o modelo Backlog e db localmente para evitar importa√ß√£o circular
                        from app.models import Backlog
                        from app import db
                        
                        backlogs_existentes = db.session.query(Backlog.project_id)\
                                                        .filter(Backlog.project_id.in_(project_ids))\
                                                        .all()
                        # Cria um set com os IDs que t√™m backlog para busca r√°pida
                        ids_com_backlog = {result[0] for result in backlogs_existentes}
                        logger.info(f"Encontrados {len(ids_com_backlog)} backlogs para {len(project_ids)} projetos ativos verificados.")
                        
                        # Adiciona a coluna 'backlog_exists' ao DataFrame
                        projetos_ativos_df['backlog_exists'] = projetos_ativos_df['Numero'].apply(lambda pid: pid in ids_com_backlog if pd.notna(pid) else False)

                    except Exception as db_error:
                        logger.error(f"Erro ao consultar backlogs existentes: {db_error}", exc_info=True)
                        # Se der erro no DB, assume que nenhum backlog existe para n√£o quebrar
                        projetos_ativos_df['backlog_exists'] = False
                else:
                    logger.info("Nenhum ID de projeto v√°lido encontrado para verificar backlog.")
                    projetos_ativos_df['backlog_exists'] = False
            else:
                 logger.info("DataFrame de projetos ativos vazio ou sem coluna 'Numero'. Pulando verifica√ß√£o de backlog.")
                 # Garante que a coluna exista mesmo vazia
                 if 'Numero' in projetos_ativos_df.columns:
                      projetos_ativos_df['backlog_exists'] = False

            # <<< FIM: Adicionar verifica√ß√£o de backlog >>>

            # Seleciona apenas as colunas que existem no DataFrame final
            colunas_finais = colunas_modal + ['backlog_exists'] # Adiciona a nova coluna
            colunas_existentes = [col for col in colunas_finais if col in projetos_ativos_df.columns]
            
            dados_para_retorno = projetos_ativos_df[colunas_existentes].copy() # Usar .copy() para evitar SettingWithCopyWarning

            # <<< IN√çCIO: Calcular tempo de vida do projeto >>>
            hoje = datetime.now().date()
            
            # Debug: mostrar colunas dispon√≠veis
            logger.info(f"Colunas dispon√≠veis para c√°lculo tempo de vida: {projetos_ativos_df.columns.tolist()}")
            
            def calcular_tempo_vida(row):
                try:
                    # Tenta encontrar data de abertura em diferentes colunas poss√≠veis
                    data_abertura = None
                    
                    # Verifica colunas poss√≠veis de data de abertura (ordem de prioridade)
                    colunas_possiveis = ['DataInicio', 'DataAbertura', 'Data Abertura', 'data_abertura', 'DataCriacao', 'Data Criacao', 'Data_Criacao', 'Aberto em']
                    for col in colunas_possiveis:
                        if col in row.index and pd.notna(row[col]):
                            data_abertura = row[col]
                            logger.debug(f"Encontrada data de abertura na coluna '{col}': {data_abertura} para projeto {row.get('Numero', 'N/A')}")
                            break
                    
                    if data_abertura is None:
                        # Se n√£o encontrou data espec√≠fica, usa uma estimativa baseada no n√∫mero do projeto
                        # Projetos mais antigos t√™m n√∫meros menores (aproxima√ß√£o)
                        if 'Numero' in row.index and pd.notna(row['Numero']):
                            numero = str(row['Numero'])
                            if numero.isdigit():
                                numero_int = int(numero)
                                # Estima: projetos com n√∫meros menores s√£o mais antigos
                                # Esta √© uma aproxima√ß√£o que pode ser ajustada
                                if numero_int < 1000:
                                    logger.debug(f"Estimativa para projeto {numero}: 400 dias (< 1000)")
                                    return 400  # ~1 ano e 1 m√™s
                                elif numero_int < 3000:
                                    logger.debug(f"Estimativa para projeto {numero}: 300 dias (< 3000)")
                                    return 300  # ~10 meses
                                elif numero_int < 5000:
                                    logger.debug(f"Estimativa para projeto {numero}: 200 dias (< 5000)")
                                    return 200  # ~6-7 meses
                                elif numero_int < 7000:
                                    logger.debug(f"Estimativa para projeto {numero}: 150 dias (< 7000)")
                                    return 150  # ~5 meses
                                else:
                                    logger.debug(f"Estimativa para projeto {numero}: 90 dias (>= 7000)")
                                    return 90   # ~3 meses
                        logger.warning(f"N√£o foi poss√≠vel calcular tempo de vida para projeto {row.get('Numero', 'N/A')} - dados insuficientes")
                        return None
                        
                    # Converte para datetime se for string
                    if isinstance(data_abertura, str):
                        # Tenta diferentes formatos de data
                        for formato in ['%Y-%m-%d', '%d/%m/%Y', '%Y-%m-%d %H:%M:%S', '%d/%m/%Y %H:%M:%S']:
                            try:
                                data_abertura = datetime.strptime(data_abertura, formato).date()
                                break
                            except ValueError:
                                continue
                    elif hasattr(data_abertura, 'date'):
                        data_abertura = data_abertura.date()
                    
                    if data_abertura:
                        diff = hoje - data_abertura
                        return diff.days
                        
                except Exception as e:
                    logger.debug(f"Erro ao calcular tempo de vida para projeto {row.get('Numero', 'N/A')}: {e}")
                
                return None
            
            # Adiciona coluna de tempo de vida
            dados_para_retorno['tempo_vida'] = projetos_ativos_df.apply(calcular_tempo_vida, axis=1)
            logger.info(f"Tempo de vida calculado - Exemplos: {dados_para_retorno['tempo_vida'].head().tolist()}")
            # <<< FIM: Calcular tempo de vida do projeto >>>

            # <<< IN√çCIO: Restaurar Renomea√ß√£o e Formata√ß√£o >>>
            # Renomeia colunas para o formato esperado pelo frontend
            rename_map_final = {
                'Numero': 'numero',
                'Projeto': 'projeto',
                'Status': 'status',
                'Squad': 'squad',
                'Conclusao': 'conclusao',
                'HorasRestantes': 'horasRestantes',
                'VencimentoEm': 'dataPrevEnc',
                'Horas': 'Horas', # Manter Horas para c√°lculo no JS se necess√°rio
                'backlog_exists': 'backlog_exists', # Manter a coluna de backlog
                'tempo_vida': 'tempo_vida' # Nova coluna de tempo de vida
            }
            # Filtra o mapa de renomea√ß√£o para incluir apenas colunas que existem em dados_para_retorno
            colunas_para_renomear_final = {k: v for k, v in rename_map_final.items() if k in dados_para_retorno.columns}
            dados_para_retorno = dados_para_retorno.rename(columns=colunas_para_renomear_final)
            
            # Formata a data de vencimento (se a coluna existir ap√≥s renomea√ß√£o)
            if 'dataPrevEnc' in dados_para_retorno.columns:
                 # Primeiro converte para datetime (caso ainda n√£o seja)
                 dados_para_retorno['dataPrevEnc'] = pd.to_datetime(dados_para_retorno['dataPrevEnc'], errors='coerce')
                 # Depois formata como string no formato brasileiro
                 dados_para_retorno['dataPrevEnc'] = dados_para_retorno['dataPrevEnc'].dt.strftime('%d/%m/%Y')
                 # Substitui valores NaT/None por 'N/A'
                 dados_para_retorno['dataPrevEnc'] = dados_para_retorno['dataPrevEnc'].fillna('N/A')
            # <<< FIM: Restaurar Renomea√ß√£o e Formata√ß√£o >>>

            logger.info(f"Calculados {metricas['total']} projetos ativos. Colunas retornadas ap√≥s renomea√ß√£o: {dados_para_retorno.columns.tolist()}")
            
            return {
                "total": metricas['total'],
                # Retorna o DataFrame formatado e substitui NaN por None na convers√£o para dict
                "dados": dados_para_retorno.replace({np.nan: None}), 
                "metricas": metricas
            }

        except KeyError as ke:
             logger.error(f"Erro de chave ao calcular projetos ativos: {ke}. Colunas dispon√≠veis: {dados.columns.tolist()}", exc_info=True)
             # Retorna estrutura vazia em caso de erro grave de coluna
             return {"total": 0, "dados": pd.DataFrame(), "metricas": {}}
        except Exception as e:
            logger.exception(f"Erro inesperado ao calcular projetos ativos: {e}")
            # Retorna estrutura vazia em caso de erro inesperado
            return {"total": 0, "dados": pd.DataFrame(), "metricas": {}}

    def calcular_projetos_criticos(self, dados):
        """
        Calcula especificamente os projetos cr√≠ticos e suas m√©tricas.
        Um projeto √© considerado cr√≠tico quando:
        - Est√° com status BLOQUEADO
        - Tem horas restantes negativas
        - Est√° com o prazo vencido
        Obs: Apenas projetos n√£o conclu√≠dos s√£o considerados
        """
        try:
            logger.info("Calculando projetos cr√≠ticos...")
            
            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)
            hoje = pd.Timestamp(datetime.now().replace(hour=0, minute=0, second=0, microsecond=0))
            logger.debug(f"Data de refer√™ncia (hoje): {hoje.strftime('%d/%m/%Y')}")
            
            # Primeiro filtra apenas projetos n√£o conclu√≠dos e exclui CDB DATA SOLUTIONS
            projetos_nao_concluidos = dados_base[
                (~dados_base['Status'].isin(self.status_concluidos)) &
                (dados_base['Squad'] != 'CDB DATA SOLUTIONS')
            ]
            logger.debug(f"Total de projetos n√£o conclu√≠dos: {len(projetos_nao_concluidos)}")
            
            # Condi√ß√µes de criticidade (aplicadas apenas em projetos n√£o conclu√≠dos)
            bloqueados = (projetos_nao_concluidos['Status'] == 'BLOQUEADO')
            logger.debug(f"Projetos bloqueados: {len(projetos_nao_concluidos[bloqueados])}")
            
            horas_negativas = (projetos_nao_concluidos['HorasRestantes'] < 0)
            logger.debug(f"Projetos com horas negativas: {len(projetos_nao_concluidos[horas_negativas])}")
            
            # Ajuste na verifica√ß√£o de prazo vencido
            projetos_nao_concluidos['VencimentoEm'] = pd.to_datetime(projetos_nao_concluidos['VencimentoEm']).dt.normalize()
            
            # Log para debug da data de hoje
            logger.debug(f"Data de refer√™ncia (hoje normalizada): {hoje.strftime('%d/%m/%Y')}")
            
            # Verifica prazo vencido com log detalhado
            prazo_vencido = projetos_nao_concluidos.apply(
                lambda row: pd.notna(row['VencimentoEm']) and row['VencimentoEm'] < hoje,
                axis=1
            )
            
            # Log detalhado das compara√ß√µes de data
            for idx, row in projetos_nao_concluidos.iterrows():
                if pd.notna(row['VencimentoEm']):
                    is_vencido = row['VencimentoEm'] < hoje
                    logger.debug(
                        f"Projeto: {row['Projeto']}, "
                        f"Data vencimento: {row['VencimentoEm'].strftime('%d/%m/%Y')}, "
                        f"Est√° vencido? {'Sim' if is_vencido else 'N√£o'}, "
                        f"Compara√ß√£o: {row['VencimentoEm']} < {hoje}"
                    )
            
            logger.debug(f"Projetos com prazo vencido: {len(projetos_nao_concluidos[prazo_vencido])}")
            
            # Combina as condi√ß√µes
            projetos_criticos = projetos_nao_concluidos[bloqueados | horas_negativas | prazo_vencido].copy()
            
            # Log dos projetos cr√≠ticos identificados
            logger.info(f"Total de projetos cr√≠ticos identificados: {len(projetos_criticos)}")
            for idx, row in projetos_criticos.iterrows():
                logger.debug(f"Projeto cr√≠tico: {row['Projeto']}, "
                            f"Status: {row['Status']}, "
                            f"Horas Restantes: {row['HorasRestantes']}, "
                            f"Data vencimento: {row['VencimentoEm'].strftime('%d/%m/%Y') if pd.notna(row['VencimentoEm']) else 'N/A'}")
            
            # Adiciona motivos
            projetos_criticos['motivo'] = ''
            projetos_criticos.loc[bloqueados, 'motivo'] += 'Projeto bloqueado; '
            projetos_criticos.loc[horas_negativas, 'motivo'] += 'Horas excedidas; '
            projetos_criticos.loc[prazo_vencido, 'motivo'] += 'Prazo vencido; '
            projetos_criticos['motivo'] = projetos_criticos['motivo'].str.rstrip('; ')
            
            # Calcula m√©tricas espec√≠ficas
            metricas = {
                'total': len(projetos_criticos),
                'bloqueados': len(projetos_nao_concluidos[bloqueados]),
                'horas_negativas': len(projetos_nao_concluidos[horas_negativas]),
                'prazo_vencido': len(projetos_nao_concluidos[prazo_vencido])
            }
            
            # Certifica-se de que a coluna Numero existe
            if 'Numero' not in projetos_criticos.columns and 'N√∫mero' in projetos_criticos.columns:
                projetos_criticos['Numero'] = projetos_criticos['N√∫mero']
            elif 'Numero' not in projetos_criticos.columns:
                logger.warning("Coluna 'Numero' n√£o encontrada em projetos cr√≠ticos. Criando coluna vazia.")
                projetos_criticos['Numero'] = ''
            
            # Adiciona verifica√ß√£o de backlog usando a fun√ß√£o auxiliar
            projetos_criticos = self._adicionar_verificacao_backlog(projetos_criticos)
            
            # Seleciona apenas as colunas existentes para retornar (igual ao m√©todo de projetos ativos)
            colunas_modal_criticos = ['Numero', 'Projeto', 'Status', 'Squad', 'Conclusao', 'HorasRestantes', 'VencimentoEm', 'Horas']
            
            # Certifica-se de que a coluna Numero existe
            if 'Numero' not in projetos_criticos.columns and 'N√∫mero' in projetos_criticos.columns:
                projetos_criticos['Numero'] = projetos_criticos['N√∫mero']
            elif 'Numero' not in projetos_criticos.columns:
                logger.warning("Coluna 'Numero' n√£o encontrada nos projetos cr√≠ticos. Criando coluna vazia.")
                projetos_criticos['Numero'] = ''
            else:
                # Garante que 'Numero' seja string
                projetos_criticos['Numero'] = projetos_criticos['Numero'].astype(str)

            # <<< IN√çCIO: Adicionar verifica√ß√£o de backlog para projetos cr√≠ticos >>>
            if not projetos_criticos.empty and 'Numero' in projetos_criticos.columns:
                project_ids = projetos_criticos['Numero'].dropna().unique().tolist()
                project_ids = [pid for pid in project_ids if pid]

                if project_ids:
                    try:
                        from app.models import Backlog
                        from app import db
                        
                        backlogs_existentes = db.session.query(Backlog.project_id)\
                                                        .filter(Backlog.project_id.in_(project_ids))\
                                                        .all()
                        ids_com_backlog = {result[0] for result in backlogs_existentes}
                        logger.info(f"Encontrados {len(ids_com_backlog)} backlogs para {len(project_ids)} projetos cr√≠ticos verificados.")
                        
                        projetos_criticos['backlog_exists'] = projetos_criticos['Numero'].apply(
                            lambda pid: pid in ids_com_backlog if pd.notna(pid) else False
                        )

                    except Exception as db_error:
                        logger.error(f"Erro ao consultar backlogs para projetos cr√≠ticos: {db_error}", exc_info=True)
                        projetos_criticos['backlog_exists'] = False
                else:
                    projetos_criticos['backlog_exists'] = False
            else:
                if 'Numero' in projetos_criticos.columns:
                    projetos_criticos['backlog_exists'] = False
            # <<< FIM: Adicionar verifica√ß√£o de backlog >>>

            # Adiciona a nova coluna de backlog √† lista de colunas
            colunas_finais_criticos = colunas_modal_criticos + ['backlog_exists']
            colunas_existentes_criticos = [col for col in colunas_finais_criticos if col in projetos_criticos.columns]
            
            dados_para_retorno = projetos_criticos[colunas_existentes_criticos].copy()

            # <<< IN√çCIO: Calcular tempo de vida para projetos cr√≠ticos >>>
            hoje = datetime.now().date()
            
            # Debug: mostrar colunas dispon√≠veis
            logger.info(f"Colunas dispon√≠veis para projetos cr√≠ticos: {projetos_criticos.columns.tolist()}")
            
            def calcular_tempo_vida_criticos(row):
                try:
                    # Tenta encontrar data de abertura em diferentes colunas poss√≠veis
                    data_abertura = None
                    
                    # Verifica colunas poss√≠veis de data de abertura (ordem de prioridade)
                    colunas_possiveis = ['DataInicio', 'DataAbertura', 'Data Abertura', 'data_abertura', 'DataCriacao', 'Data Criacao', 'DataCriacao', 'Data_Criacao']
                    for col in colunas_possiveis:
                        if col in row.index and pd.notna(row[col]):
                            data_abertura = row[col]
                            logger.debug(f"Encontrada data de abertura na coluna '{col}': {data_abertura} para projeto cr√≠tico {row.get('Numero', 'N/A')}")
                            break
                    
                    if data_abertura is None:
                        # Se n√£o encontrou data espec√≠fica, usa uma estimativa baseada no n√∫mero do projeto
                        # Para projetos cr√≠ticos, tendemos a assumir que s√£o mais antigos
                        if 'Numero' in row.index and pd.notna(row['Numero']):
                            numero = str(row['Numero'])
                            if numero.isdigit():
                                numero_int = int(numero)
                                # Estima para projetos cr√≠ticos (geralmente mais antigos)
                                if numero_int < 1000:
                                    logger.debug(f"Estimativa para projeto cr√≠tico {numero}: 500 dias (< 1000)")
                                    return 500  # ~1 ano e 4 meses
                                elif numero_int < 3000:
                                    logger.debug(f"Estimativa para projeto cr√≠tico {numero}: 400 dias (< 3000)")
                                    return 400  # ~1 ano e 1 m√™s
                                elif numero_int < 5000:
                                    logger.debug(f"Estimativa para projeto cr√≠tico {numero}: 300 dias (< 5000)")
                                    return 300  # ~10 meses
                                elif numero_int < 7000:
                                    logger.debug(f"Estimativa para projeto cr√≠tico {numero}: 200 dias (< 7000)")
                                    return 200  # ~6-7 meses
                                else:
                                    logger.debug(f"Estimativa para projeto cr√≠tico {numero}: 120 dias (>= 7000)")
                                    return 120  # ~4 meses
                        logger.warning(f"N√£o foi poss√≠vel calcular tempo de vida para projeto cr√≠tico {row.get('Numero', 'N/A')} - dados insuficientes")
                        return None
                        
                    # Converte para datetime se for string
                    if isinstance(data_abertura, str):
                        # Tenta diferentes formatos de data
                        for formato in ['%Y-%m-%d', '%d/%m/%Y', '%Y-%m-%d %H:%M:%S', '%d/%m/%Y %H:%M:%S']:
                            try:
                                data_abertura = datetime.strptime(data_abertura, formato).date()
                                logger.debug(f"Data de abertura convertida com formato {formato}: {data_abertura}")
                                break
                            except ValueError:
                                continue
                    elif hasattr(data_abertura, 'date'):
                        data_abertura = data_abertura.date()
                    
                    if data_abertura:
                        diff = hoje - data_abertura
                        return diff.days
                        
                except Exception as e:
                    logger.debug(f"Erro ao calcular tempo de vida para projeto cr√≠tico {row.get('Numero', 'N/A')}: {e}")
                
                return None
            
            # Adiciona coluna de tempo de vida
            dados_para_retorno['tempo_vida'] = projetos_criticos.apply(calcular_tempo_vida_criticos, axis=1)
            logger.info(f"Tempo de vida calculado para cr√≠ticos - Exemplos: {dados_para_retorno['tempo_vida'].head().tolist()}")
            # <<< FIM: Calcular tempo de vida >>>

            # Renomeia colunas para o formato esperado pelo frontend
            rename_map_criticos = {
                'Numero': 'numero',
                'Projeto': 'projeto',
                'Status': 'status',
                'Squad': 'squad',
                'Conclusao': 'conclusao',
                'HorasRestantes': 'horasRestantes',
                'VencimentoEm': 'dataPrevEnc',
                'Horas': 'Horas',
                'backlog_exists': 'backlog_exists',
                'tempo_vida': 'tempo_vida'
            }
            
            # Filtra o mapa de renomea√ß√£o para incluir apenas colunas que existem
            colunas_para_renomear_criticos = {k: v for k, v in rename_map_criticos.items() if k in dados_para_retorno.columns}
            dados_para_retorno = dados_para_retorno.rename(columns=colunas_para_renomear_criticos)
            
            # Formata a data de vencimento
            if 'dataPrevEnc' in dados_para_retorno.columns:
                dados_para_retorno['dataPrevEnc'] = pd.to_datetime(dados_para_retorno['dataPrevEnc'], errors='coerce')
                dados_para_retorno['dataPrevEnc'] = dados_para_retorno['dataPrevEnc'].dt.strftime('%d/%m/%Y')
                dados_para_retorno['dataPrevEnc'] = dados_para_retorno['dataPrevEnc'].fillna('N/A')

            logger.info(f"Calculados {len(projetos_criticos)} projetos cr√≠ticos. Colunas retornadas: {dados_para_retorno.columns.tolist()}")
            
            return {
                "total": len(projetos_criticos),
                "dados": dados_para_retorno.replace({np.nan: None}),
                "metricas": {
                    'bloqueados': len(projetos_nao_concluidos[bloqueados]),
                    'horas_negativas': len(projetos_nao_concluidos[horas_negativas]),
                    'prazo_vencido': len(projetos_nao_concluidos[prazo_vencido]),
                    'por_squad': projetos_criticos.groupby('Squad').size().to_dict()
                }
            }
            
        except Exception as e:
            logger.error(f"Erro ao calcular projetos cr√≠ticos: {str(e)}", exc_info=True)
            return {'total': 0, 'dados': pd.DataFrame(), 'metricas': {}}

    def calcular_projetos_concluidos(self, dados):
        """
        Calcula m√©tricas para projetos conclu√≠dos no m√™s atual.
        Retorna:
        - total: n√∫mero total de projetos conclu√≠dos no m√™s
        - dados: DataFrame com os projetos conclu√≠dos
        - metricas: m√©tricas espec√≠ficas dos projetos conclu√≠dos
        """
        try:
            logger.info("Calculando projetos conclu√≠dos do m√™s atual...")
            
            # Obt√©m o m√™s e ano atual
            hoje = datetime.now()
            mes_atual = hoje.month
            ano_atual = hoje.year
            
            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)
            
            # Filtra projetos conclu√≠dos (sem filtro de Squad para debug)
            projetos_concluidos = dados_base[
                (dados_base['Status'].isin(self.status_concluidos)) &
                (pd.to_datetime(dados_base['DataTermino'], format='%d/%m/%Y %H:%M', errors='coerce').dt.month == mes_atual) &
                (pd.to_datetime(dados_base['DataTermino'], format='%d/%m/%Y %H:%M', errors='coerce').dt.year == ano_atual)
            ].copy()
            
            # Log para debug
            logger.debug(f"Projetos conclu√≠dos filtrados (sem CDB): {len(projetos_concluidos)}")
            
            # Calcula m√©tricas
            total_concluidos = len(projetos_concluidos)
            if total_concluidos > 0:
                media_conclusao = projetos_concluidos['Conclusao'].mean()
                media_horas = projetos_concluidos['HorasTrabalhadas'].mean()
                projetos_por_squad = projetos_concluidos.groupby('Squad').size().to_dict()
            else:
                media_conclusao = 0
                media_horas = 0
                projetos_por_squad = {}
            
            # Adiciona verifica√ß√£o de backlog usando a fun√ß√£o auxiliar
            projetos_concluidos = self._adicionar_verificacao_backlog(projetos_concluidos)
            
            # Prepara dados para o modal - INCLUINDO TODAS AS COLUNAS NECESS√ÅRIAS
            colunas_necessarias = ['Numero', 'Projeto', 'Status', 'Squad', 'Horas', 'HorasTrabalhadas', 'HorasRestantes', 'VencimentoEm', 'DataTermino', 'backlog_exists']
            
            # Adiciona colunas importantes que podem existir nos dados
            colunas_opcionais = ['Especialista', 'Account Manager', 'TipoServico', 'Faturamento', 'Conclusao']
            for col in colunas_opcionais:
                if col in projetos_concluidos.columns:
                    colunas_necessarias.append(col)
            
            dados_modal = projetos_concluidos[colunas_necessarias].copy()
            
            # Renomeia colunas para o formato esperado pelo frontend
            mapeamento_colunas = {
                'Numero': 'numero',
                'Projeto': 'projeto',
                'Status': 'status',
                'Squad': 'squad',
                'Horas': 'horasContratadas',
                'HorasTrabalhadas': 'horasTrabalhadas',
                'HorasRestantes': 'horasRestantes',
                'VencimentoEm': 'dataPrevEnc',
                'DataTermino': 'dataTermino',
                'backlog_exists': 'backlog_exists',  # Mant√©m o nome
                'Especialista': 'especialista',
                'Account Manager': 'account',
                'TipoServico': 'servico',
                'Faturamento': 'tipo_faturamento',
                'Conclusao': 'conclusao'
            }
            
            # Aplica apenas os mapeamentos para colunas que existem
            mapeamento_existente = {k: v for k, v in mapeamento_colunas.items() if k in dados_modal.columns}
            dados_modal = dados_modal.rename(columns=mapeamento_existente)
            
            # Adiciona colunas que podem estar faltando com valores padr√£o
            if 'especialista' not in dados_modal.columns:
                dados_modal['especialista'] = '-'
            if 'account' not in dados_modal.columns:
                dados_modal['account'] = '-'
            if 'servico' not in dados_modal.columns:
                dados_modal['servico'] = '-'
            if 'tipo_faturamento' not in dados_modal.columns:
                dados_modal['tipo_faturamento'] = '-'
            if 'conclusao' not in dados_modal.columns:
                dados_modal['conclusao'] = 0
            
            # Padroniza valores vazios ou N/A para "-"
            colunas_texto = ['especialista', 'account', 'servico', 'tipo_faturamento']
            for col in colunas_texto:
                if col in dados_modal.columns:
                    dados_modal[col] = dados_modal[col].fillna('-')
                    dados_modal[col] = dados_modal[col].replace(['N/A', 'N√ÉO DEFINIDO', 'N√ÉO ALOCADO', ''], '-')
            
            # Formata√ß√£o de horas igual ao Relat√≥rio Geral (duas casas decimais)
            dados_modal['horasContratadas'] = pd.to_numeric(dados_modal['horasContratadas'], errors='coerce').fillna(0).round(2)
            dados_modal['horasTrabalhadas'] = pd.to_numeric(dados_modal['horasTrabalhadas'], errors='coerce').fillna(0).round(2)
            dados_modal['horasRestantes'] = pd.to_numeric(dados_modal['horasRestantes'], errors='coerce').fillna(0).round(2)
            
            # Formata√ß√£o de datas igual ao Relat√≥rio Geral (sem timestamp/timezone)
            dados_modal['dataTermino'] = pd.to_datetime(dados_modal['dataTermino'], errors='coerce').dt.strftime('%d/%m/%Y')
            dados_modal['dataTermino'] = dados_modal['dataTermino'].replace('NaT', None)
            
            dados_modal['dataPrevEnc'] = pd.to_datetime(dados_modal['dataPrevEnc'], errors='coerce').dt.strftime('%d/%m/%Y')
            dados_modal['dataPrevEnc'] = dados_modal['dataPrevEnc'].replace('NaT', None)
            
            # Calcula m√©tricas adicionais
            metricas = {
                'media_conclusao': round(media_conclusao, 1),
                'media_horas': round(media_horas, 1),
                'total_projetos': total_concluidos,
                'projetos_por_squad': projetos_por_squad
            }
            
            logger.info(f"Total de projetos conclu√≠dos no m√™s: {total_concluidos}")
            
            return {
                'total': total_concluidos,
                'dados': dados_modal.replace({np.nan: None}),
                'metricas': metricas
            }
            
        except Exception as e:
            logger.error(f"Erro ao calcular projetos conclu√≠dos: {str(e)}", exc_info=True)
            return {'total': 0, 'dados': pd.DataFrame(), 'metricas': {}}

    def calcular_projetos_risco(self, dados):
        """
        Calcula projetos em risco com base em crit√©rios preventivos:
        1. Menos de 20% das horas totais restantes
        2. Prazo pr√≥ximo (15 dias) com conclus√£o menor que 70%
        3. M√©dia de horas/dia at√© o prazo muito baixa (menos de 1 hora/dia)
        """
        try:
            hoje = pd.Timestamp(datetime.now().replace(hour=0, minute=0, second=0, microsecond=0))
            dados_base = self.preparar_dados_base(dados)
            projetos_risco = pd.DataFrame()
            
            logger.debug(f"Iniciando c√°lculo de projetos em risco. Total de projetos: {len(dados_base)}")
            
            # Filtra apenas projetos n√£o conclu√≠dos e n√£o cr√≠ticos
            projetos_nao_concluidos = dados_base[
                ~dados_base['Status'].isin(self.status_concluidos) &
                ~dados_base['Status'].isin(['BLOQUEADO']) &
                (dados_base['Status'] != 'AGUARDANDO') & # <-- NOVA CONDI√á√ÉO: Status n√£o pode ser AGUARDANDO
                (dados_base['HorasRestantes'] >= 0)
            ]
            
            # Normaliza as datas
            projetos_nao_concluidos['VencimentoEm'] = pd.to_datetime(projetos_nao_concluidos['VencimentoEm']).dt.normalize()
            
            # Lista para armazenar as condi√ß√µes
            condicoes = []
            
            # 1. Horas restantes cr√≠ticas (menos de 20% das horas totais)
            if 'HorasRestantes' in dados_base.columns and 'Horas' in dados_base.columns:
                horas_criticas = (
                    (projetos_nao_concluidos['Horas'] > 0) & 
                    (projetos_nao_concluidos['HorasRestantes'] / projetos_nao_concluidos['Horas'] < 0.2) &
                    (projetos_nao_concluidos['HorasRestantes'] > 0)
                )
                condicoes.append(horas_criticas)
                logger.debug(f"Projetos com menos de 20% das horas: {len(projetos_nao_concluidos[horas_criticas])}")
            
            # 2. Projetos pr√≥ximos ao prazo com conclus√£o preocupante
            if 'VencimentoEm' in dados_base.columns and 'Conclusao' in dados_base.columns:
                try:
                    dias_ate_termino = (projetos_nao_concluidos['VencimentoEm'] - hoje).dt.days
                    prazo_conclusao = (
                        (projetos_nao_concluidos['VencimentoEm'].notna()) &
                        (dias_ate_termino > 0) &  # Garante que n√£o est√° vencido
                        (dias_ate_termino <= 15) &  # Pr√≥ximo do prazo (15 dias)
                        (projetos_nao_concluidos['Conclusao'] < 70)  # Conclus√£o menor que 70%
                    )
                    condicoes.append(prazo_conclusao)
                    logger.debug(f"Projetos pr√≥ximos ao prazo com conclus√£o preocupante: {len(projetos_nao_concluidos[prazo_conclusao])}")
                except Exception as e:
                    logger.error(f"Erro ao calcular projetos pr√≥ximos ao prazo: {str(e)}")
            
            # 3. Horas restantes baixas em rela√ß√£o ao prazo
            if 'HorasRestantes' in dados_base.columns and 'VencimentoEm' in dados_base.columns and 'Horas' in dados_base.columns: # Adicionado 'Horas' in dados_base.columns
                try:
                    dias_ate_termino = (projetos_nao_concluidos['VencimentoEm'] - hoje).dt.days
                    horas_por_dia = projetos_nao_concluidos['HorasRestantes'] / dias_ate_termino.clip(lower=1)
                    horas_criticas_prazo = (
                        (projetos_nao_concluidos['Horas'] >= 30) &  # <-- M√≠nimo de 30h totais
                        (projetos_nao_concluidos['Status'] != 'AGUARDANDO') & # <-- NOVA CONDI√á√ÉO: Status n√£o pode ser AGUARDANDO
                        (dias_ate_termino > 0) &  # Garante que n√£o est√° vencido
                        (horas_por_dia < 1)  # Menos de 1 hora por dia at√© o prazo
                    )
                    condicoes.append(horas_criticas_prazo)
                    logger.debug(f"Projetos com poucas horas por dia at√© o prazo (e >= 30h totais e n√£o AGUARDANDO): {len(projetos_nao_concluidos[horas_criticas_prazo])}")
                except Exception as e:
                    logger.error(f"Erro ao calcular horas por dia at√© o prazo: {str(e)}")
            
            # Combina todas as condi√ß√µes com OR l√≥gico
            if condicoes:
                mascara_risco = np.logical_or.reduce(condicoes)
                projetos_risco = projetos_nao_concluidos[mascara_risco].copy()
                
                # Inicializa a coluna motivo_risco
                projetos_risco.loc[:, 'motivo_risco'] = ''
                
                # Adiciona os motivos espec√≠ficos
                if 'HorasRestantes' in dados_base.columns and 'Horas' in dados_base.columns:
                    mascara_horas = (
                        (projetos_risco['Horas'] > 0) & 
                        (projetos_risco['HorasRestantes'] / projetos_risco['Horas'] < 0.2) & 
                        (projetos_risco['HorasRestantes'] > 0)
                    )
                    projetos_risco.loc[mascara_horas, 'motivo_risco'] += 'Restam menos de 20% das horas totais; '
                
                if 'VencimentoEm' in dados_base.columns and 'Conclusao' in dados_base.columns:
                    dias_ate_termino = (projetos_risco['VencimentoEm'] - hoje).dt.days
                    mascara_prazo = (
                        (dias_ate_termino > 0) &
                        (dias_ate_termino <= 15) &
                        (projetos_risco['Conclusao'] < 70)
                    )
                    projetos_risco.loc[mascara_prazo, 'motivo_risco'] += 'Prazo pr√≥ximo (15 dias) com conclus√£o abaixo de 70%; '
                
                if 'HorasRestantes' in dados_base.columns and 'VencimentoEm' in dados_base.columns and 'Horas' in dados_base.columns: # Adicionado 'Horas' in dados_base.columns
                    dias_ate_termino = (projetos_risco['VencimentoEm'] - hoje).dt.days
                    horas_por_dia = projetos_risco['HorasRestantes'] / dias_ate_termino.clip(lower=1)
                    mascara_horas_dia = (
                        (projetos_risco['Horas'] >= 30) & # <-- M√≠nimo de 30h totais
                        (projetos_risco['Status'] != 'AGUARDANDO') & # <-- NOVA CONDI√á√ÉO: Status n√£o pode ser AGUARDANDO
                        (dias_ate_termino > 0) &
                        (horas_por_dia < 1)
                    )
                    projetos_risco.loc[mascara_horas_dia, 'motivo_risco'] += 'M√©dia de horas/dia at√© o prazo muito baixa; '
                
                # Remove o √∫ltimo '; ' do motivo
                projetos_risco['motivo_risco'] = projetos_risco['motivo_risco'].str.rstrip('; ')
                
                # Formata a data de vencimento para exibi√ß√£o
                projetos_risco['DataTermino'] = projetos_risco['VencimentoEm'].dt.strftime('%d/%m/%Y')
                projetos_risco['DataTermino'] = projetos_risco['DataTermino'].fillna('N/A')
                
                logger.info(f"Total de projetos em risco identificados: {len(projetos_risco)}")
                
                # Log para debug das datas
                for idx, row in projetos_risco.iterrows():
                    logger.debug(
                        f"Projeto em risco: {row['Projeto']}, "
                        f"Data Vencimento: {row['VencimentoEm'].strftime('%d/%m/%Y') if pd.notna(row['VencimentoEm']) else 'N/A'}, "
                        f"Data exibi√ß√£o: {row['DataTermino']}"
                    )
                
                return projetos_risco
            else:
                logger.warning("Nenhuma condi√ß√£o de risco foi aplicada")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"Erro ao calcular projetos em risco: {str(e)}", exc_info=True)
            return pd.DataFrame()

    def preparar_dados_base(self, dados):
        """
        Prepara os dados base que ser√£o usados por todas as fun√ß√µes de KPI.
        Faz as convers√µes e limpezas necess√°rias uma √∫nica vez.
        """
        try:
            dados_base = dados.copy()
            
            # Converte datas
            for col in ['DataInicio', 'DataTermino', 'VencimentoEm']:
                if col in dados_base.columns:
                    dados_base[col] = pd.to_datetime(dados_base[col], errors='coerce')
            
            # Garante tipos num√©ricos
            for col in ['Horas', 'HorasTrabalhadas', 'HorasRestantes', 'Conclusao']:
                if col in dados_base.columns:
                    dados_base[col] = pd.to_numeric(dados_base[col], errors='coerce').fillna(0.0)
            
            # Padroniza strings
            for col in ['Status', 'Squad', 'Especialista', 'Account Manager']:
                if col in dados_base.columns:
                    dados_base[col] = dados_base[col].str.strip().str.upper()
                    if col == 'Especialista':
                        dados_base[col] = dados_base[col].fillna('N√ÉO ALOCADO')
                    elif col == 'Account Manager':
                        dados_base[col] = dados_base[col].fillna('N√ÉO DEFINIDO')
                    else:
                        dados_base[col] = dados_base[col].fillna('N√ÉO DEFINIDO')
                elif col == 'Account Manager':
                    dados_base[col] = 'N√ÉO DEFINIDO'  # Garante que a coluna Account Manager sempre existe
            
            # Calcula tempo de vida do projeto (em dias)
            if 'DataInicio' in dados_base.columns:
                hoje = datetime.now()
                dados_base['TempoVida'] = (hoje - dados_base['DataInicio']).dt.days.fillna(0).astype(int)
            else:
                dados_base['TempoVida'] = 0
            
            logger.debug(f"Dados base preparados. Colunas: {dados_base.columns.tolist()}")
            logger.debug(f"Account Managers ap√≥s prepara√ß√£o: {dados_base['Account Manager'].unique().tolist() if 'Account Manager' in dados_base.columns else 'Coluna n√£o existe'}")
            
            return dados_base
        except Exception as e:
            logger.error(f"Erro ao preparar dados base: {str(e)}", exc_info=True)
            return dados.copy()

    def calcular_media_horas(self, dados):
        """
        Calcula a m√©dia de horas dos projetos ativos.
        Retorna apenas a m√©dia geral para exibi√ß√£o no card.
        """
        try:
            logger.info("Calculando m√©dia de horas...")
            
            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)
            
            # Filtra apenas projetos n√£o conclu√≠dos
            projetos_nao_concluidos = dados_base[~dados_base['Status'].isin(self.status_concluidos)]
            
            # Calcula apenas a m√©dia geral
            media_geral = round(projetos_nao_concluidos['Horas'].mean(), 1)
            
            logger.info(f"M√©dia de horas calculada: {media_geral}")
            
            return {
                'total': media_geral,  # para manter consist√™ncia com outros KPIs
                'metricas': {
                    'media_geral': media_geral,
                    'media_por_squad': projetos_nao_concluidos.groupby('Squad')['Horas'].mean().round(1).to_dict()
                }
            }
            
        except Exception as e:
            logger.error(f"Erro ao calcular m√©dia de horas: {str(e)}", exc_info=True)
            return {'total': 0.0, 'metricas': {'media_geral': 0.0, 'media_por_squad': {}}}

    def calcular_eficiencia_entrega(self, dados):
        """
        Calcula a efici√™ncia geral dos projetos usando a mesma metodologia do Status Report por Per√≠odo.
        F√≥rmula composta: 70% efici√™ncia de horas + 30% efici√™ncia de prazo
        
        Retorna:
        - total: efici√™ncia geral (porcentagem)
        - dados: DataFrame com os projetos e suas efici√™ncias
        - metricas: m√©tricas espec√≠ficas de efici√™ncia
        """
        try:
            logger.info("Calculando efici√™ncia...")
            
            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)

            # --- Filtra projetos da CDB DATA SOLUTIONS ---
            if 'Especialista' in dados_base.columns:
                dados_filtrados_cdb = dados_base[~dados_base['Especialista'].astype(str).str.upper().isin(['CDB DATA SOLUTIONS'])]
                logger.info(f"Efici√™ncia: Removidos {len(dados_base) - len(dados_filtrados_cdb)} projetos da CDB DATA SOLUTIONS.")
            else:
                logger.warning("Efici√™ncia: Coluna 'Especialista' n√£o encontrada para filtrar CDB.")
                dados_filtrados_cdb = dados_base.copy()

            # === 1. EFICI√äNCIA DE HORAS (Fechados + Em Andamento) ===
            # Inclui projetos fechados e em andamento para an√°lise mais abrangente
            projetos_para_eficiencia = dados_filtrados_cdb[
                dados_filtrados_cdb['Status'].isin(self.status_concluidos + ['NOVO', 'EM ATENDIMENTO', 'AGUARDANDO', 'BLOQUEADO'])
            ].copy()
            
            logger.info(f"Efici√™ncia: Analisando {len(projetos_para_eficiencia)} projetos (fechados + em andamento).")

            # Filtra projetos com horas v√°lidas
            projetos_com_horas = projetos_para_eficiencia[
                (projetos_para_eficiencia['Horas'].fillna(0) > 0) &
                (projetos_para_eficiencia['HorasTrabalhadas'].fillna(0) > 0)
            ].copy()

            eficiencia_horas = 0.0
            if len(projetos_com_horas) > 0:
                horas_estimadas_total = projetos_com_horas['Horas'].sum()
                horas_trabalhadas_total = projetos_com_horas['HorasTrabalhadas'].sum()
                
                if horas_estimadas_total > 0 and horas_trabalhadas_total > 0:
                    # F√ìRMULA INVERTIDA: (Horas Estimadas / Horas Trabalhadas) √ó 100
                    # Maior = melhor (120% = 20% mais eficiente que estimado)
                    eficiencia_horas = round((horas_estimadas_total / horas_trabalhadas_total * 100), 1)
                    
                    # Aplica limite m√°ximo para evitar valores extremos
                    eficiencia_horas = min(eficiencia_horas, 200.0)

            # Calcula efici√™ncia individual dos projetos com horas (para o modal)
            if len(projetos_com_horas) > 0:
                projetos_com_horas['eficiencia_horas'] = (projetos_com_horas['Horas'] / projetos_com_horas['HorasTrabalhadas'] * 100).round(1)
                # Aplica limite nos projetos individuais tamb√©m
                projetos_com_horas['eficiencia_horas'] = projetos_com_horas['eficiencia_horas'].clip(upper=200.0)

            # === 2. EFICI√äNCIA DE PRAZO (Fechados + Em Andamento) ===
            eficiencia_prazo = 0.0
            projetos_no_prazo = 0
            projetos_com_prazo = 0

            # Mapeia colunas se necess√°rio
            if 'Resolvido em' in projetos_para_eficiencia.columns:
                projetos_para_eficiencia['DataTermino'] = projetos_para_eficiencia['Resolvido em']
            if 'Vencimento em' in projetos_para_eficiencia.columns:
                projetos_para_eficiencia['VencimentoEm'] = projetos_para_eficiencia['Vencimento em']

            # Para projetos EM ANDAMENTO, usa data atual como "data de an√°lise"
            from datetime import datetime
            data_atual = datetime.now()
            projetos_para_eficiencia['DataAnalise'] = projetos_para_eficiencia['DataTermino'].fillna(data_atual)

            # Filtra projetos com datas v√°lidas para an√°lise de prazo
            projetos_com_datas = projetos_para_eficiencia[
                projetos_para_eficiencia['VencimentoEm'].notna() & 
                (projetos_para_eficiencia['VencimentoEm'] != '')
            ].copy()

            if len(projetos_com_datas) > 0:
                try:
                    # Converte datas
                    projetos_com_datas['VencimentoEm'] = pd.to_datetime(
                        projetos_com_datas['VencimentoEm'], 
                        errors='coerce', 
                        dayfirst=True
                    )
                    projetos_com_datas['DataAnalise'] = pd.to_datetime(
                        projetos_com_datas['DataAnalise'], 
                        errors='coerce'
                    )
                    
                    # Remove projetos com datas inv√°lidas
                    validos_para_prazo = projetos_com_datas.dropna(subset=['VencimentoEm', 'DataAnalise']).copy()
                    
                    if not validos_para_prazo.empty:
                        # Aplica l√≥gica de prazo (mesma do Status Report)
                        for _, projeto in validos_para_prazo.iterrows():
                            data_analise = projeto['DataAnalise']
                            data_vencimento = projeto['VencimentoEm']
                            
                            # In√≠cio do m√™s de an√°lise
                            inicio_mes_analise = datetime(data_analise.year, data_analise.month, 1)
                            inicio_mes_analise = pd.Timestamp(inicio_mes_analise).normalize()
                            
                            # Projeto no prazo se VencimentoEm >= in√≠cio do m√™s de an√°lise
                            if data_vencimento.normalize() >= inicio_mes_analise:
                                projetos_no_prazo += 1
                        
                        projetos_com_prazo = len(validos_para_prazo)
                        eficiencia_prazo = round((projetos_no_prazo / projetos_com_prazo) * 100, 1)
                        
                except Exception as e:
                    logger.warning(f"Erro ao processar datas para efici√™ncia de prazo: {str(e)}")
                    eficiencia_prazo = 0.0

            # === 3. EFICI√äNCIA COMPOSTA (70% Horas + 30% Prazo) ===
            peso_horas = 0.7  # 70% para efici√™ncia de horas
            peso_prazo = 0.3  # 30% para efici√™ncia de prazo
            
            eficiencia_composta = round(
                (eficiencia_horas * peso_horas) + (eficiencia_prazo * peso_prazo), 1
            )

            # === 4. PREPARA DADOS PARA O MODAL ===
            # Usa projetos com horas v√°lidas para exibir no modal
            dados_modal = pd.DataFrame()
            if len(projetos_com_horas) > 0:
                # Adiciona verifica√ß√£o de backlog
                projetos_com_horas = self._adicionar_verificacao_backlog(projetos_com_horas)

                # Prepara colunas do modal
                colunas_modal = ['Numero', 'Projeto', 'Status', 'Squad', 'Horas', 'HorasTrabalhadas', 'eficiencia_horas', 'backlog_exists']
                
                # Certifica-se de que a coluna Numero existe
                if 'Numero' not in projetos_com_horas.columns and 'N√∫mero' in projetos_com_horas.columns:
                    projetos_com_horas['Numero'] = projetos_com_horas['N√∫mero']
                elif 'Numero' not in projetos_com_horas.columns:
                    projetos_com_horas['Numero'] = ''
                    
                # Seleciona apenas as colunas que existem
                colunas_existentes = [col for col in colunas_modal if col in projetos_com_horas.columns]
                dados_modal = projetos_com_horas[colunas_existentes].copy()
                
                # Renomeia colunas para o formato esperado pelo frontend
                dados_modal = dados_modal.rename(columns={
                    'Numero': 'numero',
                    'Projeto': 'projeto',
                    'Status': 'status',
                    'Squad': 'squad',
                    'Horas': 'horasContratadas',
                    'HorasTrabalhadas': 'horasTrabalhadas',
                    'eficiencia_horas': 'eficiencia',
                    'backlog_exists': 'backlog_exists'
                })
                
                # Arredonda as horas para uma casa decimal
                dados_modal['horasContratadas'] = dados_modal['horasContratadas'].round(1)
                dados_modal['horasTrabalhadas'] = dados_modal['horasTrabalhadas'].round(1)

            # === 5. CALCULA M√âTRICAS ADICIONAIS ===
            metricas = {
                'eficiencia_geral': eficiencia_composta,
                'eficiencia_composta': eficiencia_composta,
                'eficiencia_horas': eficiencia_horas,
                'eficiencia_prazo': eficiencia_prazo,
                'total_projetos': len(projetos_com_horas),
                'projetos_analisados': len(projetos_para_eficiencia),
                'projetos_com_prazo': projetos_com_prazo,
                'projetos_no_prazo': projetos_no_prazo,
                'peso_horas': peso_horas,
                'peso_prazo': peso_prazo
            }
            
            # Calcula m√©tricas por squad se houver dados
            if len(projetos_com_horas) > 0:
                metricas['media_por_squad'] = projetos_com_horas.groupby('Squad')['eficiencia_horas'].mean().round(1).to_dict()
                metricas['projetos_acima_100'] = len(projetos_com_horas[projetos_com_horas['eficiencia_horas'] > 100])
                metricas['projetos_abaixo_80'] = len(projetos_com_horas[projetos_com_horas['eficiencia_horas'] < 80])
            else:
                metricas['media_por_squad'] = {}
                metricas['projetos_acima_100'] = 0
                metricas['projetos_abaixo_80'] = 0
            
            logger.info(f"Efici√™ncia calculada: {eficiencia_composta}% (Horas: {eficiencia_horas}%, Prazo: {eficiencia_prazo}%)")
            
            return {
                'total': eficiencia_composta,
                'dados': dados_modal.replace({np.nan: None}) if not dados_modal.empty else pd.DataFrame(),
                'metricas': metricas
            }
            
        except Exception as e:
            logger.error(f"Erro ao calcular efici√™ncia: {str(e)}", exc_info=True)
            return {'total': 0.0, 'dados': pd.DataFrame(), 'metricas': {}}

    def calcular_kpis(self, dados):
        """Calcula KPIs principais do dashboard"""
        try:
            if dados.empty:
                return self.criar_kpis_vazios()

            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)
            total_projetos = len(dados_base)
            
            # Usa fun√ß√µes espec√≠ficas para cada KPI
            projetos_ativos = self.calcular_projetos_ativos(dados_base)
            projetos_criticos = self.calcular_projetos_criticos(dados_base)
            media_horas = self.calcular_media_horas(dados_base)
            
            # Projetos conclu√≠dos
            projetos_concluidos = dados_base[dados_base['Status'].isin(self.status_concluidos)]
            projetos_concluidos_count = len(projetos_concluidos)

            # Efici√™ncia de entrega (usa o m√©todo espec√≠fico corrigido)
            eficiencia_entrega_result = self.calcular_eficiencia_entrega(dados_base)
            eficiencia = eficiencia_entrega_result['total']

            kpis = {
                'projetos_ativos': projetos_ativos['total'],
                'total_projetos': total_projetos,
                'projetos_criticos': projetos_criticos['total'],
                'projetos_concluidos': projetos_concluidos_count,
                'porcentagem_concluidos': round((projetos_concluidos_count / total_projetos * 100), 1) if total_projetos > 0 else 0,
                'media_horas_projeto': media_horas['total'],
                'eficiencia_entrega': eficiencia
            }

            logger.info(f"[DEBUG] KPIs calculados: {kpis}")
            return kpis

        except Exception as e:
            logger.exception(f"Erro ao calcular KPIs: {str(e)}")
            return self.criar_kpis_vazios()

    def criar_kpis_vazios(self):
        return {
            'projetos_ativos': 0, 'total_projetos': 0, 'projetos_criticos': 0,
            'projetos_concluidos': 0, 'porcentagem_concluidos': 0.0,
            'media_horas_projeto': 0.0, 'eficiencia_entrega': 0.0
        }

    def calcular_agregacoes(self, dados):
        """
        Calcula agrega√ß√µes gerais dos dados, incluindo:
        - Distribui√ß√£o por status
        - Agrega√ß√µes por squad
        - Projetos em risco
        
        Esta fun√ß√£o mant√©m compatibilidade com o dashboard original e a p√°gina de apresenta√ß√£o.
        """
        try:
            logger.info("Calculando agrega√ß√µes gerais...")
            
            # Estrutura b√°sica do resultado
            resultado = {
                'por_status': {},
                'por_squad': {},
                'projetos_risco': []
            }
            
            if dados.empty:
                logger.warning("DataFrame vazio ao calcular agrega√ß√µes")
                return resultado
            
            # Verifica√ß√£o de colunas essenciais
            if 'Status' not in dados.columns:
                logger.error("Coluna 'Status' n√£o encontrada nos dados")
                return resultado
                
            # Prepara c√≥pia de dados para evitar altera√ß√µes no original
            dados_temp = dados.copy()
            
            # Garante que Status seja string e mai√∫sculo
            dados_temp['Status'] = dados_temp['Status'].astype(str).str.strip().str.upper()
            
            # Log dos valores √∫nicos para debug
            status_unicos = dados_temp['Status'].unique().tolist()
            logger.info(f"Status √∫nicos encontrados: {status_unicos}")
            
            # Se as colunas num√©ricas n√£o existirem, cria com valores padr√£o
            for col, default in [('Horas', 0.0), ('HorasRestantes', 0.0), ('Conclusao', 0.0)]:
                if col not in dados_temp.columns:
                    logger.warning(f"Coluna '{col}' n√£o encontrada. Criando com valor padr√£o {default}")
                    dados_temp[col] = default
                else:
                    # Converte para num√©rico, tratando valores problem√°ticos
                    dados_temp[col] = pd.to_numeric(dados_temp[col], errors='coerce').fillna(default)
            
            # Obt√©m o m√™s e ano atual para filtrar projetos fechados
            hoje = datetime.now()
            mes_atual = hoje.month
            ano_atual = hoje.year
            
            # Define os status ativos e outros
            status_ativos = ['NOVO', 'EM ATENDIMENTO', 'AGUARDANDO', 'BLOQUEADO']
            status_concluidos = ['FECHADO', 'RESOLVIDO', 'ENCERRADO']
            
            # Filtra apenas projetos ativos
            dados_ativos = dados_temp[~dados_temp['Status'].isin(status_concluidos)].copy()
            
            # 1. Agrega√ß√µes por Status
            # ------------------------
            por_status = {}
            
            # Agrupa por status e calcula as m√©tricas
            # Modificado: Usar size() para contar linhas do grupo, mais robusto que contar n√£o-nulos em 'Projeto'
            contagem_status = dados_ativos.groupby('Status').size()
            
            # Calcular m√©tricas adicionais separadamente (se necess√°rio)
            soma_horas = dados_ativos.groupby('Status')['Horas'].sum()
            media_conclusao = dados_ativos.groupby('Status')['Conclusao'].mean()
            
            # Status que ser√£o ignorados no gr√°fico
            status_ignorados = ['ATRASADO', 'CANCELADO']
            logger.info(f"Status que ser√£o ignorados no gr√°fico: {status_ignorados}")
            
            # Itera sobre os status contados
            for status, quantidade in contagem_status.items(): 
                # Pula status que n√£o queremos exibir
                if status in status_ignorados:
                    logger.info(f"Ignorando status '{status}' conforme solicitado")
                    continue
                
                # Extrai valores garantindo que sejam v√°lidos e JSON-serializ√°veis
                horas_totais = float(soma_horas.get(status, 0.0))
                conclusao_media_raw = media_conclusao.get(status, 0.0)
                
                # üîß CORRE√á√ÉO: Trata valores NaN antes da serializa√ß√£o JSON
                if pd.isna(horas_totais):
                    horas_totais = 0.0
                if pd.isna(conclusao_media_raw):
                    conclusao_media_raw = 0.0
                
                conclusao_media = round(float(conclusao_media_raw), 1)
                
                # Define a cor baseada no status
                if status == 'NOVO':
                    cor = 'info'  # azul claro
                elif status == 'EM ATENDIMENTO':
                    cor = 'primary'  # azul
                elif status == 'AGUARDANDO':
                    cor = 'warning'  # amarelo
                elif status == 'BLOQUEADO':
                    cor = 'dark'     # preto
                else:
                    cor = 'secondary'  # cinza
                
                por_status[status] = {
                    'quantidade': int(quantidade),  # Garante que √© int
                    'horas_totais': round(horas_totais, 1),
                    'conclusao_media': conclusao_media,
                    'cor': cor,
                    'tipo': 'ativos' if status in status_ativos else 'outros'
                }
            
            # Garante que todos os status ativos existam, mesmo que vazios
            for status in status_ativos:
                if status not in por_status:
                    por_status[status] = {
                        'quantidade': 0,
                        'horas_totais': 0.0,
                        'conclusao_media': 0.0,
                        'cor': 'info' if status == 'NOVO' else ('primary' if status == 'EM ATENDIMENTO' else ('warning' if status == 'AGUARDANDO' else 'dark')),
                        'tipo': 'ativos'
                    }
            
            # Adiciona os projetos conclu√≠dos do m√™s atual
            if 'DataTermino' in dados_temp.columns:
                # Converte DataTermino para datetime se ainda n√£o for
                if not pd.api.types.is_datetime64_any_dtype(dados_temp['DataTermino']):
                    dados_temp['DataTermino'] = pd.to_datetime(dados_temp['DataTermino'], errors='coerce')
                
                # Filtra projetos conclu√≠dos do m√™s atual
                projetos_concluidos_mes = dados_temp[
                    (dados_temp['Status'].isin(status_concluidos)) &
                    (dados_temp['DataTermino'].dt.month == mes_atual) &
                    (dados_temp['DataTermino'].dt.year == ano_atual)
                ]
                
                if not projetos_concluidos_mes.empty:
                    quantidade_concluidos = len(projetos_concluidos_mes)
                    horas_concluidos = projetos_concluidos_mes['Horas'].sum()
                    conclusao_concluidos = projetos_concluidos_mes['Conclusao'].mean()
                    
                    # üîß CORRE√á√ÉO: Trata valores NaN para projetos conclu√≠dos
                    if pd.isna(horas_concluidos):
                        horas_concluidos = 0.0
                    if pd.isna(conclusao_concluidos):
                        conclusao_concluidos = 0.0
                    
                    por_status['FECHADO'] = {
                        'quantidade': quantidade_concluidos,
                        'horas_totais': round(float(horas_concluidos), 1),
                        'conclusao_media': round(float(conclusao_concluidos), 1),
                        'cor': 'success',
                        'tipo': 'outros'
                    }
            
            resultado['por_status'] = por_status
            
            # 2. Agrega√ß√µes por Squad
            # -----------------------
            if 'Squad' in dados_temp.columns:
                # Normaliza os nomes dos squads
                dados_temp['Squad'] = dados_temp['Squad'].str.upper()
                
                # Agrupa por squad e calcula as m√©tricas
                agregacao_squad = dados_ativos.groupby('Squad').agg({
                    'Projeto': 'count',    # quantidade
                    'Horas': 'sum',        # horas_totais
                    'Conclusao': 'mean'    # conclusao_media
                })
                
                por_squad = {}
                for squad, row in agregacao_squad.iterrows():
                    quantidade = int(row['Projeto']) if pd.notna(row['Projeto']) else 0
                    horas_totais = float(row['Horas']) if pd.notna(row['Horas']) else 0.0
                    conclusao_media = round(float(row['Conclusao']), 1) if pd.notna(row['Conclusao']) else 0.0
                    
                    por_squad[squad] = {
                        'quantidade': quantidade,
                        'horas_totais': round(horas_totais, 1),
                        'conclusao_media': conclusao_media
                    }
                
                resultado['por_squad'] = por_squad
            
            # 3. Projetos em Risco
            # --------------------
            projetos_risco_df = self.calcular_projetos_risco(dados_ativos)
            # üîß CORRE√á√ÉO: Substitui valores NaN por None antes da convers√£o para dict
            if not projetos_risco_df.empty:
                resultado['projetos_risco'] = projetos_risco_df.replace({np.nan: None}).to_dict('records')
            else:
                resultado['projetos_risco'] = []
            
            logger.info("Agrega√ß√µes calculadas com sucesso")
            return resultado
            
        except Exception as e:
            logger.error(f"Erro ao calcular agrega√ß√µes: {str(e)}", exc_info=True)
            return {
                'por_status': {},
                'por_squad': {},
                'projetos_risco': []
            }

    def calcular_historico_projetos(self, dados):
        """
        Calcula o hist√≥rico de projetos abertos e entregues nos √∫ltimos 4 meses.
        Retorna um dicion√°rio com as datas e contagens.
        """
        try:
            if dados.empty:
                logger.warning("DataFrame vazio ao calcular hist√≥rico de projetos.")
                return {
                    'datas': [],
                    'projetos_abertos': [],
                    'projetos_entregues': []
                }

            # Obt√©m a data atual
            data_atual = pd.Timestamp.now()
            # Calcula a data de 4 meses atr√°s
            data_inicio = data_atual - pd.DateOffset(months=4)
            
            # Cria um range de datas mensais
            datas = pd.date_range(start=data_inicio, end=data_atual, freq='M')
            
            # Inicializa listas para armazenar as contagens
            projetos_abertos = []
            projetos_entregues = []
            
            # Para cada m√™s no range
            for data in datas:
                # Projetos abertos no m√™s
                abertos = len(dados[
                    (dados['DataInicio'].dt.to_period('M') == data.to_period('M'))
                ])
                
                # Projetos entregues no m√™s
                entregues = len(dados[
                    (dados['DataTermino'].dt.to_period('M') == data.to_period('M')) &
                    (dados['Status'].isin(self.status_concluidos))
                ])
                
                projetos_abertos.append(abertos)
                projetos_entregues.append(entregues)
            
            logger.info(f"Hist√≥rico calculado para {len(datas)} meses")
            logger.debug(f"Projetos abertos: {projetos_abertos}")
            logger.debug(f"Projetos entregues: {projetos_entregues}")
            
            return {
                'datas': [d.strftime('%B/%Y') for d in datas],
                'projetos_abertos': projetos_abertos,
                'projetos_entregues': projetos_entregues
            }
            
        except Exception as e:
            logger.exception(f"Erro ao calcular hist√≥rico de projetos: {str(e)}")
            return {
                'datas': [],
                'projetos_abertos': [],
                'projetos_entregues': []
            }

    def calcular_alocacao_especialistas(self, dados):
        """Calcula a aloca√ß√£o detalhada por especialista, focando em projetos ativos."""
        try:
            if dados.empty:
                logger.warning("DataFrame vazio ao calcular aloca√ß√£o por especialistas.")
                return {}

            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)
            
            if 'Especialista' not in dados_base.columns:
                logger.warning("Coluna 'Especialista' n√£o encontrada nos dados.")
                return {}

            # Filtra para incluir apenas projetos N√ÉO CONCLU√çDOS
            dados_ativos = dados_base[~dados_base['Status'].isin(self.status_concluidos)].copy()
            logger.info(f"Filtrando especialistas: {len(dados_base)} linhas no total -> {len(dados_ativos)} linhas ativas consideradas.")

            # --- NOVO: Calcular o n√∫mero total de projetos ativos ---
            total_projetos_ativos_geral = len(dados_ativos)
            logger.info(f"N√∫mero total de projetos ativos (geral): {total_projetos_ativos_geral}")
            # ------------------------------------------------------

            # Garante que as colunas para agrega√ß√£o existem e s√£o num√©ricas nos dados ATIVOS
            colunas_numericas = ['Horas', 'HorasTrabalhadas', 'HorasRestantes']
            for col in colunas_numericas:
                if col in dados_ativos.columns:
                    if dados_ativos[col].dtype == 'object':
                         dados_ativos[col] = dados_ativos[col].astype(str).str.strip().str.replace(',', '.', regex=False)
                    dados_ativos[col] = pd.to_numeric(dados_ativos[col], errors='coerce').fillna(0.0)
                else:
                    logger.warning(f"Coluna num√©rica '{col}' n√£o encontrada nos dados ativos para c√°lculo de aloca√ß√£o. Usando 0.")
                    dados_ativos[col] = 0.0

            # Agrupa os dados J√Å FILTRADOS (ativos)
            agrupado = dados_ativos.groupby('Especialista', dropna=False)

            # Realiza as agrega√ß√µes necess√°rias
            sumario = agrupado.agg(
                # Conta os projetos ativos POR especialista
                total_projetos_especialista=('Projeto', 'count'),
                # Mant√©m as somas de horas para exibi√ß√£o na tabela
                total_horas_agregado=('Horas', 'sum'),
                horas_trabalhadas_agregado=('HorasTrabalhadas', 'sum'),
                horas_restantes_agregado=('HorasRestantes', 'sum')
            ).reset_index()

            # Calcula projetos bloqueados separadamente
            bloqueados = dados_ativos[dados_ativos['Status'] == 'BLOQUEADO'].groupby('Especialista').size()
            sumario = sumario.merge(bloqueados.rename('projetos_bloqueados'), on='Especialista', how='left')
            sumario['projetos_bloqueados'] = sumario['projetos_bloqueados'].fillna(0).astype(int)

            # Prepara o dicion√°rio final
            resultado_final = {}
            for index, row in sumario.iterrows():
                especialista = row['Especialista']
                if pd.isna(especialista):
                    especialista = 'N√£o Alocado'
                
                # N√∫mero de projetos ativos DESTE especialista
                projetos_ativos_esp = row['total_projetos_especialista']
                # Obt√©m os valores de horas agregados
                total_horas_esp = row['total_horas_agregado']
                horas_restantes_esp = row['horas_restantes_agregado']
                horas_trabalhadas_esp = row['horas_trabalhadas_agregado']
                projetos_bloqueados = row['projetos_bloqueados']

                # --- NOVO C√ÅLCULO DA TAXA DE USO (BASEADO EM PROJETOS) ---
                taxa_uso = 0.0
                # Evita divis√£o por zero se n√£o houver projetos ativos no total
                if total_projetos_ativos_geral > 0:
                    taxa_uso = (projetos_ativos_esp / total_projetos_ativos_geral) * 100
                    # üîß CORRE√á√ÉO: Trata valores NaN e garante arredondamento seguro
                    if pd.isna(taxa_uso):
                        taxa_uso = 0.0
                    else:
                        taxa_uso = round(float(taxa_uso), 1)
                # ---------------------------------------------------------

                # --- N√çVEL DE RISCO (AJUSTADO para taxa baseada em PROJETOS) ---
                nivel_risco = 'secondary' # Padr√£o para 'N√£o Alocado' ou sem projetos
                if especialista != 'N√£o Alocado' and projetos_ativos_esp > 0:
                    # Ajuste os limites percentuais conforme necess√°rio
                    if taxa_uso > 50: # Mais de 50% dos projetos ativos
                        nivel_risco = 'danger'
                    elif taxa_uso > 25: # Entre 25.1% e 50%
                        nivel_risco = 'warning'
                    else: # 25% ou menos
                        nivel_risco = 'success'
                # ----------------------------------------------------------

                # üîß CORRE√á√ÉO: Trata valores NaN para horas
                total_horas_safe = 0.0 if pd.isna(total_horas_esp) else float(total_horas_esp)
                horas_trabalhadas_safe = 0.0 if pd.isna(horas_trabalhadas_esp) else float(horas_trabalhadas_esp)
                horas_restantes_safe = 0.0 if pd.isna(horas_restantes_esp) else float(horas_restantes_esp)
                
                resultado_final[especialista] = {
                    # A chave 'total_projetos' agora reflete os projetos ativos do especialista
                    'total_projetos': int(projetos_ativos_esp),
                    # Mant√©m as colunas de horas como antes
                    'horas_contratadas': round(total_horas_safe, 1),
                    'horas_trabalhadas': round(horas_trabalhadas_safe, 1),
                    'horas_restantes': round(horas_restantes_safe, 1),
                    'projetos_bloqueados': int(projetos_bloqueados),
                    'taxa_uso': taxa_uso, # Nova taxa (baseada em projetos)
                    'nivel_risco': nivel_risco # Novo risco (baseado na taxa de projetos)
                }

            logger.info(f"Aloca√ß√£o por especialista (ativos) calculada para {len(resultado_final)} especialistas.")
            if resultado_final:
                 first_key = list(resultado_final.keys())[0]
                 logger.debug(f"Exemplo aloca√ß√£o ('{first_key}'): {resultado_final[first_key]}")
            return resultado_final

        except Exception as e:
            logger.exception(f"Erro ao calcular aloca√ß√£o por especialistas: {str(e)}")
            return {}

    def preparar_dados_abas(self, dados):
        """Prepara dados agregados para as diferentes abas do dashboard"""
        dados_abas_padrao = {'dados_status': [], 'dados_especialistas': {}, 'dados_accounts': []}
        if dados.empty:
            logger.warning("DataFrame vazio ao preparar dados para abas.")
            return dados_abas_padrao

        try:
            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)
            
            # --- Dados para aba de Status (usado no gr√°fico) ---
            # Reutiliza a agrega√ß√£o j√° feita
            agregacoes = self.calcular_agregacoes(dados_base)
            por_status_dict = agregacoes['por_status']
            # Converte para lista de dicion√°rios se necess√°rio para alguma tabela espec√≠fica
            dados_status_lista = [{'Status': k, **v} for k, v in por_status_dict.items()]

            # --- Dados para aba de Especialistas ---
            dados_especialistas = self.calcular_alocacao_especialistas(dados_base)
            # Log j√° est√° dentro da fun√ß√£o chamada

            # --- Dados para aba de Account Managers ---
            dados_accounts = []
            if 'Account Manager' in dados_base.columns:
                try:
                    # Status que indicam que o projeto n√£o est√° mais ativo
                    STATUS_NAO_ATIVOS = ['FECHADO', 'ENCERRADO', 'RESOLVIDO', 'CANCELADO']
                    
                    # Filtra apenas projetos ativos
                    dados_ativos = dados_base[~dados_base['Status'].str.upper().isin([s.upper() for s in STATUS_NAO_ATIVOS])]
                    
                    # Log para debug
                    logger.debug(f"Total de projetos ativos para Account Managers: {len(dados_ativos)}")
                    
                    # Garante que colunas usadas na agrega√ß√£o s√£o num√©ricas
                    for col in ['Horas', 'HorasRestantes', 'Conclusao']:
                        if col in dados_ativos.columns:
                            dados_ativos[col] = pd.to_numeric(dados_ativos[col], errors='coerce').fillna(0.0)

                    # Agrupa por Account Manager (incluindo 'N√£o Alocado')
                    accounts_agg = dados_ativos.groupby('Account Manager', dropna=False).agg(
                        total_projetos=('Projeto', 'count'),
                        horas_totais=('Horas', 'sum'),
                        horas_restantes=('HorasRestantes', 'sum'),
                        conclusao_media=('Conclusao', 'mean'),
                        projetos_bloqueados=('Status', lambda x: (x.str.upper() == 'BLOQUEADO').sum())
                    ).reset_index()

                    # Trata o caso de Account Manager ser NaN
                    accounts_agg['Account Manager'] = accounts_agg['Account Manager'].fillna('N√ÉO DEFINIDO')
                    
                    # Agrupa novamente se necess√°rio
                    if accounts_agg['Account Manager'].duplicated().any():
                        accounts_agg = accounts_agg.groupby('Account Manager').agg({
                            'total_projetos': 'sum',
                            'horas_totais': 'sum',
                            'horas_restantes': 'sum',
                            'conclusao_media': 'mean',
                            'projetos_bloqueados': 'sum'
                        }).reset_index()

                    # üîß CORRE√á√ÉO: Arredonda valores num√©ricos e trata NaN
                    for col in ['horas_totais', 'horas_restantes', 'conclusao_media']:
                        accounts_agg[col] = accounts_agg[col].fillna(0.0).round(1)

                    dados_accounts = accounts_agg.to_dict('records')
                    logger.debug(f"Dados para aba Account Managers preparados: {len(dados_accounts)} itens")
                    logger.debug(f"Account Managers encontrados: {accounts_agg['Account Manager'].tolist()}")
                except Exception as e:
                    logger.error(f"Erro ao preparar dados de Account Managers: {str(e)}")
                    dados_accounts = []
            else:
                logger.warning("Coluna 'Account Manager' n√£o encontrada para preparar dados da aba.")

            return {
                'dados_status': dados_status_lista, # Retorna a lista para consist√™ncia
                'dados_especialistas': dados_especialistas, # Dicion√°rio por especialista
                'dados_accounts': dados_accounts # Lista de dicion√°rios por account
            }

        except Exception as e:
            logger.exception(f"Erro ao preparar dados para abas: {str(e)}")
            return dados_abas_padrao

    def calcular_tempo_medio_vida(self, dados, mes_referencia=None):
        """
        Calcula o tempo m√©dio de vida dos projetos (em dias) conclu√≠dos
        em um m√™s espec√≠fico.
        
        Args:
            dados: DataFrame com os dados dos projetos.
            mes_referencia: Data (datetime) do m√™s para filtrar os projetos conclu√≠dos.
                          Se None, usa o m√™s atual.
                          
        Returns:
            Dictionary com:
            - media_dias: m√©dia de dias entre in√≠cio e t√©rmino dos projetos conclu√≠dos no m√™s
            - total_projetos: n√∫mero de projetos considerados no c√°lculo
            - distribuicao: distribui√ß√£o dos projetos por faixa de tempo
            - dados: lista detalhada dos projetos considerados
        """
        try:
            # Define o m√™s de refer√™ncia se n√£o informado
            if not mes_referencia:
                mes_referencia = datetime.now()
            
            logger.info(f"Calculando tempo m√©dio de vida para projetos conclu√≠dos em {mes_referencia.strftime('%m/%Y')}...")
            
            # Verifica se os dados s√£o v√°lidos
            if dados.empty:
                logger.warning("DataFrame vazio ao calcular tempo m√©dio de vida")
                return {
                    'media_dias': 0,
                    'total_projetos': 0,
                    'distribuicao': {},
                    'dados': []
                }
            
            # Obt√©m dados do trimestre atual (fiscal Microsoft)
            hoje = datetime.now()
            # Determina o trimestre fiscal da Microsoft (come√ßa em julho)
            mes_atual = hoje.month
            ano_atual = hoje.year
            
            # Determina o trimestre fiscal:
            # Q1: Jul-Sep, Q2: Oct-Dec, Q3: Jan-Mar, Q4: Apr-Jun
            if 7 <= mes_atual <= 9:
                quarter = "Q1"
                inicio_trimestre = datetime(ano_atual, 7, 1)
                fim_trimestre = datetime(ano_atual, 9, 30)
            elif 10 <= mes_atual <= 12:
                quarter = "Q2"
                inicio_trimestre = datetime(ano_atual, 10, 1)
                fim_trimestre = datetime(ano_atual, 12, 31)
            elif 1 <= mes_atual <= 3:
                quarter = "Q3"
                inicio_trimestre = datetime(ano_atual, 1, 1)
                fim_trimestre = datetime(ano_atual, 3, 31)
            else:  # 4-6
                quarter = "Q4"
                inicio_trimestre = datetime(ano_atual, 4, 1)
                fim_trimestre = datetime(ano_atual, 6, 30)
            
            # Filtra apenas projetos conclu√≠dos no trimestre atual
            dados_filtrados = dados.copy()
            
            # Normaliza Status para mai√∫sculo
            dados_filtrados['Status'] = dados_filtrados['Status'].str.upper()
            
            # Converte DataTermino e DataInicio para datetime
            dados_filtrados['DataTermino'] = pd.to_datetime(dados_filtrados['DataTermino'], errors='coerce')
            dados_filtrados['DataInicio'] = pd.to_datetime(dados_filtrados['DataInicio'], errors='coerce')
            
            # Calcula o primeiro e √∫ltimo dia do m√™s de refer√™ncia
            ano_ref = mes_referencia.year
            mes_ref = mes_referencia.month
            inicio_mes_ref = datetime(ano_ref, mes_ref, 1)
            # Calcula o √∫ltimo dia do m√™s
            if mes_ref == 12:
                proximo_mes_inicio = datetime(ano_ref + 1, 1, 1)
            else:
                proximo_mes_inicio = datetime(ano_ref, mes_ref + 1, 1)
            fim_mes_ref = proximo_mes_inicio - timedelta(days=1)
            # Define o fim do dia para incluir todo o √∫ltimo dia
            fim_mes_ref = fim_mes_ref.replace(hour=23, minute=59, second=59, microsecond=999999)

            logger.info(f"Per√≠odo de filtro para Tempo M√©dio Vida: {inicio_mes_ref.strftime('%Y-%m-%d')} a {fim_mes_ref.strftime('%Y-%m-%d')}")

            # --- IN√çCIO DA ALTERA√á√ÉO PARA PER√çODO M√ìVEL ---
            # Calcula o fim do per√≠odo (√∫ltimo dia do m√™s de refer√™ncia)
            ano_ref = mes_referencia.year
            mes_ref = mes_referencia.month
            # Calcula o √∫ltimo dia do m√™s de refer√™ncia
            if mes_ref == 12:
                proximo_mes_inicio = datetime(ano_ref + 1, 1, 1)
            else:
                proximo_mes_inicio = datetime(ano_ref, mes_ref + 1, 1)
            fim_periodo = proximo_mes_inicio - timedelta(days=1)
            # Define o fim do dia para incluir todo o √∫ltimo dia
            fim_periodo = fim_periodo.replace(hour=23, minute=59, second=59, microsecond=999999)

            # Calcula o in√≠cio do per√≠odo (3 meses atr√°s, incluindo o atual)
            # Subtrai 2 meses da data de refer√™ncia para obter o in√≠cio da janela de 3 meses
            inicio_periodo_dt = mes_referencia.replace(day=1) # Garante que estamos no dia 1
            for _ in range(2): # Subtrai um m√™s duas vezes
                primeiro_dia_mes_anterior = inicio_periodo_dt - timedelta(days=1)
                inicio_periodo_dt = primeiro_dia_mes_anterior.replace(day=1)
            
            inicio_periodo = inicio_periodo_dt
            # Define o in√≠cio do dia
            inicio_periodo = inicio_periodo.replace(hour=0, minute=0, second=0, microsecond=0)

            logger.info(f"Per√≠odo de filtro para Tempo M√©dio Vida (√∫ltimos 3 meses): {inicio_periodo.strftime('%Y-%m-%d')} a {fim_periodo.strftime('%Y-%m-%d')}")
            # --- FIM DA ALTERA√á√ÉO PARA PER√çODO M√ìVEL ---

            # Filtra apenas projetos conclu√≠dos no per√≠odo
            projetos_concluidos = dados_filtrados[
                (dados_filtrados['Status'].str.upper().isin(self.status_concluidos)) &
                (dados_filtrados['DataTermino'] >= inicio_periodo) &
                (dados_filtrados['DataTermino'] <= fim_periodo) &
                (dados_filtrados['DataInicio'].notna()) &
                (dados_filtrados['DataTermino'].notna())
            ].copy()

            logger.info(f"[Tempo M√©dio Vida - {mes_referencia.strftime('%m/%Y')} - √öltimos 3 meses] Projetos conclu√≠dos encontrados no per√≠odo: {len(projetos_concluidos)}") # Log ajustado

            # Log Adicionado: Verificar DataInicio e DataTermino dos projetos filtrados
            if not projetos_concluidos.empty:
                # Log detalhado do DataFrame filtrado
                logger.info(f"[Tempo M√©dio Vida - {mes_referencia.strftime('%m/%Y')}] DataFrame 'projetos_concluidos' ANTES do c√°lculo de tempo_vida:")
                try:
                    # Tenta logar como string para melhor visualiza√ß√£o
                    log_df_str = projetos_concluidos[['Projeto', 'Status', 'DataInicio', 'DataTermino']].to_string()
                    logger.info(f"\n{log_df_str}\n") 
                except Exception as log_err:
                    logger.error(f"Erro ao formatar DataFrame para log: {log_err}")
                    # Fallback para log b√°sico se to_string falhar
                    logger.info(projetos_concluidos[['Projeto', 'Status', 'DataInicio', 'DataTermino']].head())
                    
                # Verificar tipos das colunas de data DENTRO DESTE DATAFRAME FILTRADO
                if 'DataInicio' in projetos_concluidos.columns: logger.info(f"[Tempo M√©dio Vida - {mes_referencia.strftime('%m/%Y')}] Tipo DataInicio (filtrado): {projetos_concluidos['DataInicio'].dtype}")
                if 'DataTermino' in projetos_concluidos.columns: logger.info(f"[Tempo M√©dio Vida - {mes_referencia.strftime('%m/%Y')}] Tipo DataTermino (filtrado): {projetos_concluidos['DataTermino'].dtype}")
            
            if projetos_concluidos.empty:
                logger.warning("Nenhum projeto conclu√≠do neste m√™s para c√°lculo do tempo m√©dio de vida")
                return {
                    'media_dias': 0,
                    'total_projetos': 0,
                    'distribuicao': {},
                    'dados': []
                }

            # Calcula a diferen√ßa em dias
            projetos_concluidos['tempo_vida'] = (
                projetos_concluidos['DataTermino'] - projetos_concluidos['DataInicio']
            ).dt.days

            # Log das dura√ß√µes calculadas ANTES de filtrar outliers
            logger.debug(f"  Dura√ß√µes calculadas (tempo_vida) antes de filtrar outliers:\n{projetos_concluidos[['Projeto', 'tempo_vida']]}") # Log Adicionado

            # Remove outliers (dura√ß√£o negativa ou maior que 365 dias)
            projetos_validos = projetos_concluidos[
                (projetos_concluidos['tempo_vida'] >= 0) &
                (projetos_concluidos['tempo_vida'] <= 365)
            ]

            logger.info(f"  Projetos v√°lidos ap√≥s filtrar outliers (<0 ou >365 dias): {len(projetos_validos)}") # Log Adicionado

            if projetos_validos.empty:
                logger.warning("Nenhum projeto v√°lido ap√≥s filtragem para c√°lculo do tempo m√©dio de vida")
                return {
                    'media_dias': 0,
                    'total_projetos': 0,
                    'distribuicao': {},
                    'dados': []
                }

            # Calcula a m√©dia
            media_dias = round(projetos_validos['tempo_vida'].mean(), 1)

            # Cria faixas de tempo para distribui√ß√£o
            def categorizar_tempo(dias):
                if dias <= 30:
                    return 'At√© 30 dias'
                elif dias <= 90:
                    return '31 a 90 dias'
                elif dias <= 180:
                    return '91 a 180 dias'
                else:
                    return 'Mais de 180 dias'

            projetos_validos['faixa_tempo'] = projetos_validos['tempo_vida'].apply(categorizar_tempo)
            distribuicao = projetos_validos['faixa_tempo'].value_counts().to_dict()

            # Prepara dados detalhados para visualiza√ß√£o
            dados_detalhados = projetos_validos[['Projeto', 'DataInicio', 'DataTermino', 'tempo_vida', 'Squad']].copy()
            dados_detalhados = dados_detalhados.sort_values('tempo_vida', ascending=False)

            logger.info(f"Tempo m√©dio de vida calculado: {media_dias} dias, baseado em {len(projetos_validos)} projetos")
            logger.info(f"Distribui√ß√£o por faixa: {distribuicao}")

            return {
                'media_dias': media_dias,
                'total_projetos': len(projetos_validos),
                'distribuicao': distribuicao,
                'dados': dados_detalhados.to_dict('records')
            }

        except Exception as e:
            logger.error(f"Erro ao calcular tempo m√©dio de vida dos projetos: {str(e)}")
            return {
                'media_dias': 0,
                'total_projetos': 0,
                'distribuicao': {},
                'dados': []
            }

    def calcular_ocupacao_squads(self, dados):
        """
        Calcula a ocupa√ß√£o por squad, incluindo horas restantes e percentual de ocupa√ß√£o.
        Retorna uma lista de dicion√°rios com informa√ß√µes de cada squad.
        """
        try:
            logger.info("Calculando ocupa√ß√£o por squad...")
            
            # Configura√ß√µes de capacidade por squad (igual ao Gerencial)
            HORAS_POR_PESSOA = 180  # horas/m√™s
            PESSOAS_POR_SQUAD = 3   # pessoas por squad
            CAPACIDADE_TOTAL = HORAS_POR_PESSOA * PESSOAS_POR_SQUAD  # 540 horas por squad
            
            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)
            
            # Primeiro filtramos especialistas da CDB DATA SOLUTIONS (antes de qualquer outro filtro)
            # Isso garante que n√£o inclu√≠mos projetos da CDB DATA SOLUTIONS no c√°lculo
            if 'Especialista' in dados_base.columns:
                dados_base = dados_base[dados_base['Especialista'] != 'CDB DATA SOLUTIONS']
            
            # Filtra apenas projetos ativos e exclui o Squad CDB DATA SOLUTIONS tamb√©m
            projetos_ativos = dados_base[
                (~dados_base['Status'].isin(self.status_concluidos)) &
                (dados_base['Squad'] != 'CDB DATA SOLUTIONS')
            ].copy()
            
            # Adiciona logs detalhados para depura√ß√£o, especialmente para DATA E POWER
            data_power_projetos = projetos_ativos[projetos_ativos['Squad'] == 'DATA E POWER']
            if not data_power_projetos.empty:
                logger.info(f"Encontrados {len(data_power_projetos)} projetos para o squad DATA E POWER:")
                for _, projeto in data_power_projetos.iterrows():
                    logger.info(f"  Projeto: {projeto.get('Projeto', 'N/A')}")
                    logger.info(f"    Status: {projeto.get('Status', 'N/A')}")
                    logger.info(f"    Horas Originais: {projeto.get('Horas', 0.0)}")
                    logger.info(f"    Horas Trabalhadas: {projeto.get('HorasTrabalhadas', 0.0)}")
                    logger.info(f"    Horas Restantes: {projeto.get('HorasRestantes', 0.0)}")
            
            # Ajusta horas restantes: para negativas, usa 10% do esfor√ßo inicial (igual ao Gerencial)
            # Melhorado para garantir exatamente 10% e logging detalhado
            def ajustar_horas_restantes(row):
                if row['HorasRestantes'] >= 0:
                    return row['HorasRestantes']
                else:
                    valor_ajustado = 0.10 * row['Horas']
                    if row['Squad'] == 'DATA E POWER':
                        logger.info(f"  Ajustando projeto {row.get('Projeto', 'N/A')}: "
                                  f"Horas Restantes: {row['HorasRestantes']} -> "
                                  f"Ajustado (10% de {row['Horas']}): {valor_ajustado}")
                    return valor_ajustado
            
            projetos_ativos['HorasRestantesAjustadas'] = projetos_ativos.apply(ajustar_horas_restantes, axis=1)
            
            # Separa projetos em planejamento
            planejamento_pmo = projetos_ativos[projetos_ativos['Squad'] == 'Em Planejamento - PMO'].copy()
            dados_squads = projetos_ativos[projetos_ativos['Squad'] != 'Em Planejamento - PMO'].copy()
            
            # Calcula horas totais em planejamento
            total_horas_planejamento = planejamento_pmo['HorasRestantesAjustadas'].sum() if not planejamento_pmo.empty else 0
            total_projetos_planejamento = len(planejamento_pmo)
            
            # Lista para armazenar os resultados
            resultado = []
            
            # Processa os squads regulares
            if not dados_squads.empty:
                # Agrupa por Squad
                squads = dados_squads.groupby('Squad').agg({
                    'Projeto': 'count',
                    'HorasRestantesAjustadas': 'sum'
                }).reset_index()
                
                for _, squad in squads.iterrows():
                    nome_squad = squad['Squad']
                    # Calcula o percentual de ocupa√ß√£o baseado na capacidade mensal
                    horas_restantes = squad['HorasRestantesAjustadas']
                    capacidade_utilizada = round((horas_restantes / CAPACIDADE_TOTAL * 100), 1)
                    horas_disponiveis = round(CAPACIDADE_TOTAL - horas_restantes, 1)
                    
                    # Verifica se h√° projetos com horas negativas para este squad
                    projetos_squad = dados_squads[dados_squads['Squad'] == nome_squad]
                    tem_horas_negativas = any(projetos_squad['HorasRestantes'] < 0)
                    
                    # Log detalhado para o squad DATA E POWER
                    if nome_squad == 'DATA E POWER':
                        logger.info(f"Detalhes do c√°lculo para Squad DATA E POWER:")
                        logger.info(f"  Total de projetos: {len(projetos_squad)}")
                        logger.info(f"  Soma das Horas Restantes (n√£o ajustadas): {projetos_squad['HorasRestantes'].sum()}")
                        logger.info(f"  Soma das Horas Restantes Ajustadas: {horas_restantes}")
                    
                    # Adiciona HorasRestantesAjustadas √† sa√≠da dos projetos para coer√™ncia na exibi√ß√£o
                    projetos_output = projetos_squad[['Projeto', 'Status', 'HorasRestantes', 'Conclusao']].copy()
                    # Adiciona a coluna de horas ajustadas para refer√™ncia
                    projetos_output['HorasRestantesAjustadas'] = projetos_squad['HorasRestantesAjustadas']
                    
                    # Prepara os dados do squad
                    squad_info = {
                        'nome': nome_squad,
                        'horas_restantes': round(horas_restantes, 1),
                        'total_projetos': int(squad['Projeto']),
                        'percentual_ocupacao': capacidade_utilizada,
                        'tem_horas_negativas': tem_horas_negativas,
                        'capacidade_utilizada': capacidade_utilizada,
                        'horas_disponiveis': horas_disponiveis,
                        'projetos': projetos_output.to_dict('records')
                    }
                    resultado.append(squad_info)
            
            # Adiciona linha para Em Planejamento - PMO se houver projetos
            if total_projetos_planejamento > 0:
                pmo_info = {
                    'nome': 'Em Planejamento - PMO',
                    'horas_restantes': round(total_horas_planejamento, 1),
                    'total_projetos': total_projetos_planejamento,
                    'percentual_ocupacao': 0,  # N√£o calculamos percentual para planejamento
                    'tem_horas_negativas': False,
                    'capacidade_utilizada': 0,  # N√£o calculamos capacidade para planejamento
                    'horas_disponiveis': 0,     # N√£o calculamos horas dispon√≠veis para planejamento
                    'projetos': planejamento_pmo[['Projeto', 'Status', 'HorasRestantes', 'Conclusao']].to_dict('records')
                }
                resultado.append(pmo_info)
            
            # Ordena por horas restantes (decrescente)
            resultado = sorted(resultado, key=lambda x: x['horas_restantes'], reverse=True)
            
            logger.info(f"Ocupa√ß√£o calculada para {len(resultado)} squads")
            return resultado
            
        except Exception as e:
            logger.error(f"Erro ao calcular ocupa√ß√£o por squad: {str(e)}", exc_info=True)
            return []

    def processar_gerencial(self, dados):
        """Processa dados para a vis√£o gerencial com os status reais"""
        try:
            if dados.empty:
                logging.warning("DataFrame vazio recebido em processar_gerencial")
                return self.criar_estrutura_vazia()

            dados_limpos = dados.copy()
            
            # Padroniza√ß√£o de dados (uppercase e trim)
            for col in ['Status', 'Faturamento']:
                if col in dados_limpos.columns:
                    dados_limpos[col] = dados_limpos[col].str.strip().str.upper()
            
            # Calcula m√©tricas principais
            metricas = self.calcular_kpis(dados_limpos)
            
            # Calcula projetos em risco
            projetos_risco = self.calcular_projetos_risco(dados_limpos)
            
            # Calcula ocupa√ß√£o dos Squads
            ocupacao_squads = self.calcular_ocupacao_squads(dados_limpos)
            
            resultado = {
                'metricas_qualidade': metricas,
                'projetos_criticos': projetos_risco.replace({np.nan: None}).to_dict('records'),
                'projetos_por_squad': dados_limpos.groupby('Squad').size().to_dict(),
                'projetos_por_faturamento': dados_limpos.groupby('Faturamento').size().to_dict(),
                'squads_disponiveis': sorted(dados_limpos['Squad'].unique().tolist()),
                'faturamentos_disponiveis': sorted(dados_limpos['Faturamento'].unique().tolist()),
                'ocupacao_squads': ocupacao_squads
            }
            
            return resultado
            
        except Exception as e:
            logging.error(f"Erro no processamento: {str(e)}")
            return self.criar_estrutura_vazia()

    def calcular_projetos_por_faturamento(self, dados, mes_ref=None):
        """
        Calcula a distribui√ß√£o de projetos por tipo de faturamento.
        
        Args:
            dados: DataFrame com os dados dos projetos
            mes_ref: M√™s de refer√™ncia para filtrar os dados (formato datetime)
        
        Returns:
            Dictionary com contagem por tipo de faturamento e dados detalhados
        """
        try:
            logger.info("Calculando projetos por tipo de faturamento...")
            
            # Usa dados j√° tratados
            dados_base = self.preparar_dados_base(dados)
            
            # Filtra apenas projetos ativos
            projetos_ativos = dados_base[~dados_base['Status'].isin(self.status_concluidos)].copy()
            
            # Se um m√™s de refer√™ncia for fornecido, filtra os dados
            if mes_ref:
                # Converte DataInicio para datetime se ainda n√£o estiver
                if 'DataInicio' in projetos_ativos.columns:
                    projetos_ativos['DataInicio'] = pd.to_datetime(projetos_ativos['DataInicio'], errors='coerce')
                    # Filtra apenas projetos que j√° estavam abertos at√© o final do m√™s
                    primeiro_dia_proximo_mes = (mes_ref.replace(day=28) + timedelta(days=4)).replace(day=1)
                    projetos_ativos = projetos_ativos[projetos_ativos['DataInicio'] < primeiro_dia_proximo_mes]
            
            # Garante que a coluna Faturamento existe
            if 'Faturamento' not in projetos_ativos.columns:
                logger.warning("Coluna 'Faturamento' n√£o encontrada ao calcular projetos por faturamento")
                return {
                    'contagem': {},
                    'dados': []
                }
            
            # Contagem por tipo de faturamento
            contagem = projetos_ativos['Faturamento'].value_counts().to_dict()
            
            # Define cores para os tipos de faturamento
            cores_faturamento = {
                'PRIME': '#4CAF50',   # Verde
                'PLUS': '#2196F3',    # Azul
                'INICIO': '#9C27B0',  # Roxo
                'TERMINO': '#FF9800', # Laranja
                'FEOP': '#F44336',    # Vermelho
                'ENGAJAMENTO': '#673AB7', # Roxo escuro
                'NAO_MAPEADO': '#9E9E9E'  # Cinza
            }
            
            # Prepara dados detalhados
            dados_detalhados = []
            for tipo, qtd in contagem.items():
                if tipo in cores_faturamento:
                    cor = cores_faturamento[tipo]
                else:
                    cor = '#9E9E9E'  # Cinza para n√£o mapeados
                
                dados_detalhados.append({
                    'tipo': tipo,
                    'quantidade': qtd,
                    'cor': cor,
                    'percentual': round((qtd / len(projetos_ativos) * 100), 1) if len(projetos_ativos) > 0 else 0
                })
            
            # Ordena por quantidade em ordem decrescente
            dados_detalhados = sorted(dados_detalhados, key=lambda x: x['quantidade'], reverse=True)
            
            logger.info(f"Distribui√ß√£o por tipo de faturamento calculada: {contagem}")
            
            return {
                'contagem': contagem,
                'dados': dados_detalhados,
                'total': len(projetos_ativos)
            }
            
        except Exception as e:
            logger.error(f"Erro ao calcular projetos por tipo de faturamento: {str(e)}")
            return {
                'contagem': {},
                'dados': [],
                'total': 0
            }

    def calcular_dados_comparativos(self, dados, mes_atual=None, mes_anterior=None):
        """
        Calcula dados comparativos entre dois meses.
        
        Args:
            dados: DataFrame com os dados dos projetos
            mes_atual: Data do m√™s atual para filtrar (formato datetime)
            mes_anterior: Data do m√™s anterior para filtrar (formato datetime)
            
        Returns:
            Dictionary com dados comparativos entre os dois meses
        """
        try:
            logger.info(f"--- Iniciando calcular_dados_comparativos para {mes_atual.strftime('%m/%Y')} vs {mes_anterior.strftime('%m/%Y')} ---") # Log Adicionado
            
            # Se n√£o forem fornecidos meses, usa o m√™s atual e o anterior
            if not mes_atual:
                hoje = datetime.now()
                mes_atual = hoje.replace(day=1)
            
            if not mes_anterior:
                # Considera o m√™s anterior
                primeiro_dia_mes_atual = mes_atual.replace(day=1)
                mes_anterior = (primeiro_dia_mes_atual - timedelta(days=1)).replace(day=1)
                
            # Determinamos o final de cada m√™s
            # Para o m√™s atual (na verdade, m√™s de refer√™ncia)
            if mes_atual.month == 12:
                ultimo_dia_mes_atual = datetime(mes_atual.year + 1, 1, 1) - timedelta(days=1)
            else:
                ultimo_dia_mes_atual = datetime(mes_atual.year, mes_atual.month + 1, 1) - timedelta(days=1)
                
            # Para o m√™s anterior (na verdade, m√™s de compara√ß√£o)
            if mes_anterior.month == 12:
                ultimo_dia_mes_anterior = datetime(mes_anterior.year + 1, 1, 1) - timedelta(days=1)
            else:
                ultimo_dia_mes_anterior = datetime(mes_anterior.year, mes_anterior.month + 1, 1) - timedelta(days=1)
                
            logger.info(f"Per√≠odo de refer√™ncia: {mes_atual.strftime('%d/%m/%Y')} a {ultimo_dia_mes_atual.strftime('%d/%m/%Y')}")
            logger.info(f"Per√≠odo comparativo: {mes_anterior.strftime('%d/%m/%Y')} a {ultimo_dia_mes_anterior.strftime('%d/%m/%Y')}")
                
            # Preparamos a c√≥pia dos dados principal
            dados_completos = dados.copy()
            
            # Convertemos as datas para formato datetime
            for coluna_data in ['DataInicio', 'DataTermino']:
                if coluna_data in dados_completos.columns:
                    dados_completos[coluna_data] = pd.to_datetime(dados_completos[coluna_data], errors='coerce')
            
            # Filtramos os dados de cada m√™s
            # Para o m√™s atual (refer√™ncia)
            # Inclu√≠mos projetos que existiam at√© o final do m√™s (in√≠cio antes do final do m√™s)
            dados_mes_atual_df = dados_completos[
                (dados_completos['DataInicio'] <= ultimo_dia_mes_atual)
            ].copy()
            
            # Para o m√™s anterior (comparativo)
            # Inclu√≠mos projetos que existiam at√© o final do m√™s (in√≠cio antes do final do m√™s)
            dados_mes_anterior_df = dados_completos[
                (dados_completos['DataInicio'] <= ultimo_dia_mes_anterior)
            ].copy()
            
            # C√°lculo para o m√™s de refer√™ncia (atual)
            dados_mes_atual = self.calcular_agregacoes(dados_mes_atual_df)
            faturamento_atual = self.calcular_projetos_por_faturamento(dados_mes_atual_df, mes_atual)
            
            # Log Adicionado: Verificar dados antes de calcular tempo de vida
            logger.info(f"Verificando dados para tempo_medio_vida (M√™s: {mes_atual.strftime('%m/%Y')}). Total de linhas: {len(dados_mes_atual_df)}")
            if not dados_mes_atual_df.empty:
                 colunas_log = [col for col in ['Projeto', 'DataInicio', 'DataTermino', 'Status'] if col in dados_mes_atual_df.columns]
                 if colunas_log:
                      logger.info(f"Amostra dos dados (tempo_medio_vida):\n{dados_mes_atual_df[colunas_log].head()}")
                      # Verificar tipos das colunas de data
                      if 'DataInicio' in colunas_log: logger.info(f"Tipo DataInicio: {dados_mes_atual_df['DataInicio'].dtype}")
                      if 'DataTermino' in colunas_log: logger.info(f"Tipo DataTermino: {dados_mes_atual_df['DataTermino'].dtype}")
                 else:
                      logger.warning("Colunas essenciais para log de tempo_medio_vida n√£o encontradas.")
                      
            tempo_vida_atual = self.calcular_tempo_medio_vida(dados_mes_atual_df, mes_atual) # Passa mes_atual
            
            # Log para debug
            logger.debug(f"Dados m√™s atual - status: {list(dados_mes_atual['por_status'].keys())}")
            logger.debug(f"Dados m√™s atual - squads: {list(dados_mes_atual.get('por_squad', {}).keys())}")
            
            # C√°lculo para o m√™s de compara√ß√£o (anterior)
            agregacoes_mes_anterior = self.calcular_agregacoes(dados_mes_anterior_df)
            faturamento_anterior = self.calcular_projetos_por_faturamento(dados_mes_anterior_df, mes_anterior)
            tempo_vida_anterior = self.calcular_tempo_medio_vida(dados_mes_anterior_df, mes_anterior) # Passa mes_anterior
            
            # Prepara resultado com comparativos
            comparativo = {
                'mes_atual': {
                    'nome': mes_atual.strftime('%B/%Y'),
                    'agregacoes': dados_mes_atual,
                    'faturamento': faturamento_atual,
                    'tempo_medio_vida': tempo_vida_atual
                },
                'mes_anterior': {
                    'nome': mes_anterior.strftime('%B/%Y'),
                    'agregacoes': agregacoes_mes_anterior,
                    'faturamento': faturamento_anterior,
                    'tempo_medio_vida': tempo_vida_anterior
                },
                'variacao': {
                    'por_status': {},
                    'por_squad': {}
                }
            }
            
            # Calcula varia√ß√µes percentuais entre os meses para STATUS
            if 'por_status' in dados_mes_atual and 'por_status' in agregacoes_mes_anterior:
                for status, dados_status in dados_mes_atual['por_status'].items():
                    qtd_atual = dados_status.get('quantidade', 0)
                    qtd_anterior = agregacoes_mes_anterior['por_status'].get(status, {}).get('quantidade', 0)
                    
                    if qtd_anterior > 0:
                        variacao_pct = ((qtd_atual - qtd_anterior) / qtd_anterior) * 100
                    else:
                        variacao_pct = 100 if qtd_atual > 0 else 0
                    
                    comparativo['variacao']['por_status'][status] = {
                        'valor_anterior': qtd_anterior,
                        'valor_atual': qtd_atual,
                        'variacao_absoluta': qtd_atual - qtd_anterior,
                        'variacao_percentual': round(variacao_pct, 1)
                    }
            
            # Calcula varia√ß√µes percentuais entre os meses para SQUAD
            if 'por_squad' in dados_mes_atual and 'por_squad' in agregacoes_mes_anterior:
                for squad, dados_squad in dados_mes_atual['por_squad'].items():
                    qtd_atual = dados_squad.get('quantidade', 0)
                    qtd_anterior = agregacoes_mes_anterior['por_squad'].get(squad, {}).get('quantidade', 0)
                    
                    if qtd_anterior > 0:
                        variacao_pct = ((qtd_atual - qtd_anterior) / qtd_anterior) * 100
                    else:
                        variacao_pct = 100 if qtd_atual > 0 else 0
                    
                    comparativo['variacao']['por_squad'][squad] = {
                        'valor_anterior': qtd_anterior,
                        'valor_atual': qtd_atual,
                        'variacao_absoluta': qtd_atual - qtd_anterior,
                        'variacao_percentual': round(variacao_pct, 1)
                    }
            
            logger.info("Dados comparativos calculados com sucesso")
            return comparativo
            
        except Exception as e:
            logger.error(f"Erro ao calcular dados comparativos: {str(e)}")
            return {
                'mes_atual': {
                    'nome': mes_atual.strftime('%B/%Y') if mes_atual else 'Atual',
                    'agregacoes': {'por_status': {}, 'por_squad': {}},
                    'faturamento': {'dados': []},
                    'tempo_medio_vida': {'media_dias': 0, 'distribuicao': {}}
                },
                'mes_anterior': {
                    'nome': mes_anterior.strftime('%B/%Y') if mes_anterior else 'Anterior',
                    'agregacoes': {'por_status': {}, 'por_squad': {}},
                    'faturamento': {'dados': []},
                    'tempo_medio_vida': {'media_dias': 0, 'distribuicao': {}}
                },
                'variacao': {
                    'por_status': {},
                    'por_squad': {}
                }
            }

    def obter_projetos_por_squad_status_mes(self, dados, squad, mes_referencia=None):
        """
        Obt√©m os projetos de um squad espec√≠fico filtrados por status e por m√™s de refer√™ncia.
        
        Args:
            dados: DataFrame com os dados dos projetos
            squad: Nome do squad para filtrar
            mes_referencia: Data de refer√™ncia para filtro (formato datetime). Se None, usa o √∫ltimo dia do m√™s atual
            
        Returns:
            Dictionary com a contagem de projetos por status e o total
        """
        try:
            logger.info(f"Obtendo projetos do squad {squad} por status para o m√™s de refer√™ncia")
            
            # Define o m√™s de refer√™ncia como o m√™s atual, caso n√£o seja fornecido
            if not mes_referencia:
                hoje = datetime.now()
                mes_referencia = hoje
                
            # Determina o √∫ltimo dia do m√™s de refer√™ncia
            if mes_referencia.month == 12:
                ultimo_dia_mes = datetime(mes_referencia.year + 1, 1, 1) - timedelta(days=1)
            else:
                ultimo_dia_mes = datetime(mes_referencia.year, mes_referencia.month + 1, 1) - timedelta(days=1)
                
            logger.info(f"Per√≠odo de refer√™ncia: at√© {ultimo_dia_mes.strftime('%d/%m/%Y')}")
            
            # Prepara c√≥pia dos dados
            dados_temp = dados.copy()
            
            # Mapeamento de squads para normalizar nomes
            # Adicione aqui qualquer mapeamento espec√≠fico necess√°rio
            squad_mapping = {
                'AZURE': ['AZURE', 'Azure'],
                'M365': ['M365', 'M365'],
                'DATA E POWER': ['DATA E POWER', 'Data e Power'],
                'CDB': ['CDB', 'CDB']
            }
            
            # Log para depura√ß√£o - status e squads dispon√≠veis nos dados
            if not dados_temp.empty:
                todos_status = dados_temp['Status'].dropna().unique().tolist()
                todos_squads = dados_temp['Squad'].dropna().unique().tolist()
                logger.info(f"Status dispon√≠veis nos dados: {todos_status}")
                logger.info(f"Squads dispon√≠veis nos dados: {todos_squads}")
            
            # Certifica-se que as colunas esperadas existem
            colunas_necessarias = ['DataInicio', 'Squad', 'Status', 'Especialista']
            colunas_faltantes = [col for col in colunas_necessarias if col not in dados_temp.columns]
            if colunas_faltantes:
                logger.warning(f"Colunas necess√°rias n√£o encontradas: {colunas_faltantes}")
                return {
                    'total': 0,
                    'por_status': {},
                    'squad': squad
                }
                
            # Converte a coluna de data para datetime
            dados_temp['DataInicio'] = pd.to_datetime(dados_temp['DataInicio'], errors='coerce')
            
            # Fun√ß√£o auxiliar para verificar se um registro corresponde ao squad solicitado
            # considerando o especialista
            def corresponde_squad_especialista(row, target_squad):
                if pd.isna(row['Squad']) or not row['Squad']:
                    return False
                
                # Trata valores NaN na coluna Especialista
                especialista = '' if pd.isna(row['Especialista']) else str(row['Especialista']).strip()
                row_squad = str(row['Squad']).strip().upper()
                target_squad = str(target_squad).strip().upper()
                
                # Caso especial para CDB
                if target_squad == 'CDB':
                    # Para CDB, verifica se o especialista √© "CDB DATA SOLUTIONS"
                    return especialista.upper() == 'CDB DATA SOLUTIONS'
                
                # Para os outros squads (AZURE, M365, DATA E POWER)
                # Verifica se o especialista N√ÉO √© "CDB DATA SOLUTIONS" e o squad corresponde
                if especialista.upper() == 'CDB DATA SOLUTIONS':
                    return False
                
                # Verifica correspond√™ncia direta
                if row_squad == target_squad:
                    return True
                
                # Verifica no mapeamento de squads
                for key, values in squad_mapping.items():
                    if target_squad == key.upper():
                        # Se o squad alvo √© uma chave no mapeamento, verifica se o squad da linha est√° nos valores
                        return any(str(v).strip().upper() == row_squad for v in values)
                    elif row_squad == key.upper():
                        # Se o squad da linha √© uma chave no mapeamento, verifica se o squad alvo est√° nos valores
                        return any(str(v).strip().upper() == target_squad for v in values)
                
                return False
            
            # Aplica a fun√ß√£o de correspond√™ncia
            dados_temp['MatchSquad'] = dados_temp.apply(lambda row: corresponde_squad_especialista(row, squad), axis=1)
            
            # Filtra projetos at√© o √∫ltimo dia do m√™s de refer√™ncia e do squad correto
            dados_filtrados = dados_temp[
                (dados_temp['DataInicio'] <= ultimo_dia_mes) &
                (dados_temp['MatchSquad'] == True)
            ].copy()
            
            # Log para depura√ß√£o - projetos encontrados
            total_projetos = len(dados_filtrados)
            logger.info(f"Total de projetos encontrados para o squad {squad}: {total_projetos}")
            
            if not dados_filtrados.empty:
                primeiro_projeto = dados_filtrados.iloc[0]
                logger.info(f"Exemplo de projeto encontrado: Projeto={primeiro_projeto.get('Projeto', 'N/A')}, " 
                          f"Status={primeiro_projeto.get('Status', 'N/A')}, "
                          f"Squad={primeiro_projeto.get('Squad', 'N/A')}, "
                          f"Especialista={primeiro_projeto.get('Especialista', 'N/A')}")
                # Mostra todos os projetos do squad para depura√ß√£o
                for idx, row in dados_filtrados.iterrows():
                    logger.debug(f"Projeto filtrado: {row.get('Projeto', 'N/A')} - Status: {row.get('Status', 'N/A')} - "
                               f"Squad: {row.get('Squad', 'N/A')} - Especialista: {row.get('Especialista', 'N/A')}")
            
            # Exclui projetos que j√° estavam fechados/conclu√≠dos
            dados_filtrados = dados_filtrados[~dados_filtrados['Status'].isin(self.status_concluidos)]
            logger.info(f"Projetos ativos ap√≥s remover conclu√≠dos: {len(dados_filtrados)}")
            
            # Calcula contagem por status
            por_status = {}
            if not dados_filtrados.empty:
                contagem_status = dados_filtrados['Status'].value_counts().to_dict()
                for status, qtd in contagem_status.items():
                    por_status[status] = qtd
                    logger.info(f"Status {status}: {qtd} projetos")
            
            # Prepara resultado
            resultado = {
                'total': len(dados_filtrados),
                'por_status': por_status,
                'squad': squad
            }
            
            return resultado
            
        except Exception as e:
            logger.error(f"Erro ao obter projetos por squad e status: {str(e)}")
            logger.exception(e)
            return {
                'total': 0,
                'por_status': {},
                'squad': squad
            }

    def calcular_projetos_entregues(self, dados, mes_referencia=None):
        """
        Calcula os dados de projetos entregues no m√™s.
        
        Args:
            dados: DataFrame com os dados dos projetos
            mes_referencia: Data de refer√™ncia (formato datetime). Se None, usa o m√™s atual
            
        Returns:
            Dictionary com dados sobre projetos entregues
        """
        try:
            logger.info("Calculando projetos entregues...")
            
            # Define o m√™s de refer√™ncia se n√£o informado
            if not mes_referencia:
                hoje = datetime.now()
                mes_referencia = hoje
            
            # Calcula in√≠cio e fim do m√™s de refer√™ncia
            mes_inicio = datetime(mes_referencia.year, mes_referencia.month, 1)
            if mes_referencia.month == 12:
                mes_fim = datetime(mes_referencia.year + 1, 1, 1) - timedelta(days=1)
            else:
                mes_fim = datetime(mes_referencia.year, mes_referencia.month + 1, 1) - timedelta(days=1)
            
            # Filtra projetos conclu√≠dos no per√≠odo usando a fonte de dados correta
            dados_filtrados = self.filtrar_projetos_concluidos(dados, mes_inicio, mes_fim)
            
            # Total de projetos entregues no m√™s
            total_mes = len(dados_filtrados)
            
            # Calcular projetos entregues no prazo e fora do prazo dinamicamente
            no_prazo = 0
            fora_prazo = 0
            
            # Log para verificar os dados ANTES do dropna
            if not dados_filtrados.empty:
                logger.debug(f"VencimentoEm para projetos conclu√≠dos ANTES de dropna:\n{dados_filtrados[['Projeto', 'VencimentoEm', 'Status', 'DataTermino']]}")

            if not dados_filtrados.empty and 'VencimentoEm' in dados_filtrados.columns:
                # Converte VencimentoEm para datetime se necess√°rio e normaliza (ignora hora)
                if not pd.api.types.is_datetime64_any_dtype(dados_filtrados['VencimentoEm']):
                     dados_filtrados['VencimentoEm'] = pd.to_datetime(dados_filtrados['VencimentoEm'], errors='coerce')
                dados_filtrados['VencimentoEm'] = dados_filtrados['VencimentoEm'].dt.normalize()

                # Filtra apenas onde a data de vencimento √© v√°lida
                validos_para_prazo = dados_filtrados.dropna(subset=['VencimentoEm']).copy()
                logger.info(f"Projetos conclu√≠dos com VencimentoEm v√°lido: {len(validos_para_prazo)}") # Log adicionado

                if not validos_para_prazo.empty:
                    # Normaliza o mes_referencia para comparar apenas ano e m√™s (pegando o primeiro dia)
                    inicio_mes_ref = mes_referencia.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
                    logger.debug(f"--- Iniciando C√°lculo Prazo para M√™s Ref: {inicio_mes_ref.strftime('%Y-%m-%d')} ---")

                    # No prazo: VencimentoEm >= in√≠cio do m√™s de refer√™ncia
                    no_prazo = (validos_para_prazo['VencimentoEm'] >= inicio_mes_ref).sum()
                    
                    # Fora do prazo: VencimentoEm < in√≠cio do m√™s de refer√™ncia
                    fora_prazo_com_data = (validos_para_prazo['VencimentoEm'] < inicio_mes_ref).sum()

                    logger.info(f"Projetos com data v√°lida: No Prazo = {no_prazo}, Fora Prazo com data = {fora_prazo_com_data}")
                    
                    # Projetos sem data de vencimento s√£o considerados FORA DO PRAZO
                    projetos_sem_vencimento = total_mes - len(validos_para_prazo)
                    fora_prazo = fora_prazo_com_data + projetos_sem_vencimento
                    
                    logger.info(f"[Vis√£o Atual] No Prazo = {no_prazo}, Fora Prazo = {fora_prazo} (incluindo {projetos_sem_vencimento} sem data)")
                    
                    if projetos_sem_vencimento > 0:
                        # Identifica quais projetos n√£o t√™m data de vencimento v√°lida
                        projetos_invalidos = dados_filtrados[dados_filtrados['VencimentoEm'].isna() | 
                                                            dados_filtrados['VencimentoEm'].isnull()]
                        
                        logger.warning(f"[Vis√£o Atual] {projetos_sem_vencimento} projetos sem data de vencimento ser√£o considerados FORA DO PRAZO.")
                        
                        for _, projeto in projetos_invalidos.iterrows():
                            numero = projeto.get('Numero', projeto.get('N√∫mero', 'N/A'))
                            nome_projeto = projeto.get('Projeto', 'N/A')
                            logger.warning(f"  - Projeto #{numero}: {nome_projeto}")
                else:
                    # Se n√£o h√° projetos com data v√°lida, todos s√£o considerados fora do prazo
                    no_prazo = 0
                    fora_prazo = total_mes
                    logger.warning(f"[Vis√£o Atual] Nenhum projeto com data v√°lida. Todos os {total_mes} projetos ser√£o considerados FORA DO PRAZO.")

            # Calcular hist√≥rico (agora apenas do m√™s anterior)
            historico = self.calcular_historico_entregas(dados, mes_referencia)
            
            resultado = {
                'total_mes': total_mes,
                'no_prazo': no_prazo,
                'fora_prazo': fora_prazo,
                'historico': historico
            }
            
            logger.info(f"Projetos entregues calculados: {total_mes} no total, {no_prazo} no prazo, {fora_prazo} fora do prazo")
            return resultado
            
        except Exception as e:
            logger.exception(f"Erro ao calcular projetos entregues: {str(e)}")
            # Retorna valores padr√£o em caso de erro
            return {
                'total_mes': 0,
                'no_prazo': 0,
                'fora_prazo': 0,
                'historico': []
            }
    
    def filtrar_projetos_concluidos(self, dados, data_inicio, data_fim):
        """
        Filtra projetos conclu√≠dos em um per√≠odo espec√≠fico.
        """
        try:
            # Status que indicam conclus√£o
            status_conclusao = ['FECHADO', 'ENCERRADO', 'RESOLVIDO']
            coluna_data_termino = 'DataTermino' # Usar a coluna correta ap√≥s renomea√ß√£o

            # Verifica se temos a coluna DataTermino
            if coluna_data_termino not in dados.columns:
                logger.warning(f"Coluna '{coluna_data_termino}' n√£o encontrada. N√£o √© poss√≠vel filtrar conclu√≠dos por data.")
                # Retorna DataFrame vazio se n√£o puder filtrar por data
                return pd.DataFrame()

            # Converte para datetime se necess√°rio
            if not pd.api.types.is_datetime64_any_dtype(dados[coluna_data_termino]):
                dados[coluna_data_termino] = pd.to_datetime(dados[coluna_data_termino], errors='coerce')

            # Filtra projetos conclu√≠dos no per√≠odo usando DataTermino
            concluidos = dados[
                (dados['Status'].str.upper().isin([s.upper() for s in status_conclusao])) &
                (dados[coluna_data_termino].notna()) & # Garante que a data n√£o √© NaT
                (dados[coluna_data_termino] >= data_inicio) &
                (dados[coluna_data_termino] <= data_fim)
            ].copy()

            logger.debug(f"Filtrados {len(concluidos)} projetos conclu√≠dos entre {data_inicio.strftime('%Y-%m-%d')} e {data_fim.strftime('%Y-%m-%d')}")
            return concluidos

        except Exception as e:
            logger.exception(f"Erro ao filtrar projetos conclu√≠dos: {str(e)}")
            return pd.DataFrame()  # Retorna DataFrame vazio em caso de erro
    
    def calcular_historico_entregas(self, dados, mes_referencia):
        """
        Calcula o hist√≥rico de entregas para os 3 meses anteriores ao m√™s de refer√™ncia,
        incluindo valores fixos para Dez/24 e Jan/25.
        """
        try:
            logger.info(f"Calculando hist√≥rico de entregas para os 3 meses anteriores a {mes_referencia.strftime('%m/%Y')}")
            historico = []
            mes_nomes = [
                'Janeiro', 'Fevereiro', 'Mar√ßo', 'Abril', 'Maio', 'Junho',
                'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro'
            ]
            
            quantidades_meses = {}
            datas_meses = {}

            # Calcula as datas dos 3 meses anteriores
            for i in range(3, 0, -1):
                # Calcula o m√™s/ano do m√™s hist√≥rico
                mes_atual = mes_referencia.month
                ano_atual = mes_referencia.year
                
                # Subtrai 'i' meses
                mes_hist = mes_atual - i
                ano_hist = ano_atual
                while mes_hist <= 0:
                    mes_hist += 12
                    ano_hist -= 1
                
                data_mes_hist = datetime(ano_hist, mes_hist, 1)
                datas_meses[i] = data_mes_hist # Guarda a data (chave 3 = M-3, 2 = M-2, 1 = M-1)
                nome_mes_hist = mes_nomes[mes_hist - 1]
                logger.info(f"  Processando hist√≥rico para: {nome_mes_hist}/{ano_hist} (M-{i})")
                
                quantidade = 0
                # 1. Verifica valores hardcoded
                if ano_hist == 2024 and mes_hist == 12:
                    quantidade = 7
                    logger.info(f"    Usando valor hardcoded para Dez/24: {quantidade}")
                elif ano_hist == 2025 and mes_hist == 1:
                    quantidade = 8
                    logger.info(f"    Usando valor hardcoded para Jan/25: {quantidade}")
                else:
                    # 2. Tenta carregar fonte espec√≠fica
                    fonte_historico = None
                    # Mapeamento simples (pode ser expandido)
                    if ano_hist == 2025:
                        if mes_hist == 2: fonte_historico = 'dadosr_apt_fev'
                        if mes_hist == 3: fonte_historico = 'dadosr_apt_mar'
                        if mes_hist == 4: fonte_historico = 'dadosr_apt_abr'  # ADICIONADO: mapeamento para abril
                        if mes_hist == 5: fonte_historico = 'dadosr_apt_mai'  # ADICIONADO: mapeamento para maio
                        if mes_hist == 6: fonte_historico = 'dadosr_apt_jun'  # ADICIONADO: mapeamento para junho
                        # Adicionar mapeamentos futuros aqui (Julho, Agosto, etc.)
                    
                    if fonte_historico:
                        logger.info(f"    Tentando carregar dados da fonte: {fonte_historico}")
                        dados_historico = self.carregar_dados(fonte=fonte_historico)
                        
                        if not dados_historico.empty:
                            # Define o primeiro e √∫ltimo dia do m√™s hist√≥rico
                            data_inicio = datetime(ano_hist, mes_hist, 1)
                            if mes_hist == 12:
                                data_fim = datetime(ano_hist + 1, 1, 1) - timedelta(days=1)
                            else:
                                data_fim = datetime(ano_hist, mes_hist + 1, 1) - timedelta(days=1)
                                
                            # Filtra projetos conclu√≠dos neste m√™s usando os dados hist√≥ricos
                            concluidos_mes = self.filtrar_projetos_concluidos(dados_historico, data_inicio, data_fim)
                            quantidade = len(concluidos_mes)
                            logger.info(f"    Encontrados {quantidade} projetos conclu√≠dos em {nome_mes_hist} usando {fonte_historico}.csv")
                        else:
                            logger.warning(f"    N√£o foi poss√≠vel carregar dados da fonte hist√≥rica: {fonte_historico}. Quantidade ser√° 0.")
                    else:
                        logger.warning(f"    Nenhuma fonte de dados espec√≠fica definida para {nome_mes_hist}/{ano_hist}. Quantidade ser√° 0.")
                        
                quantidades_meses[i] = quantidade # Guarda a quantidade (chave 3 = Qtd M-3, etc.)

            # Monta o resultado final e calcula varia√ß√µes
            qtd_base_pct = quantidades_meses.get(3, 0) # Quantidade do primeiro m√™s (M-3) para c√°lculo %%
            logger.info(f"Base para c√°lculo percentual (M√™s M-3): {qtd_base_pct}")

            for i in range(3, 0, -1):
                data_mes = datas_meses[i]
                nome_mes = mes_nomes[data_mes.month - 1]
                qtd_atual = quantidades_meses[i]
                variacao_abs = '-'
                variacao_pct = 0
                
                # Calcula varia√ß√£o ABSOLUTA em rela√ß√£o ao m√™s anterior (se houver)
                if i < 3:
                    qtd_anterior = quantidades_meses[i + 1] # M√™s anterior √© i+1
                    variacao_abs = qtd_atual - qtd_anterior
                # else: M√™s M-3, variacao_abs permanece '-'
                    
                # Calcula varia√ß√£o PERCENTUAL em rela√ß√£o ao M√äS BASE (M-3)
                # Exceto para o pr√≥prio m√™s base (i=3)
                if i < 3:
                    if qtd_base_pct > 0:
                        variacao_pct = round(((qtd_atual - qtd_base_pct) / qtd_base_pct) * 100, 1)
                    elif qtd_atual > 0: # Base era 0, atual n√£o √©
                        variacao_pct = 100.0 
                    # else: ambos 0 (ou base 0), pct √© 0
                        
                historico.append({
                    'mes': nome_mes,
                    'quantidade': qtd_atual,
                    'variacao': f"{variacao_abs:+}" if isinstance(variacao_abs, int) else variacao_abs,
                    'variacao_percentual': variacao_pct
                })
                
            logger.info(f"Hist√≥rico de entregas final calculado: {historico}")
            return historico

        except Exception as e:
            logger.exception(f"Erro ao calcular hist√≥rico de entregas (3 meses): {str(e)}")
            return []

    def _calcular_historico_dinamico(self, mes_referencia):
        """
        Fun√ß√£o auxiliar para calcular o hist√≥rico de entregas dinamicamente 
        para os 3 meses anteriores ao m√™s de refer√™ncia, tentando carregar fontes.
        Usado pela Vis√£o Atual.
        """
        try:
            logger.info(f"[_calcular_historico_dinamico] Calculando para 3 meses antes de {mes_referencia.strftime('%m/%Y')}")
            historico = []
            mes_nomes = [
                'Janeiro', 'Fevereiro', 'Mar√ßo', 'Abril', 'Maio', 'Junho',
                'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro'
            ]
            quantidades_meses = {}
            datas_meses = {}

            # Calcula as datas dos 3 meses anteriores
            for i in range(3, 0, -1): # M-3, M-2, M-1
                mes_atual = mes_referencia.month
                ano_atual = mes_referencia.year
                mes_hist = mes_atual - i
                ano_hist = ano_atual
                while mes_hist <= 0:
                    mes_hist += 12
                    ano_hist -= 1
                
                data_mes_hist = datetime(ano_hist, mes_hist, 1)
                datas_meses[i] = data_mes_hist
                nome_mes_hist = mes_nomes[mes_hist - 1]
                logger.info(f"  Processando hist√≥rico para: {nome_mes_hist}/{ano_hist} (M-{i})")
                
                quantidade = 0
                # Determina a fonte de dados hist√≥rica usando a fun√ß√£o auxiliar
                fonte_historico = self._obter_fonte_historica(ano_hist, mes_hist)
                
                if fonte_historico:
                    logger.info(f"    Tentando carregar dados da fonte: {fonte_historico}")
                    dados_historico = self.carregar_dados(fonte=fonte_historico)
                    
                    if not dados_historico.empty:
                        data_inicio = datetime(ano_hist, mes_hist, 1)
                        if mes_hist == 12:
                            data_fim = datetime(ano_hist + 1, 1, 1) - timedelta(days=1)
                        else:
                            data_fim = datetime(ano_hist, mes_hist + 1, 1) - timedelta(days=1)
                        
                        concluidos_mes = self.filtrar_projetos_concluidos(dados_historico, data_inicio, data_fim)
                        quantidade = len(concluidos_mes)
                        logger.info(f"    Encontrados {quantidade} projetos conclu√≠dos em {nome_mes_hist} usando {fonte_historico}.csv")
                    else:
                        logger.warning(f"    N√£o foi poss√≠vel carregar dados da fonte hist√≥rica: {fonte_historico}. Quantidade ser√° 0.")
                else:
                    # Verifica valores hardcoded como fallback
                    if ano_hist == 2024 and mes_hist == 12: 
                        quantidade = 7
                        logger.info(f"    Fonte n√£o encontrada, usando valor hardcoded para Dez/24: {quantidade}")
                    elif ano_hist == 2025 and mes_hist == 1: 
                        quantidade = 8
                        logger.info(f"    Fonte n√£o encontrada, usando valor hardcoded para Jan/25: {quantidade}")
                    else:
                         logger.warning(f"    Nenhuma fonte de dados espec√≠fica ou valor fixo definido para {nome_mes_hist}/{ano_hist}. Quantidade ser√° 0.")
                        
                quantidades_meses[i] = quantidade

            # Define a quantidade do primeiro m√™s do hist√≥rico (M-3) como base
            qtd_base_pct = quantidades_meses.get(3, 0)
            logger.info(f"[_calcular_historico_dinamico] Base para c√°lculo percentual (M√™s M-3): {qtd_base_pct}")

            # Monta o resultado final e calcula varia√ß√µes
            for i in range(3, 0, -1):
                data_mes = datas_meses[i]
                nome_mes = mes_nomes[data_mes.month - 1]
                qtd_atual = quantidades_meses[i]
                variacao_abs = '-'
                variacao_pct = 0

                # Calcula varia√ß√£o ABSOLUTA em rela√ß√£o ao m√™s anterior (se houver)
                if i < 3:
                    qtd_anterior = quantidades_meses.get(i + 1, 0) # Usa .get para seguran√ßa
                    variacao_abs = qtd_atual - qtd_anterior
                # else: M√™s M-3, variacao_abs permanece '-'

                # Calcula varia√ß√£o PERCENTUAL em rela√ß√£o ao M√äS BASE (M-3)
                # Exceto para o pr√≥prio m√™s base (i=3), onde a varia√ß√£o √© 0 ou '-'
                if i < 3: # Apenas para M-2 e M-1
                    if qtd_base_pct > 0:
                        variacao_pct = round(((qtd_atual - qtd_base_pct) / qtd_base_pct) * 100, 1)
                    elif qtd_atual > 0: # Base era 0, atual n√£o √©
                        variacao_pct = 100.0
                    # else: base 0 ou ambos 0, pct √© 0
                # else: i == 3 (m√™s base), variacao_pct permanece 0

                historico.append({
                    'mes': nome_mes,
                    'quantidade': qtd_atual,
                    'variacao': f"{variacao_abs:+}" if isinstance(variacao_abs, int) else variacao_abs,
                    # Mant√©m '-' para o primeiro m√™s, ou o percentual calculado para os outros
                    'variacao_percentual': variacao_pct if i < 3 else '-'
                })

            logger.info(f"[_calcular_historico_dinamico] Hist√≥rico final calculado: {historico}")
            return historico
        
        except Exception as e:
            logger.exception(f"[_calcular_historico_dinamico] Erro ao calcular hist√≥rico din√¢mico: {str(e)}")
            return []

    def calcular_projetos_entregues_atual(self, dados, mes_referencia):
        """
        Calcula os dados de projetos entregues para a Vis√£o Atual.
        Inclui c√°lculo din√¢mico do hist√≥rico para os 3 meses anteriores.
        
        Args:
            dados: DataFrame com os dados dos projetos (geralmente dadosr.csv).
            mes_referencia: Data de refer√™ncia (datetime) determinada dinamicamente.
            
        Returns:
            Dictionary com dados sobre projetos entregues.
        """
        try:
            logger.info(f"[Vis√£o Atual] Calculando projetos entregues para {mes_referencia.strftime('%m/%Y')}...")
            
            # Calcula in√≠cio e fim do m√™s de refer√™ncia
            mes_inicio = datetime(mes_referencia.year, mes_referencia.month, 1)
            if mes_referencia.month == 12:
                mes_fim = datetime(mes_referencia.year + 1, 1, 1) - timedelta(days=1)
            else:
                mes_fim = datetime(mes_referencia.year, mes_referencia.month + 1, 1) - timedelta(days=1)
            
            # Filtra projetos conclu√≠dos no per√≠odo usando os dados ATUAIS (dadosr.csv)
            dados_filtrados = self.filtrar_projetos_concluidos(dados, mes_inicio, mes_fim)
            
            # Total de projetos entregues no m√™s
            total_mes = len(dados_filtrados)
            
            # Calcular projetos entregues no prazo e fora do prazo (l√≥gica original que resultava em n√£o classificados)
            no_prazo = 0
            fora_prazo = 0
            if not dados_filtrados.empty and 'VencimentoEm' in dados_filtrados.columns:
                if not pd.api.types.is_datetime64_any_dtype(dados_filtrados['VencimentoEm']):
                     dados_filtrados['VencimentoEm'] = pd.to_datetime(dados_filtrados['VencimentoEm'], errors='coerce')
                dados_filtrados['VencimentoEm'] = dados_filtrados['VencimentoEm'].dt.normalize()
                validos_para_prazo = dados_filtrados.dropna(subset=['VencimentoEm']).copy()
                if not validos_para_prazo.empty:
                    inicio_mes_ref = mes_referencia.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
                    no_prazo = (validos_para_prazo['VencimentoEm'] >= inicio_mes_ref).sum()
                    fora_prazo_com_data = (validos_para_prazo['VencimentoEm'] < inicio_mes_ref).sum()
                    
                    # üîß CORRE√á√ÉO: Projetos sem data de vencimento s√£o considerados FORA DO PRAZO
                    projetos_sem_vencimento = total_mes - len(validos_para_prazo)
                    fora_prazo = fora_prazo_com_data + projetos_sem_vencimento
                    
                    logger.info(f"[Vis√£o Atual] No Prazo = {no_prazo}, Fora Prazo = {fora_prazo} (incluindo {projetos_sem_vencimento} sem data)")
                    
                    if projetos_sem_vencimento > 0:
                        # Identifica quais projetos n√£o t√™m data de vencimento v√°lida
                        projetos_invalidos = dados_filtrados[dados_filtrados['VencimentoEm'].isna() | 
                                                            dados_filtrados['VencimentoEm'].isnull()]
                        
                        logger.warning(f"[Vis√£o Atual] {projetos_sem_vencimento} projetos sem data de vencimento ser√£o considerados FORA DO PRAZO.")
                        
                        for _, projeto in projetos_invalidos.iterrows():
                            numero = projeto.get('Numero', projeto.get('N√∫mero', 'N/A'))
                            nome_projeto = projeto.get('Projeto', 'N/A')
                            logger.warning(f"  - Projeto #{numero}: {nome_projeto}")
                else:
                    # Se n√£o h√° projetos com data v√°lida, todos s√£o considerados fora do prazo
                    no_prazo = 0
                    fora_prazo = total_mes
                    logger.warning(f"[Vis√£o Atual] Nenhum projeto com data v√°lida. Todos os {total_mes} projetos ser√£o considerados FORA DO PRAZO.")
            else:
                # Se n√£o h√° coluna VencimentoEm ou dados filtrados vazios, todos s√£o fora do prazo
                no_prazo = 0
                fora_prazo = total_mes
                logger.warning(f"[Vis√£o Atual] Coluna 'VencimentoEm' n√£o encontrada ou dados filtrados vazios. Todos os {total_mes} projetos ser√£o considerados FORA DO PRAZO.")

            # Chama a fun√ß√£o auxiliar para calcular o hist√≥rico din√¢mico
            historico = self._calcular_historico_dinamico(mes_referencia)
            
            resultado = {
                'total_mes': total_mes,
                'no_prazo': no_prazo,
                'fora_prazo': fora_prazo,
                'historico': historico
            }
            
            logger.info(f"[Vis√£o Atual] Projetos entregues calculados (CORRIGIDO): {total_mes} no total, {no_prazo} no prazo, {fora_prazo} fora do prazo")
            logger.info(f"[Vis√£o Atual] Hist√≥rico din√¢mico: {historico}")
            return resultado
            
        except Exception as e:
            logger.exception(f"[Vis√£o Atual] Erro ao calcular projetos entregues: {str(e)}")
            return {
                'total_mes': 0,
                'no_prazo': 0,
                'fora_prazo': 0,
                'historico': []
            }

    def calcular_novos_projetos_mes(self, dados, mes_referencia):
        """
        Calcula a quantidade de projetos iniciados no m√™s de refer√™ncia, agregados por squad.

        Args:
            dados: DataFrame com os dados dos projetos.
            mes_referencia: Data (datetime) do m√™s de refer√™ncia.

        Returns:
            Dictionary com contagem por squad e total. Ex: {'por_squad': {'AZURE': 5, ...}, 'total': 10}
        """
        try:
            logger.info(f"Calculando novos projetos para o m√™s {mes_referencia.strftime('%m/%Y')}...")

            if dados.empty or 'DataInicio' not in dados.columns or 'Squad' not in dados.columns:
                logger.warning("Dados insuficientes para calcular novos projetos (DataFrame vazio ou colunas faltando).")
                return {'por_squad': {}, 'total': 0}

            # Garante que DataInicio √© datetime
            if not pd.api.types.is_datetime64_any_dtype(dados['DataInicio']):
                 dados['DataInicio'] = pd.to_datetime(dados['DataInicio'], errors='coerce')

            # Filtra projetos iniciados no m√™s/ano de refer√™ncia
            dados_mes = dados[
                (dados['DataInicio'].dt.month == mes_referencia.month) &
                (dados['DataInicio'].dt.year == mes_referencia.year)
            ].copy()

            total_novos = len(dados_mes)
            logger.info(f"Total de projetos iniciados no m√™s: {total_novos}")

            # Agrupa por Squad (garante que Squad seja string e mai√∫sculo)
            dados_mes['Squad'] = dados_mes['Squad'].astype(str).str.strip().str.upper() # Garante que a coluna est√° em mai√∫sculas
            contagem_squad = dados_mes.groupby('Squad').size().to_dict()

            # Normaliza os squads principais
            squads_principais = ['AZURE', 'M365', 'DATA E POWER', 'CDB']
            resultado_squad = {s: 0 for s in squads_principais}
            outros = 0

            for squad, contagem in contagem_squad.items():
                # O squad j√° est√° em mai√∫sculas devido ao .str.upper() acima
                if squad in resultado_squad:
                    resultado_squad[squad] = contagem
                # N√£o precisamos mais do elif, pois a compara√ß√£o direta j√° funciona
                else:
                    logger.debug(f"Squad '{squad}' n√£o √© principal, contagem: {contagem}")
                    outros += contagem

            # O total considera todos os projetos iniciados no m√™s
            resultado_final = {
                'por_squad': resultado_squad,
                'total': total_novos,
                'novos_projetos': dados_mes  # Adiciona os dados dos projetos novos
            }
            logger.info(f"Contagem de novos projetos por squad: {resultado_squad}, Total: {total_novos}")

            return resultado_final

        except Exception as e:
            logger.error(f"Erro ao calcular novos projetos: {str(e)}")
            return {'por_squad': {}, 'total': 0}

    def calcular_novos_projetos_atual(self, dados, mes_referencia):
        """
        Calcula os dados de novos projetos para a Vis√£o Atual.
        Retorna estrutura de compara√ß√£o com m√™s atual vs anterior.
        
        Args:
            dados: DataFrame com os dados dos projetos (geralmente dadosr.csv).
            mes_referencia: Data de refer√™ncia (datetime) determinada dinamicamente.
            
        Returns:
            Dictionary com estrutura de compara√ß√£o de novos projetos.
        """
        try:
            logger.info(f"[Vis√£o Atual] Calculando novos projetos para {mes_referencia.strftime('%m/%Y')}...")
            
            # Calcular novos projetos do m√™s atual
            resultado_mes_atual = self.calcular_novos_projetos_mes(dados, mes_referencia)
            
            # Calcular m√™s anterior
            if mes_referencia.month == 1:
                mes_anterior = mes_referencia.replace(year=mes_referencia.year - 1, month=12)
            else:
                mes_anterior = mes_referencia.replace(month=mes_referencia.month - 1)
            
            logger.info(f"[Vis√£o Atual] Tentando calcular dados do m√™s anterior: {mes_anterior.strftime('%m/%Y')}")
            
            # Tentar obter dados hist√≥ricos do m√™s anterior
            resultado_mes_anterior = {'por_squad': {}, 'total': 0}
            
            # Verifica se existe fonte hist√≥rica para o m√™s anterior
            fonte_anterior = self._obter_fonte_historica(mes_anterior.year, mes_anterior.month)
            if fonte_anterior:
                try:
                    dados_anterior = self.carregar_dados(fonte=fonte_anterior)
                    if not dados_anterior.empty:
                        resultado_mes_anterior = self.calcular_novos_projetos_mes(dados_anterior, mes_anterior)
                        logger.info(f"[Vis√£o Atual] Dados do m√™s anterior carregados da fonte: {fonte_anterior}")
                    else:
                        logger.warning(f"[Vis√£o Atual] Fonte {fonte_anterior} retornou dados vazios")
                except Exception as e:
                    logger.error(f"[Vis√£o Atual] Erro ao carregar dados da fonte {fonte_anterior}: {e}")
            else:
                # Fallback: tentar calcular usando os mesmos dados atuais (pode incluir projetos do m√™s anterior)
                try:
                    resultado_mes_anterior = self.calcular_novos_projetos_mes(dados, mes_anterior)
                    logger.info(f"[Vis√£o Atual] Usando fallback com dados atuais para calcular m√™s anterior")
                except Exception as e:
                    logger.warning(f"[Vis√£o Atual] Fallback falhou: {e}")
            
            # Estruturar dados para compara√ß√£o
            squads_principais = ['AZURE', 'M365', 'DATA E POWER', 'CDB']
            comparativo = {
                'por_squad': {},
                'total': {
                    'atual': resultado_mes_atual['total'],
                    'anterior': resultado_mes_anterior['total'],
                    'variacao_abs': 0,
                    'variacao_pct': 0
                }
            }
            
            # Calcular varia√ß√µes por squad
            for squad in squads_principais:
                atual = resultado_mes_atual['por_squad'].get(squad, 0)
                anterior = resultado_mes_anterior['por_squad'].get(squad, 0)
                variacao_abs = atual - anterior
                variacao_pct = 0
                
                if anterior > 0:
                    variacao_pct = round(((atual - anterior) / anterior) * 100, 1)
                elif atual > 0:
                    variacao_pct = 100.0
                
                comparativo['por_squad'][squad] = {
                    'atual': atual,
                    'anterior': anterior,
                    'variacao_abs': variacao_abs,
                    'variacao_pct': variacao_pct
                }
            
            # Calcular varia√ß√µes totais
            total_atual = comparativo['total']['atual']
            total_anterior = comparativo['total']['anterior']
            total_variacao_abs = total_atual - total_anterior
            total_variacao_pct = 0
            
            if total_anterior > 0:
                total_variacao_pct = round(((total_atual - total_anterior) / total_anterior) * 100, 1)
            elif total_atual > 0:
                total_variacao_pct = 100.0
            
            comparativo['total']['variacao_abs'] = total_variacao_abs
            comparativo['total']['variacao_pct'] = total_variacao_pct
            
            logger.info(f"[Vis√£o Atual] Comparativo calculado. Atual: {total_atual}, Anterior: {total_anterior}, VarAbs: {total_variacao_abs}")
            
            return comparativo
            
        except Exception as e:
            logger.exception(f"[Vis√£o Atual] Erro ao calcular novos projetos: {str(e)}")
            # Retorna estrutura vazia mas correta
            return {
                'por_squad': {squad: {'atual': 0, 'anterior': 0, 'variacao_abs': 0, 'variacao_pct': 0} 
                             for squad in ['AZURE', 'M365', 'DATA E POWER', 'CDB']},
                'total': {'atual': 0, 'anterior': 0, 'variacao_abs': 0, 'variacao_pct': 0}
            }

    def _obter_fonte_historica(self, ano, mes):
        """
        Obt√©m o nome da fonte hist√≥rica para um determinado m√™s/ano.
        
        Args:
            ano (int): Ano
            mes (int): M√™s (1-12)
            
        Returns:
            str: Nome da fonte (sem extens√£o) ou None se n√£o encontrada
        """
        # Mapeamento dos meses para abrevia√ß√µes
        mes_to_abbr = {
            1: 'jan', 2: 'fev', 3: 'mar', 4: 'abr', 5: 'mai', 6: 'jun',
            7: 'jul', 8: 'ago', 9: 'set', 10: 'out', 11: 'nov', 12: 'dez'
        }
        
        if mes in mes_to_abbr:
            fonte = f"dadosr_apt_{mes_to_abbr[mes]}"
            # Verifica se o arquivo existe
            arquivo_path = self.csv_path.parent / f"{fonte}.csv"
            if arquivo_path.exists():
                return fonte
        
        return None

    def obter_detalhes_projeto(self, project_id):
        """
        Busca os detalhes de um projeto espec√≠fico pelo ID.
        OTIMIZADO: Usa cache de 60 segundos para projetos e reduz logs.
        
        Args:
            project_id: ID do projeto (int ou string)
            
        Returns:
            dict: Detalhes do projeto ou None se n√£o encontrado
        """
        # OTIMIZA√á√ÉO: Verificar cache de projeto primeiro (SEM LOGS)
        cached_details = _get_cached_project_details(project_id)
        if cached_details is not None:
            # SEM LOGS para evitar spam - detalhes j√° est√£o no cache
            return cached_details
        
        # Cache miss - buscar projeto
        dados = self.carregar_dados()
        if dados.empty:
            return None
        
        # Converte project_id para int para garantir compatibilidade
        try:
            project_id_int = int(project_id)
        except (ValueError, TypeError):
            # OTIMIZA√á√ÉO: Log apenas em caso de erro real
            logger.warning(f"N√£o foi poss√≠vel converter project_id '{project_id}' para int")
            return None
        
        # Busca o projeto pelo ID
        projeto = dados[dados['Numero'] == project_id_int]
        
        if projeto.empty:
            # OTIMIZA√á√ÉO: Log silenciado para projetos n√£o encontrados (muito comum)
            # logger.warning(f"Projeto com ID {project_id_int} n√£o encontrado")
            return None
        
        # Retorna o primeiro resultado como dicion√°rio
        projeto_dict = projeto.iloc[0].to_dict()
        
        # --- IN√çCIO: Normaliza√ß√£o das chaves ---
        normalized_details = { _normalize_key(k): v for k, v in projeto_dict.items() }
        # --- FIM: Normaliza√ß√£o das chaves ---

        # OTIMIZA√á√ÉO: Cache o resultado para futuras consultas
        _set_cached_project_details(project_id, normalized_details)
        
        # OTIMIZA√á√ÉO: Log silenciado para evitar spam (projeto encontrado √© comum)
        # self.logger.info(f"Projeto encontrado: {projeto_dict.get('Projeto', 'N/A')}")
        
        return normalized_details

    def obter_fontes_disponiveis(self):
        """
        Detecta automaticamente arquivos dadosr_apt_* dispon√≠veis no diret√≥rio de dados.
        Estes s√£o arquivos "legados" que representam um espelho espec√≠fico do m√™s.
        N√ÉO inclui dadosr.csv pois este cont√©m todos os dados (vis√£o atual para Status Report).
        
        Returns:
            list: Lista de dicion√°rios com informa√ß√µes sobre fontes dispon√≠veis
                  Formato: [{'arquivo': 'dadosr_apt_jan', 'nome_exibicao': 'Janeiro/2025', 'mes': 1, 'ano': 2025}, ...]
                  Ordenado do mais recente para o mais antigo
        """
        try:
            logger.info("Detectando fontes de dados dadosr_apt_* dispon√≠veis...")
            
            # Obt√©m o diret√≥rio de dados
            data_dir = self.csv_path.parent
            
            # Lista todos os arquivos CSV que seguem o padr√£o dadosr_apt_*
            arquivos_apt = list(data_dir.glob("dadosr_apt_*.csv"))
            
            fontes = []
            
            # Processa cada arquivo encontrado
            for arquivo in arquivos_apt:
                nome_arquivo = arquivo.stem  # Remove a extens√£o .csv
                
                # Ignora arquivos de backup (que cont√™m '_backup_' no nome)
                if '_backup_' in nome_arquivo:
                    logger.info(f"Ignorando arquivo de backup: {nome_arquivo}")
                    continue
                
                # Extrai a abrevia√ß√£o do m√™s do nome do arquivo
                # Formato esperado: dadosr_apt_abr, dadosr_apt_jan, etc.
                if '_' in nome_arquivo:
                    partes = nome_arquivo.split('_')
                    if len(partes) >= 3:
                        abrev_mes = partes[2]  # 'abr', 'jan', etc.
                        
                        # Mapeia abrevia√ß√£o para m√™s/ano
                        mes_num, ano = self._mapear_abreviacao_para_data(abrev_mes)
                        
                        if mes_num and ano:
                            nome_mes_completo = self._obter_nome_mes_completo(mes_num)
                            fontes.append({
                                'arquivo': nome_arquivo,
                                'nome_exibicao': f"{nome_mes_completo}/{ano}",
                                'mes': mes_num,
                                'ano': ano,
                                'abreviacao': abrev_mes.upper()
                            })
                            logger.info(f"Fonte detectada: {nome_arquivo} -> {nome_mes_completo}/{ano}")
            
            # Ordena por ano e m√™s (mais recente primeiro)
            fontes.sort(key=lambda x: (x['ano'], x['mes']), reverse=True)
            
            logger.info(f"Total de fontes hist√≥ricas detectadas: {len(fontes)}")
            return fontes
            
        except Exception as e:
            logger.error(f"Erro ao detectar fontes dispon√≠veis: {e}")
            return []

    def _mapear_abreviacao_para_data(self, abrev_mes):
        """
        Mapeia abrevia√ß√£o do m√™s para n√∫mero do m√™s e ano.
        
        Args:
            abrev_mes (str): Abrevia√ß√£o do m√™s (ex: 'jan', 'fev', 'mar')
            
        Returns:
            tuple: (mes_num, ano) ou (None, None) se n√£o conseguir mapear
        """
        # Mapeamento de abrevia√ß√µes para n√∫meros de m√™s
        mes_abbr_to_num = {
            'jan': 1, 'fev': 2, 'mar': 3, 'abr': 4, 'mai': 5, 'jun': 6,
            'jul': 7, 'ago': 8, 'set': 9, 'out': 10, 'nov': 11, 'dez': 12
        }
        
        if abrev_mes.lower() not in mes_abbr_to_num:
            logger.warning(f"Abrevia√ß√£o de m√™s desconhecida: {abrev_mes}")
            return None, None
            
        mes_num = mes_abbr_to_num[abrev_mes.lower()]
        
        # L√≥gica melhorada para determinar o ano
        hoje = datetime.now()
        ano_atual = hoje.year
        
        # Para dados hist√≥ricos de 2025, sempre usa 2025
        # Esta l√≥gica pode ser expandida conforme necess√°rio para outros anos
        if ano_atual == 2025:
            ano_assumido = 2025
            logger.info(f"Usando ano 2025 para m√™s {mes_num} (abrev: {abrev_mes})")
        else:
            # L√≥gica para anos futuros: 
            # Se o m√™s √© significativamente maior que o atual (mais de 3 meses), pode ser do ano passado
            # Caso contr√°rio, assume ano atual
            if mes_num > hoje.month + 3:
                ano_assumido = ano_atual - 1
                logger.info(f"M√™s {mes_num} parece ser do ano anterior ({ano_assumido})")
            else:
                ano_assumido = ano_atual
                logger.info(f"Usando ano atual ({ano_assumido}) para m√™s {mes_num}")
            
        return mes_num, ano_assumido
    
    def _obter_nome_mes_pt(self, mes_num):
        """
        Obt√©m o nome do m√™s em portugu√™s para o n√∫mero do m√™s.
        
        Args:
            mes_num (int): N√∫mero do m√™s (1-12)
            
        Returns:
            str: Nome do m√™s abreviado em portugu√™s
        """
        mes_num_to_label = {
            1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Abr', 5: 'Mai', 6: 'Jun',
            7: 'Jul', 8: 'Ago', 9: 'Set', 10: 'Out', 11: 'Nov', 12: 'Dez'
        }
        
        return mes_num_to_label.get(mes_num, f"M√™s{mes_num}")
    
    def _obter_nome_mes_completo(self, mes_num):
        """
        Obt√©m o nome completo do m√™s em portugu√™s para o n√∫mero do m√™s.
        
        Args:
            mes_num (int): N√∫mero do m√™s (1-12)
            
        Returns:
            str: Nome completo do m√™s em portugu√™s
        """
        mes_num_to_nome_completo = {
            1: 'Janeiro', 2: 'Fevereiro', 3: 'Mar√ßo', 4: 'Abril', 5: 'Maio', 6: 'Junho',
            7: 'Julho', 8: 'Agosto', 9: 'Setembro', 10: 'Outubro', 11: 'Novembro', 12: 'Dezembro'
        }
        
        return mes_num_to_nome_completo.get(mes_num, f"M√™s {mes_num}")

    def get_specialist_list(self):
        """Carrega os dados e retorna uma lista √∫nica e ordenada de especialistas."""
        try:
            dados = self.carregar_dados()
            if dados.empty:
                self.logger.warning("Dados vazios para listar especialistas")
                return []
            
            if 'Especialista' not in dados.columns:
                self.logger.error("Coluna 'Especialista' n√£o encontrada no DataFrame")
                return []
            
            # Remove valores nulos e obt√©m lista √∫nica ordenada
            especialistas = dados['Especialista'].dropna().unique()
            especialistas_sorted = sorted(especialistas)
            
            self.logger.info(f"Encontrados {len(especialistas_sorted)} especialistas √∫nicos")
            return especialistas_sorted
            
        except Exception as e:
            self.logger.error(f"Erro ao obter lista de especialistas: {str(e)}")
            return []

    def gerar_dados_status_report(self, project_id):
        """
        Gera os dados necess√°rios para o status report de um projeto espec√≠fico.
        """
        try:
            logger.info(f"Gerando dados de status report para projeto {project_id}")
            
            # Converte project_id para int para garantir compatibilidade
            try:
                project_id_int = int(project_id)
            except (ValueError, TypeError):
                logger.warning(f"N√£o foi poss√≠vel converter project_id '{project_id}' para int")
                return self._get_empty_status_report_data(project_id, f"ID de projeto inv√°lido: {project_id}")
            
            # Carregar dados do projeto
            dados = self.carregar_dados()
            if dados.empty:
                logger.warning("Dados vazios para gerar status report")
                return self._get_empty_status_report_data(project_id, "Dados n√£o dispon√≠veis")
            
            # Buscar projeto espec√≠fico usando o ID convertido
            projeto = dados[dados['Numero'] == project_id_int]
            if projeto.empty:
                logger.warning(f"Projeto {project_id_int} n√£o encontrado")
                return self._get_empty_status_report_data(project_id, f"Projeto {project_id_int} n√£o encontrado")
            
            projeto_row = projeto.iloc[0]
            
            # Calcular progresso - L√ìGICA ESPECIAL PARA DEMANDAS INTERNAS
            servico_terceiro_nivel = projeto_row.get('TipoServico', '')
            
            if servico_terceiro_nivel == 'Demandas Internas':
                # Para Demandas Internas, calcular percentual baseado em tarefas
                percentual_concluido = self._calcular_percentual_por_tarefas(project_id)
                logger.info(f"Projeto Demandas Internas detectado - Percentual calculado por tarefas: {percentual_concluido:.1f}%")
            else:
                # Para projetos normais, usar percentual do CSV
                percentual_concluido = float(projeto_row.get('Conclusao', 0.0))
                logger.info(f"Projeto normal - Percentual do CSV: {percentual_concluido:.1f}%")
            data_vencimento = projeto_row.get('VencimentoEm', 'N/A')
            logger.info(f"Data vencimento bruta: {repr(data_vencimento)} (tipo: {type(data_vencimento)})")
            
            if pd.notna(data_vencimento):
                try:
                    # Usar pandas para convers√£o como nos outros endpoints
                    data_vencimento_dt = pd.to_datetime(data_vencimento)
                    data_prevista_termino = data_vencimento_dt.strftime('%d/%m/%Y')
                    logger.info(f"Data prevista convertida com sucesso: {data_prevista_termino}")
                    
                    # Calcular status do prazo usando pandas Timestamp
                    from datetime import datetime as dt_module  # Import com alias para evitar conflito
                    hoje = dt_module.now()
                    data_vencimento_py = data_vencimento_dt.to_pydatetime()  # Converter para datetime do Python
                    
                    if data_vencimento_py < hoje:
                        status_prazo = 'Atrasado'
                    elif (data_vencimento_py - hoje).days <= 7:
                        status_prazo = 'Pr√≥ximo do Prazo'
                    else:
                        status_prazo = 'No Prazo'
                        
                    logger.info(f"Status do prazo calculado: {status_prazo}")
                except Exception as e:
                    logger.error(f"Erro ao converter data de vencimento: {str(e)}")
                    data_prevista_termino = 'N/A'
                    status_prazo = 'N/A'
            else:
                logger.warning(f"Data de vencimento √© NaT ou inv√°lida: {data_vencimento}")
                data_prevista_termino = 'N/A'
                status_prazo = 'N/A'
            
            # Calcular esfor√ßo - L√ìGICA ESPECIAL PARA DEMANDAS INTERNAS
            horas_trabalhadas = float(projeto_row.get('HorasTrabalhadas', 0))
            horas_restantes = float(projeto_row.get('HorasRestantes', 0))
            
            if servico_terceiro_nivel == 'Demandas Internas':
                # Para Demandas Internas, calcular esfor√ßo baseado em tarefas
                horas_planejadas = self._calcular_esforco_por_tarefas(project_id)
                logger.info(f"Projeto Demandas Internas detectado - Esfor√ßo calculado por tarefas: {horas_planejadas}h")
            else:
                # Para projetos normais, usar esfor√ßo do CSV
                horas_planejadas = horas_trabalhadas + horas_restantes
                logger.info(f"Projeto normal - Esfor√ßo do CSV: {horas_planejadas}h")
            
            if horas_planejadas > 0:
                percentual_consumido = round((horas_trabalhadas / horas_planejadas) * 100, 1)
            else:
                percentual_consumido = 0.0
            
            # === NOVA L√ìGICA DE STATUS GERAL BASEADA EM TAREFAS REAIS ===
            # Inicializar vari√°veis para an√°lise posterior
            status_projeto = projeto_row.get('Status', '').upper()
            status_concluidos = ['FECHADO', 'ENCERRADO', 'RESOLVIDO', 'CANCELADO']
            status_geral_indicador = 'cinza'  # Default
            
            # Buscar backlog_id para o projeto
            backlog_id = self.get_backlog_id_for_project(project_id)
            
            # Buscar milestones do backlog
            milestones = []
            # Inicializar categorias de tarefas
            tarefas_proximo_prazo = []
            tarefas_em_andamento = []
            tarefas_em_revisao = []
            tarefas_pendentes = []
            tarefas_concluidas = []
            
            if backlog_id:
                logger.info(f"Backlog ID encontrado: {backlog_id}")
                
                try:
                    milestones = self.get_milestones_from_backlog(backlog_id)
                    logger.info(f"Milestones encontrados: {len(milestones) if milestones else 0}")
                except Exception as e:
                    logger.error(f"Erro ao buscar milestones: {str(e)}")
                    milestones = []
                
                # Carregar tarefas do backlog
                try:
                    from app.models import Task, Column
                    from datetime import datetime, timedelta
                    
                    all_tasks = Task.query.filter_by(backlog_id=backlog_id).all()
                    logger.info(f"Total de tarefas encontradas: {len(all_tasks)}")
                    
                    hoje = datetime.now()
                    sete_dias = hoje + timedelta(days=7)
                    
                    for task in all_tasks:
                        try:
                            # Determinar o status da tarefa
                            status_nome = 'N/A'
                            if task.column_id:
                                column = Column.query.get(task.column_id)
                                if column:
                                    status_nome = column.name
                            
                            # Determinar data de vencimento
                            data_vencimento = None
                            if task.due_date:
                                data_vencimento = task.due_date
                            elif task.start_date:
                                data_vencimento = task.start_date
                            
                            task_data = {
                                'id': task.id,
                                'titulo': task.title or 'N/A',
                                'descricao': task.description or '',
                                'status': status_nome,
                                'especialista': task.specialist_name or 'N/A',
                                'prioridade': task.priority or 'N/A',
                                'data_criacao': task.created_at.strftime('%d/%m/%Y') if task.created_at else 'N/A',
                                'data_vencimento': data_vencimento.strftime('%d/%m/%Y') if data_vencimento else 'N/A',
                                'data_inicio': task.start_date.strftime('%d/%m/%Y') if task.start_date else 'N/A',
                                'estimativa': task.estimated_effort or 0,
                                'progresso': 0  # N√£o h√° campo progress no modelo, usar 0
                            }
                            
                            # Categorizar tarefa baseado no status da coluna PRIMEIRO
                            status_lower = status_nome.lower()
                            logger.debug(f"Categorizando tarefa '{task.title}' com status '{status_nome}' (lower: '{status_lower}')")
                            
                            # PRIORIDADE 1: Status da coluna (define o estado atual da tarefa)
                            if 'conclu√≠do' in status_lower or 'concluido' in status_lower or 'done' in status_lower or 'finalizado' in status_lower:
                                tarefas_concluidas.append(task_data)
                                logger.debug(f"  ‚Üí Categorizada como CONCLU√çDA")
                            elif 'andamento' in status_lower or 'progresso' in status_lower or 'doing' in status_lower or 'em progresso' in status_lower:
                                tarefas_em_andamento.append(task_data)
                                logger.debug(f"  ‚Üí Categorizada como EM ANDAMENTO")
                            elif 'revis√£o' in status_lower or 'revisao' in status_lower or 'review' in status_lower:
                                tarefas_em_revisao.append(task_data)
                                logger.debug(f"  ‚Üí Categorizada como EM REVIS√ÉO")
                            
                            # PRIORIDADE 2: Tarefas pendentes SEMPRE v√£o para "Pendente" (independente da data)
                            elif 'fazer' in status_lower or 'todo' in status_lower or 'pendente' in status_lower:
                                # TODAS as tarefas pendentes v√£o para se√ß√£o "Pendente"
                                tarefas_pendentes.append(task_data)
                                logger.debug(f"  ‚Üí Categorizada como PENDENTE (status reconhecido)")
                            
                            # PRIORIDADE 3: Demais tarefas (status n√£o reconhecido) - verificar data
                            else:
                                # Verificar data para categorizar tarefas com status desconhecido
                                if data_vencimento and data_vencimento > hoje and data_vencimento <= sete_dias:
                                    # Tarefas com status desconhecido mas com prazo pr√≥ximo
                                    tarefas_proximo_prazo.append(task_data)
                                    logger.debug(f"  ‚Üí Categorizada como PR√ìXIMO PRAZO (status desconhecido, data pr√≥xima)")
                                else:
                                    # Tarefas com status desconhecido sem prazo pr√≥ximo
                                    tarefas_pendentes.append(task_data)
                                    logger.debug(f"  ‚Üí Categorizada como PENDENTE (status desconhecido, sem data pr√≥xima)")
                            
                        except Exception as e:
                            logger.error(f"Erro ao processar tarefa {task.id}: {str(e)}")
                            continue
                    
                    logger.info(f"Tarefas categorizadas: Pr√≥ximo prazo: {len(tarefas_proximo_prazo)}, Em andamento: {len(tarefas_em_andamento)}, Em revis√£o: {len(tarefas_em_revisao)}, Pendentes: {len(tarefas_pendentes)}, Conclu√≠das: {len(tarefas_concluidas)}")
                    
                except Exception as e:
                    logger.error(f"Erro ao carregar tarefas do backlog: {str(e)}")
            else:
                logger.warning(f"Backlog n√£o encontrado para projeto {project_id}")
            
            # === NOVA L√ìGICA INTELIGENTE DE STATUS GERAL ===
            # Usar percentual do CSV (n√£o das tarefas)
            logger.info(f"Percentual do CSV: {percentual_concluido:.1f}%")
            
            # Calcular indicadores de atividade das tarefas
            total_tarefas = len(tarefas_concluidas) + len(tarefas_em_andamento) + len(tarefas_em_revisao) + len(tarefas_pendentes) + len(tarefas_proximo_prazo)
            tarefas_ativas = len(tarefas_em_andamento) + len(tarefas_em_revisao)
            tem_atividade = tarefas_ativas > 0
            percentual_ativo = (tarefas_ativas / total_tarefas * 100) if total_tarefas > 0 else 0
            
            # Verificar se h√° tarefas atrasadas (vencimento passado)
            from datetime import datetime
            hoje = datetime.now()
            tarefas_atrasadas = 0
            
            # Contar tarefas em andamento/pendentes que j√° passaram do prazo
            for task_list in [tarefas_em_andamento, tarefas_em_revisao, tarefas_pendentes]:
                for task in task_list:
                    data_venc_str = task.get('data_vencimento', 'N/A')
                    if data_venc_str != 'N/A':
                        try:
                            data_venc = datetime.strptime(data_venc_str, '%d/%m/%Y')
                            if data_venc < hoje:
                                tarefas_atrasadas += 1
                        except:
                            pass
            
            tem_tarefas_atrasadas = tarefas_atrasadas > 0
            logger.info(f"Tarefas atrasadas: {tarefas_atrasadas}/{total_tarefas}")
            
            # Verificar status do projeto
            status_iniciais = ['NOVO', 'ABERTO']
            projeto_recente = status_projeto in status_iniciais
            projeto_bloqueado = status_projeto == 'BLOQUEADO'
            
            # === ALGORITMO BASEADO NAS ESPECIFICA√á√ïES ===
            if status_projeto in status_concluidos:
                # üîµ AZUL - "Conclu√≠do" - Status oficial conclu√≠do
                status_geral_indicador = 'azul'
                logger.info(f"Status AZUL: Projeto oficialmente conclu√≠do ({status_projeto})")
                
            elif projeto_bloqueado:
                # üî¥ VERMELHO - "Cr√≠tico" - Status BLOQUEADO
                status_geral_indicador = 'vermelho'
                logger.info(f"Status VERMELHO: Projeto bloqueado ({status_projeto})")
                
            elif projeto_recente:
                # ‚ö´ CINZA - "N√£o Iniciado" - Projeto com status NOVO/ABERTO
                status_geral_indicador = 'cinza'
                logger.info(f"Status CINZA: Projeto recente ({status_projeto}) ainda n√£o iniciado")
                
            elif not tem_tarefas_atrasadas and status_prazo != 'Atrasado':
                # üü¢ VERDE - "Saud√°vel" - Tarefas n√£o atrasadas E projeto no prazo
                status_geral_indicador = 'verde'
                logger.info(f"Status VERDE: Projeto saud√°vel - tarefas no prazo e projeto no prazo")
                
            elif percentual_concluido >= 50 and status_prazo == 'Atrasado':
                # üü° AMARELO - "Aten√ß√£o" - Progresso bom (‚â•50%) mas atrasado
                status_geral_indicador = 'amarelo'
                logger.info(f"Status AMARELO: Progresso bom ({percentual_concluido:.1f}%) mas projeto atrasado")
                
            elif percentual_concluido >= 40 and percentual_concluido < 75 and tem_atividade:
                # üü° AMARELO - "Aten√ß√£o" - Progresso moderado (40-74%) com atividade
                status_geral_indicador = 'amarelo'
                logger.info(f"Status AMARELO: Progresso moderado ({percentual_concluido:.1f}%) com atividade ({tarefas_ativas} tarefas)")
                
            elif percentual_concluido >= 15 and percentual_concluido < 40 and percentual_ativo >= 20:
                # üü° AMARELO - "Aten√ß√£o" - Progresso baixo (15-39%) mas com ‚â•20% atividade
                status_geral_indicador = 'amarelo'
                logger.info(f"Status AMARELO: Progresso baixo ({percentual_concluido:.1f}%) mas com {percentual_ativo:.1f}% de atividade")
                
            else:
                # üî¥ VERMELHO - "Cr√≠tico" - Demais casos cr√≠ticos
                if percentual_concluido >= 40 and not tem_atividade:
                    logger.info(f"Status VERMELHO: Progresso moderado ({percentual_concluido:.1f}%) mas sem atividade")
                elif percentual_concluido >= 15 and percentual_ativo < 20:
                    logger.info(f"Status VERMELHO: Progresso baixo ({percentual_concluido:.1f}%) sem atividade suficiente ({percentual_ativo:.1f}%)")
                elif percentual_concluido < 15:
                    logger.info(f"Status VERMELHO: Progresso muito baixo ({percentual_concluido:.1f}%)")
                else:
                    logger.info(f"Status VERMELHO: Situa√ß√£o cr√≠tica n√£o categorizada - progresso: {percentual_concluido:.1f}%, atividade: {percentual_ativo:.1f}%")
                
                status_geral_indicador = 'vermelho'
            
            logger.info(f"Status final: {status_geral_indicador} | Progresso CSV: {percentual_concluido:.1f}% | Tarefas ativas: {tarefas_ativas}/{total_tarefas} | Atrasadas: {tarefas_atrasadas} | Projeto: {status_projeto}")
            
            # Buscar marcos recentes
            try:
                marcos_recentes = self.obter_marcos_recentes(project_id)
                logger.info(f"Marcos recentes encontrados: {len(marcos_recentes) if marcos_recentes else 0}")
            except Exception as e:
                logger.error(f"Erro ao buscar marcos recentes: {str(e)}")
                marcos_recentes = []

            # üÜï NOVO: Buscar fases do projeto
            try:
                fases_projeto = self.obter_fases_projeto(project_id, backlog_id)
                logger.info(f"Fases do projeto encontradas: {len(fases_projeto) if fases_projeto else 0}")
            except Exception as e:
                logger.error(f"Erro ao buscar fases do projeto: {str(e)}")
                fases_projeto = []

            # Buscar riscos e impedimentos do backlog
            riscos_impedimentos = []
            notas_observacoes = []
            
            if backlog_id:
                try:
                    # Buscar riscos
                    from app.models import ProjectRisk, Note
                    
                    project_risks = ProjectRisk.query.filter_by(backlog_id=backlog_id).order_by(ProjectRisk.created_at.desc()).all()
                    for risk in project_risks:
                        risco_data = {
                            'id': risk.id,
                            'titulo': risk.title,  # ‚úÖ ADICIONADO: Campo t√≠tulo
                            'title': risk.title,   # ‚úÖ FALLBACK: Para compatibilidade
                            'descricao': risk.description,
                            'impacto': risk.impact.value if risk.impact else 'N/A',
                            'probabilidade': risk.probability.value if risk.probability else 'N/A',
                            'status': risk.status.value if risk.status else 'N/A',
                            'severidade': risk.severity,
                            'responsavel': risk.responsible or 'N/A',
                            'plano_mitigacao': risk.mitigation_plan or '',
                            'plano_contingencia': risk.contingency_plan or '',
                            'data_identificacao': risk.identified_date.strftime('%d/%m/%Y') if risk.identified_date else 'N/A',
                            'data_resolucao': risk.resolved_date.strftime('%d/%m/%Y') if risk.resolved_date else None,
                            'tendencia': risk.trend or 'N/A'
                        }
                        riscos_impedimentos.append(risco_data)
                    
                    logger.info(f"Riscos encontrados: {len(riscos_impedimentos)}")
                    
                    # Buscar notas e observa√ß√µes  
                    # NOVA ABORDAGEM: Usar flag include_in_status_report (opt-out)
                    # Por padr√£o todas as notas aparecem, apenas as marcadas como False s√£o exclu√≠das
                    project_notes = Note.query.filter_by(
                        backlog_id=backlog_id, 
                        include_in_status_report=True
                    ).order_by(
                        Note.event_date.desc().nulls_last(),  # Ordena por data do evento (mais recente primeiro)
                        Note.created_at.desc()  # Fallback para data de cria√ß√£o
                    ).all()
                    
                    for note in project_notes:
                        # Traduzir campos para portugu√™s
                        categoria_pt = self._traduzir_categoria(note.category)
                        prioridade_pt = self._traduzir_prioridade(note.priority)
                        
                        # Usar data do evento quando dispon√≠vel, sen√£o usar data de cria√ß√£o
                        data_exibicao = note.event_date.strftime('%d/%m/%Y') if note.event_date else (note.created_at.strftime('%d/%m/%Y %H:%M') if note.created_at else 'N/A')
                        
                        nota_data = {
                            'id': note.id,
                            'conteudo': note.content,
                            'categoria': categoria_pt,
                            'prioridade': prioridade_pt,
                            'status_relatorio': note.report_status,
                            'data_criacao': note.created_at.strftime('%d/%m/%Y %H:%M') if note.created_at else 'N/A',
                            'data_evento': note.event_date.strftime('%d/%m/%Y') if note.event_date else None,
                            'data_exibicao': data_exibicao,  # Campo unificado para exibi√ß√£o
                            'tags': [tag.name for tag in note.tags] if note.tags else []
                        }
                        notas_observacoes.append(nota_data)
                    
                    logger.info(f"Notas encontradas: {len(notas_observacoes)}")
                    
                except Exception as e:
                    logger.error(f"Erro ao buscar riscos e notas: {str(e)}")
            
            # Informa√ß√µes gerais do projeto (para compatibilidade)
            info_geral = {
                'id': str(project_id),
                'numero': str(projeto_row.get('Numero', project_id)),
                'nome': str(projeto_row.get('Projeto', 'N/A')),
                'squad': str(projeto_row.get('Squad', 'N/A')),
                'especialista': str(projeto_row.get('Especialista', 'N/A')),
                'account_manager': str(projeto_row.get('Account Manager', 'N/A')),
                'data_inicio': projeto_row.get('DataInicio').strftime('%d/%m/%Y') if pd.notnull(projeto_row.get('DataInicio')) else 'N/A',
                'data_vencimento': projeto_row.get('VencimentoEm').strftime('%d/%m/%Y') if pd.notnull(projeto_row.get('VencimentoEm')) else 'N/A',
                'status': str(projeto_row.get('Status', 'N/A')),
                'status_atual': str(projeto_row.get('Status', 'N/A')),
                'conclusao': projeto_row.get('Conclusao', 0),
                'horas_trabalhadas': projeto_row.get('HorasTrabalhadas', 0),
                'horas_restantes': projeto_row.get('HorasRestantes', 0)
            }
            
            # Montar resultado final na estrutura esperada pelo template
            resultado = {
                'info_geral': info_geral,
                'progresso': {
                    'percentual_concluido': round(percentual_concluido, 1),
                    'data_prevista_termino': data_prevista_termino,
                    'status_prazo': status_prazo
                },
                'esforco': {
                    'horas_planejadas': round(horas_planejadas, 1),
                    'horas_utilizadas': round(horas_trabalhadas, 1),
                    'percentual_consumido': percentual_consumido
                },
                'status_geral_indicador': status_geral_indicador,
                'milestones': milestones or [],
                # Adicionar as tarefas categorizadas
                'tarefas_proximo_prazo': tarefas_proximo_prazo,
                'tarefas_em_andamento': tarefas_em_andamento,
                'tarefas_em_revisao': tarefas_em_revisao,
                'tarefas_pendentes': tarefas_pendentes,
                'tarefas_concluidas': tarefas_concluidas,
                'marcos_recentes': marcos_recentes or [],
                'fases_projeto': fases_projeto or [],  # üÜï NOVO: Fases do projeto
                'backlog_id': backlog_id,
                'riscos_impedimentos': riscos_impedimentos,
                'notas': notas_observacoes,
                'proximos_passos': []
            }
            
            logger.info(f"Status report gerado com sucesso para projeto {project_id}")
            logger.info(f"Progresso: {percentual_concluido}%, Status: {status_prazo}, Indicador: {status_geral_indicador}")
            
            return resultado
            
        except Exception as e:
            logger.exception(f"Erro ao gerar dados de status report para projeto {project_id}: {str(e)}")
            return self._get_empty_status_report_data(project_id, f"Erro interno: {str(e)}")

    def _get_empty_status_report_data(self, project_id, error_message, info_geral=None):
        """
        Retorna uma estrutura vazia de status report em caso de erro.
        """
        default_info = {
            'id': str(project_id),
            'numero': str(project_id),
            'nome': 'Projeto n√£o encontrado',
            'squad': 'N/A',
            'especialista': 'N/A',
            'account_manager': 'N/A',
            'data_inicio': 'N/A',
            'data_vencimento': 'N/A',
            'status': 'N/A',
            'status_atual': 'N/A',
            'conclusao': 0,
            'horas_trabalhadas': 0,
            'horas_restantes': 0
        }
        
        return {
            'info_geral': info_geral or default_info,
            'progresso': {
                'percentual_concluido': 0,
                'data_prevista_termino': 'N/A',
                'status_prazo': 'N/A'
            },
            'esforco': {
                'horas_planejadas': 0,
                'horas_utilizadas': 0,
                'percentual_consumido': 0
            },
            'status_geral_indicador': 'cinza',
            'milestones': [],
            # Corrigir para usar as categorias de tarefas esperadas pelo template
            'tarefas_proximo_prazo': [],
            'tarefas_em_andamento': [],
            'tarefas_em_revisao': [],
            'tarefas_pendentes': [],
            'tarefas_concluidas': [],
            'marcos_recentes': [],
            'fases_projeto': [],  # üÜï NOVO: Fases do projeto
            'backlog_id': None,
            'riscos_impedimentos': [],
            'notas': [],
            'proximos_passos': [],
            'error': error_message
        }

    def obter_marcos_recentes(self, project_id):
        """
        Obt√©m marcos recentes relacionados ao projeto.
        """
        try:
            logger.info(f"Buscando marcos recentes para projeto {project_id}")
            
            # Buscar o backlog_id para o projeto
            backlog_id = self.get_backlog_id_for_project(project_id)
            
            if not backlog_id:
                logger.warning(f"Nenhum backlog encontrado para projeto {project_id}")
                return []
            
            # Buscar os milestones do backlog
            milestones = self.get_milestones_from_backlog(backlog_id)
            
            # Converter para formato esperado pelo template (marcos_recentes)
            marcos_recentes = []
            for milestone in milestones:
                # üîÑ USAR O STATUS REAL CALCULADO
                status_real = milestone.get('status_real', 'Pendente')
                
                marco_data = {
                    'id': milestone.get('id'),
                    'nome': milestone.get('titulo', 'N/A'),
                    'title': milestone.get('titulo', 'N/A'),  # fallback para compatibilidade
                    'data_planejada': milestone.get('data_vencimento', 'N/A'),
                    'due_date': milestone.get('data_vencimento', 'N/A'),  # fallback para compatibilidade
                    'status': status_real,  # üÜï USAR STATUS REAL EM VEZ DE L√ìGICA SIMPLES
                    'atrasado': milestone.get('atrasado', False),
                    'descricao': milestone.get('descricao', ''),
                    'data_criacao': milestone.get('data_criacao', 'N/A'),
                    'data_inicio_real': milestone.get('data_inicio_real'),
                    'criticidade': milestone.get('criticidade', 'M√©dia')
                }
                marcos_recentes.append(marco_data)
            
            logger.info(f"Convertidos {len(marcos_recentes)} milestones para marcos recentes")
            return marcos_recentes
            
        except Exception as e:
            logger.error(f"Erro ao buscar marcos recentes: {str(e)}")
            return []

    def get_backlog_id_for_project(self, project_id):
        """
        Obt√©m o backlog_id associado a um projeto espec√≠fico.
        """
        try:
            from app.models import Backlog  # Import local
            
            # Buscar backlog pelo project_id
            backlog = Backlog.query.filter_by(project_id=str(project_id)).first()
            
            if backlog:
                logger.info(f"Backlog encontrado: ID {backlog.id} para projeto {project_id}")
                return backlog.id
            else:
                logger.warning(f"Nenhum backlog encontrado para projeto {project_id}")
                return None
                
        except Exception as e:
            logger.error(f"Erro ao buscar backlog para projeto {project_id}: {str(e)}")
            return None

    def get_milestones_from_backlog(self, backlog_id):
        """
        Obt√©m os milestones de um backlog espec√≠fico.
        MELHORADO: Agora considera o status real das tarefas para determinar o status do marco.
        """
        try:
            from app.models import ProjectMilestone, Task, Column  # Import local
            
            milestones = ProjectMilestone.query.filter_by(backlog_id=backlog_id).all()
            
            milestones_data = []
            for milestone in milestones:
                # üîÑ NOVA L√ìGICA: Determinar status baseado no estado real das tarefas
                status_real = self._determinar_status_real_marco(milestone, backlog_id)
                
                milestone_data = {
                    'id': milestone.id,
                    'titulo': milestone.name or 'N/A',
                    'descricao': milestone.description or '',
                    'data_vencimento': milestone.planned_date.strftime('%d/%m/%Y') if milestone.planned_date else 'N/A',
                    'concluido': status_real == 'Conclu√≠do',
                    'status_real': status_real,  # üÜï NOVO: Status calculado baseado nas tarefas
                    'data_criacao': milestone.created_at.strftime('%d/%m/%Y') if milestone.created_at else 'N/A',
                    'data_inicio_real': milestone.started_at.strftime('%d/%m/%Y') if milestone.started_at else None,
                    'atrasado': milestone.is_delayed,
                    'criticidade': milestone.criticality.value if milestone.criticality else 'M√©dia'
                }
                milestones_data.append(milestone_data)
            
            logger.info(f"Encontrados {len(milestones_data)} milestones para backlog {backlog_id}")
            return milestones_data
            
        except Exception as e:
            logger.error(f"Erro ao buscar milestones do backlog {backlog_id}: {str(e)}")
            return []

    def _determinar_status_real_marco(self, milestone, backlog_id):
        """
        Determina o status real do marco baseado no estado das tarefas relacionadas.
        """
        try:
            from app.models import Task, Column
            from datetime import datetime
            
            # Se o marco tem data de in√≠cio real, ent√£o pelo menos come√ßou
            if milestone.started_at:
                logger.info(f"Marco '{milestone.name}' tem data de in√≠cio: {milestone.started_at}")
                
                # Se est√° marcado como conclu√≠do no banco, mant√©m conclu√≠do
                if milestone.status.value == 'Conclu√≠do':
                    return 'Conclu√≠do'
                else:
                    # Se come√ßou mas n√£o foi conclu√≠do, est√° em andamento
                    return 'Em Andamento'
            
            # Verificar se h√° tarefas relacionadas ao marco no backlog
            # Vamos considerar que marcos est√£o relacionados por nome ou proximidade temporal
            marco_nome = milestone.name.lower()
            
            # Buscar tarefas que podem estar relacionadas ao marco
            all_tasks = Task.query.filter_by(backlog_id=backlog_id).all()
            
            tarefas_relacionadas = []
            for task in all_tasks:
                if task.title and any(palavra in task.title.lower() for palavra in marco_nome.split()):
                    tarefas_relacionadas.append(task)
            
            logger.info(f"Marco '{milestone.name}': {len(tarefas_relacionadas)} tarefas relacionadas encontradas")
            
            if not tarefas_relacionadas:
                # Se n√£o h√° tarefas relacionadas, usar o status do banco
                return milestone.status.value
            
            # Analisar status das tarefas relacionadas
            status_tarefas = []
            for task in tarefas_relacionadas:
                if task.column_id:
                    column = Column.query.get(task.column_id)
                    if column:
                        status_tarefas.append(column.name.lower())
            
            if not status_tarefas:
                return milestone.status.value
            
            # L√≥gica para determinar status do marco baseado nas tarefas
            concluidas = sum(1 for status in status_tarefas if any(palavra in status for palavra in ['conclu√≠', 'done', 'finalizado']))
            em_andamento = sum(1 for status in status_tarefas if any(palavra in status for palavra in ['andamento', 'progress', 'execu']))
            
            logger.info(f"Marco '{milestone.name}': {concluidas} tarefas conclu√≠das, {em_andamento} em andamento de {len(status_tarefas)} total")
            
            if concluidas == len(status_tarefas):
                return 'Conclu√≠do'
            elif em_andamento > 0 or concluidas > 0:
                return 'Em Andamento'
            else:
                return 'Pendente'
                
        except Exception as e:
            logger.error(f"Erro ao determinar status real do marco: {str(e)}")
            return milestone.status.value if milestone.status else 'Pendente'

    def obter_fases_projeto(self, project_id, backlog_id=None):
        """
        Obt√©m as fases do projeto com informa√ß√µes sobre progresso e status.
        """
        try:
            from app.models import Backlog, ProjectPhaseConfiguration, ProjectMilestone
            
            if not backlog_id:
                backlog_id = self.get_backlog_id_for_project(project_id)
            
            if not backlog_id:
                logger.warning(f"Nenhum backlog encontrado para projeto {project_id}")
                return []
            
            # Buscar configura√ß√£o do backlog
            backlog = Backlog.query.get(backlog_id)
            if not backlog:
                logger.warning(f"Backlog {backlog_id} n√£o encontrado")
                return []
            
            # üîÑ CORRE√á√ÉO: Determinar tipo de projeto usando ProjectPhaseService
            from app.utils.project_phase_service import ProjectPhaseService
            phase_service = ProjectPhaseService()
            
            # Obt√©m o tipo de projeto do servi√ßo
            project_type_enum = phase_service.get_project_type(project_id)
            
            # Se n√£o h√° tipo definido, assume waterfall como padr√£o
            if not project_type_enum:
                logger.warning(f"Tipo de projeto n√£o definido para projeto {project_id}, usando Waterfall como padr√£o")
                from app.models import ProjectType
                project_type_enum = ProjectType.WATERFALL
            
            # Determina o tipo como string para logs
            project_type_str = project_type_enum.value.lower()
            current_phase = backlog.current_phase or 1
            
            logger.info(f"Projeto {project_id}: Tipo={project_type_str}, Fase atual={current_phase}")
            
            # Buscar configura√ß√£o das fases para o tipo de projeto
            fases_config = ProjectPhaseConfiguration.get_phases_for_type(project_type_enum)
            
            # Se n√£o h√° configura√ß√£o, criar fases padr√£o
            if not fases_config:
                fases_config = self._criar_fases_padrao(project_type_str)
            
            # Buscar marcos do projeto
            milestones = self.get_milestones_from_backlog(backlog_id)
            
            # Mapear marcos para fases
            fases_timeline = []
            for fase_config in fases_config:
                fase_number = fase_config.phase_number if hasattr(fase_config, 'phase_number') else fase_config.get('phase_number', 1)
                fase_name = fase_config.phase_name if hasattr(fase_config, 'phase_name') else fase_config.get('phase_name', 'Fase')
                fase_color = fase_config.phase_color if hasattr(fase_config, 'phase_color') else fase_config.get('phase_color', '#E8F5E8')
                
                # Determinar status da fase
                if fase_number < current_phase:
                    status = 'completed'
                elif fase_number == current_phase:
                    status = 'current'
                else:
                    status = 'pending'
                
                # Buscar marcos relacionados √† fase
                marcos_da_fase = []
                milestone_names = []
                if hasattr(fase_config, 'get_milestone_names'):
                    milestone_names = fase_config.get_milestone_names()
                elif isinstance(fase_config, dict) and 'milestone_names' in fase_config:
                    milestone_names = fase_config['milestone_names']
                
                # Encontrar marcos que correspondem aos nomes esperados
                for milestone_name in milestone_names:
                    for milestone in milestones:
                        if milestone_name.lower() in milestone.get('titulo', '').lower():
                            marcos_da_fase.append({
                                'nome': milestone.get('titulo'),
                                'status': milestone.get('status_real', 'Pendente'),
                                'data_planejada': milestone.get('data_vencimento'),
                                'atrasado': milestone.get('atrasado', False)
                            })
                            break
                
                # Calcular progresso da fase baseado nos marcos
                total_marcos = len(marcos_da_fase)
                marcos_concluidos = sum(1 for marco in marcos_da_fase if marco['status'] == 'Conclu√≠do')
                marcos_em_andamento = sum(1 for marco in marcos_da_fase if marco['status'] == 'Em Andamento')
                
                if total_marcos > 0:
                    progresso = int((marcos_concluidos / total_marcos) * 100)
                    if marcos_em_andamento > 0 and progresso == 0:
                        progresso = 25  # Mostrar algum progresso se h√° marcos em andamento
                else:
                    progresso = 100 if status == 'completed' else (50 if status == 'current' else 0)
                
                fase_data = {
                    'numero': fase_number,
                    'nome': fase_name,
                    'status': status,
                    'cor': fase_color,
                    'progresso': progresso,
                    'marcos': marcos_da_fase,
                    'descricao': fase_config.phase_description if hasattr(fase_config, 'phase_description') else fase_config.get('phase_description', '')
                }
                
                fases_timeline.append(fase_data)
                
            logger.info(f"Fases do projeto {project_id}: {len(fases_timeline)} fases carregadas")
            return fases_timeline
            
        except Exception as e:
            logger.error(f"Erro ao obter fases do projeto {project_id}: {str(e)}")
            return []

    def _criar_fases_padrao(self, project_type):
        """
        Cria fases padr√£o se n√£o houver configura√ß√£o no banco.
        """
        if project_type == 'waterfall':
            return [
                {'phase_number': 1, 'phase_name': 'Planejamento', 'phase_color': '#E8F5E8', 'milestone_names': ['Milestone Start']},
                {'phase_number': 2, 'phase_name': 'Execu√ß√£o', 'phase_color': '#E8F0FF', 'milestone_names': ['Milestone Setup']},
                {'phase_number': 3, 'phase_name': 'CutOver', 'phase_color': '#FFF8E1', 'milestone_names': ['Milestone CutOver']},
                {'phase_number': 4, 'phase_name': 'GoLive', 'phase_color': '#E8FFE8', 'milestone_names': ['Milestone Finish Project']}
            ]
        else:  # agile
            return [
                {'phase_number': 1, 'phase_name': 'Planejamento', 'phase_color': '#E8F5E8', 'milestone_names': ['Milestone Start']},
                {'phase_number': 2, 'phase_name': 'Sprint Planning', 'phase_color': '#F0F8FF', 'milestone_names': ['Milestone Setup']},
                {'phase_number': 3, 'phase_name': 'Desenvolvimento', 'phase_color': '#E8F0FF', 'milestone_names': ['Milestone Developer']},
                {'phase_number': 4, 'phase_name': 'CutOver', 'phase_color': '#FFF8E1', 'milestone_names': ['Milestone CutOver']},
                {'phase_number': 5, 'phase_name': 'GoLive', 'phase_color': '#E8FFE8', 'milestone_names': ['Milestone Finish Project']}
            ]

    def gerar_status_report(self, project_id):
        """
        Gera um status report completo para um projeto.
        """
        try:
            logger.info(f"Gerando status report para projeto {project_id}")
            
            # Gerar dados do relat√≥rio
            dados_relatorio = self.gerar_dados_status_report(project_id)
            
            # Aqui voc√™ pode adicionar l√≥gica adicional de formata√ß√£o se necess√°rio
            
            return dados_relatorio
            
        except Exception as e:
            logger.exception(f"Erro ao gerar status report para projeto {project_id}: {str(e)}")
            return self._get_empty_status_report_data(project_id, f"Erro ao gerar relat√≥rio: {str(e)}")

    def _adicionar_verificacao_backlog(self, dataframe):
        """
        M√©todo auxiliar para adicionar a coluna 'backlog_exists' a um DataFrame.
        Verifica quais projetos t√™m backlog no banco de dados.
        """
        if dataframe.empty or 'Numero' not in dataframe.columns:
            logger.info("DataFrame vazio ou sem coluna 'Numero'. Pulando verifica√ß√£o de backlog.")
            if 'Numero' in dataframe.columns:
                dataframe['backlog_exists'] = False
            return dataframe
            
        # Garante que 'Numero' seja string para a consulta do backlog
        dataframe['Numero'] = dataframe['Numero'].astype(str)
        
        # Pega todos os IDs de projeto (n√∫meros) √∫nicos e n√£o vazios
        project_ids = dataframe['Numero'].dropna().unique().tolist()
        project_ids = [pid for pid in project_ids if pid]  # Remove vazios

        if project_ids:
            try:
                # Importa o modelo Backlog e db localmente para evitar importa√ß√£o circular
                from app.models import Backlog
                from app import db
                
                # Consulta o banco para ver quais IDs t√™m backlog
                backlogs_existentes = db.session.query(Backlog.project_id)\
                                                .filter(Backlog.project_id.in_(project_ids))\
                                                .all()
                # Cria um set com os IDs que t√™m backlog para busca r√°pida
                ids_com_backlog = {result[0] for result in backlogs_existentes}
                logger.info(f"Encontrados {len(ids_com_backlog)} backlogs para {len(project_ids)} projetos ativos verificados.")
                
                # Adiciona a coluna 'backlog_exists' ao DataFrame
                dataframe['backlog_exists'] = dataframe['Numero'].apply(lambda pid: pid in ids_com_backlog if pd.notna(pid) else False)

            except Exception as db_error:
                logger.error(f"Erro ao consultar backlogs existentes: {db_error}", exc_info=True)
                # Se der erro no DB, assume que nenhum backlog existe para n√£o quebrar
                dataframe['backlog_exists'] = False
        else:
            logger.info("Nenhum ID de projeto v√°lido encontrado para verificar backlog.")
            dataframe['backlog_exists'] = False
            
        return dataframe

    def calcular_metricas_tipos_servico_simples(self, dados):
        """
        Calcula m√©tricas b√°sicas por tipo de servi√ßo usando categoriza√ß√£o CSV.
        Vers√£o simples e incremental.
        
        Args:
            dados (pd.DataFrame): DataFrame com os projetos
            
        Returns:
            dict: M√©tricas organizadas por categoria
        """
        try:
            from .typeservice_reader import type_service_reader
            
            logger.info("üîÑ Calculando m√©tricas simples dos tipos de servi√ßo...")
            
            # Valida arquivo CSV primeiro
            valido, mensagem = type_service_reader.validar_arquivo()
            if not valido:
                logger.error(f"‚ùå Arquivo CSV inv√°lido: {mensagem}")
                return {'erro': mensagem, 'categorias': {}, 'tipos': {}}
            
            logger.info(f"‚úÖ {mensagem}")
            
            # Verifica coluna TipoServico nos dados
            if 'TipoServico' not in dados.columns:
                logger.warning("Coluna 'TipoServico' n√£o encontrada nos dados")
                return {'erro': 'Coluna TipoServico n√£o encontrada', 'categorias': {}, 'tipos': {}}
            
            # Prepara dados b√°sicos
            dados_limpos = dados[dados['TipoServico'].notna() & (dados['TipoServico'] != '')].copy()
            
            if dados_limpos.empty:
                logger.warning("Nenhum projeto com tipo de servi√ßo v√°lido")
                return {'erro': 'Nenhum projeto com tipo de servi√ßo v√°lido', 'categorias': {}, 'tipos': {}}
            
            # Carrega mapeamento do CSV
            mapeamento_tipos = type_service_reader.carregar_tipos_servico()
            
            # Calcula m√©tricas por tipo
            metricas_tipos = {}
            metricas_categorias = {}
            
            tipos_unicos = dados_limpos['TipoServico'].unique()
            
            for tipo in tipos_unicos:
                dados_tipo = dados_limpos[dados_limpos['TipoServico'] == tipo]
                categoria = type_service_reader.obter_categoria(tipo)
                
                # M√©tricas b√°sicas do tipo
                metricas_tipo = {
                    'nome': tipo,
                    'categoria': categoria,
                    'total_projetos': len(dados_tipo),
                    'projetos_ativos': len(dados_tipo[~dados_tipo['Status'].isin(['FECHADO', 'ENCERRADO', 'RESOLVIDO', 'CANCELADO'])]),
                    'projetos_concluidos': len(dados_tipo[dados_tipo['Status'].isin(['FECHADO', 'ENCERRADO', 'RESOLVIDO', 'CANCELADO'])])
                }
                
                # Adiciona horas se dispon√≠vel
                if 'Horas' in dados_tipo.columns:
                    metricas_tipo['horas_totais'] = float(dados_tipo['Horas'].sum())
                else:
                    metricas_tipo['horas_totais'] = 0.0
                
                metricas_tipos[tipo] = metricas_tipo
                
                # Agrega por categoria
                if categoria not in metricas_categorias:
                    metricas_categorias[categoria] = {
                        'nome': categoria,
                        'total_projetos': 0,
                        'projetos_ativos': 0,
                        'projetos_concluidos': 0,
                        'horas_totais': 0.0,
                        'tipos_na_categoria': []
                    }
                
                metricas_categorias[categoria]['total_projetos'] += metricas_tipo['total_projetos']
                metricas_categorias[categoria]['projetos_ativos'] += metricas_tipo['projetos_ativos']
                metricas_categorias[categoria]['projetos_concluidos'] += metricas_tipo['projetos_concluidos']
                metricas_categorias[categoria]['horas_totais'] += metricas_tipo['horas_totais']
                metricas_categorias[categoria]['tipos_na_categoria'].append(tipo)
            
            # Adiciona informa√ß√µes de per√≠odo
            import datetime
            data_atual = datetime.datetime.now()
            
            # Pega datas m√≠nima e m√°xima dos dados se dispon√≠vel
            periodo_info = {
                'data_analise': data_atual.strftime('%d/%m/%Y %H:%M'),
                'mes_referencia': data_atual.strftime('%m/%Y'),
                'total_registros_analisados': len(dados_limpos)
            }
            
            # Tenta obter per√≠odo dos dados se houver coluna de data
            if 'DataCriacao' in dados_limpos.columns or 'DataInicio' in dados_limpos.columns:
                coluna_data = 'DataCriacao' if 'DataCriacao' in dados_limpos.columns else 'DataInicio'
                try:
                    # Converte para datetime se necess√°rio
                    datas_validas = pd.to_datetime(dados_limpos[coluna_data], errors='coerce').dropna()
                    if not datas_validas.empty:
                        periodo_info['data_inicio'] = datas_validas.min().strftime('%d/%m/%Y')
                        periodo_info['data_fim'] = datas_validas.max().strftime('%d/%m/%Y')
                        periodo_info['periodo_dias'] = (datas_validas.max() - datas_validas.min()).days
                except:
                    pass
            
            resultado = {
                'tipos': metricas_tipos,
                'categorias': metricas_categorias,
                'resumo': {
                    'total_tipos': len(tipos_unicos),
                    'total_categorias': len(metricas_categorias),
                    'total_projetos': len(dados_limpos),
                    'tipos_cadastrados_csv': len(mapeamento_tipos)
                },
                'periodo': periodo_info,
                'status': 'sucesso'
            }
            
            logger.info(f"‚úÖ M√©tricas calculadas: {len(tipos_unicos)} tipos, {len(metricas_categorias)} categorias")
            return resultado
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao calcular m√©tricas tipos de servi√ßo: {str(e)}", exc_info=True)
            return {
                'erro': str(e),
                'categorias': {},
                'tipos': {},
                'status': 'erro'
            }

    def calcular_projetos_principais_mes(self, dados, mes_referencia=None):
        """
        Calcula os 5 principais projetos do m√™s baseado em:
        1. Sele√ß√£o manual (quando dispon√≠vel) 
        2. Volume de horas trabalhadas ESPECIFICAMENTE no m√™s (fallback autom√°tico)
        
        Args:
            dados (pd.DataFrame): DataFrame com os dados dos projetos do m√™s atual
            mes_referencia (datetime): M√™s de refer√™ncia para o c√°lculo
            
        Returns:
            dict: Lista com os 5 principais projetos e suas informa√ß√µes
        """
        try:
            logger.info(f"üöÄ CALCULAR: Iniciando calcular_projetos_principais_mes")
            logger.info(f"üöÄ CALCULAR: dados.shape = {dados.shape if not dados.empty else 'VAZIO'}")
            logger.info(f"üöÄ CALCULAR: mes_referencia = {mes_referencia}")
            
            if dados.empty:
                logger.warning("‚ö†Ô∏è CALCULAR: DataFrame vazio para calcular projetos principais do m√™s")
                return {'projetos': [], 'total_encontrados': 0}
            
            logger.info(f"üìä CALCULAR: Calculando projetos principais do m√™s: {mes_referencia.strftime('%B/%Y') if mes_referencia else 'atual'}")
            
            logger.info(f"üìä CALCULAR: Preparando dados base...")
            dados_base = self.preparar_dados_base(dados)
            logger.info(f"üìä CALCULAR: Dados base preparados: {dados_base.shape}")
            
            # === CALCULAR HORAS TRABALHADAS NO M√äS ESPEC√çFICO ===
            logger.info(f"‚è∞ CALCULAR: Calculando horas trabalhadas no m√™s...")
            dados_com_horas_mes = self._calcular_horas_trabalhadas_no_mes(dados_base, mes_referencia)
            logger.info(f"‚è∞ CALCULAR: Horas calculadas para {dados_com_horas_mes.shape[0]} projetos")
            
            # Filtros para projetos principais:
            # 1. Tem horas trabalhadas no m√™s espec√≠fico
            # 2. N√£o s√£o projetos cancelados
            
            logger.info(f"üîç CALCULAR: Aplicando filtros...")
            projetos_filtrados = dados_com_horas_mes[
                (dados_com_horas_mes['horas_trabalhadas_mes'].fillna(0) > 0) &  # Tem horas trabalhadas no m√™s
                (~dados_com_horas_mes['Status'].isin(['CANCELADO']))  # Exclui cancelados
            ].copy()
            
            logger.info(f"üîç CALCULAR: Projetos filtrados (com horas trabalhadas no m√™s): {len(projetos_filtrados)}")
            
            if projetos_filtrados.empty:
                logger.warning("‚ö†Ô∏è CALCULAR: Nenhum projeto encontrado com atividade no m√™s")
                return {'projetos': [], 'total_encontrados': 0}
                
            logger.info(f"‚úÖ CALCULAR: {len(projetos_filtrados)} projetos passaram nos filtros, prosseguindo...")
            
            # === VERIFICAR SE H√Å SELE√á√ÉO MANUAL ===
            logger.info(f"üîç CALCULAR: CHEGOU AT√â A VERIFICA√á√ÉO DE SELE√á√ÉO MANUAL!")
            logger.info(f"üîç CALCULAR: Chamando carregar_projetos_principais_selecionados...")
            projetos_selecionados_manual = self.carregar_projetos_principais_selecionados(mes_referencia)
            
            logger.info(f"üîç CARD: Verificando sele√ß√£o manual para {mes_referencia.strftime('%Y-%m') if mes_referencia else 'None'}")
            logger.info(f"üîç CARD: Projetos selecionados manual: {projetos_selecionados_manual}")
            logger.info(f"üîç CARD: Total projetos filtrados dispon√≠veis: {len(projetos_filtrados)}")
            
            if projetos_selecionados_manual:
                logger.info(f"‚úÖ CARD: Usando sele√ß√£o manual: {len(projetos_selecionados_manual)} projetos configurados")
                logger.info(f"üîç CARD: N√∫meros √∫nicos nos dados: {list(projetos_filtrados['Numero'].unique())[:10]}...")
                
                # Debug: verificar tipos de dados
                tipos_manual = [type(x) for x in projetos_selecionados_manual[:3]]
                tipos_dados = [type(x) for x in projetos_filtrados['Numero'].head(3)]
                logger.info(f"üîç CARD: Tipos manual: {tipos_manual}, Tipos dados: {tipos_dados}")
                
                # Converter ambos para string para compara√ß√£o consistente
                projetos_selecionados_manual_str = [str(x) for x in projetos_selecionados_manual]
                projetos_filtrados_str = projetos_filtrados.copy()
                projetos_filtrados_str['Numero'] = projetos_filtrados_str['Numero'].astype(str)
                
                # Filtrar apenas os projetos selecionados manualmente que existem nos dados
                top_projetos = projetos_filtrados_str[
                    projetos_filtrados_str['Numero'].isin(projetos_selecionados_manual_str)
                ].copy()
                
                logger.info(f"üîç CARD: Projetos encontrados na sele√ß√£o: {len(top_projetos)}")
                logger.info(f"üîç CARD: N√∫meros encontrados: {list(top_projetos['Numero'].values)}")
                
                if not top_projetos.empty:
                    # Manter a ordem da sele√ß√£o manual
                    top_projetos = top_projetos.set_index('Numero').loc[
                        [num for num in projetos_selecionados_manual_str if num in top_projetos.index]
                    ].reset_index()
                    
                    # Converter de volta para tipo original
                    top_projetos['Numero'] = top_projetos['Numero'].astype(projetos_filtrados['Numero'].dtype)
                    
                    criterio_usado = f"Sele√ß√£o manual ({len(top_projetos)} projetos configurados)"
                    logger.info(f"‚úÖ CARD: Projetos manuais selecionados com sucesso: {len(top_projetos)}")
                else:
                    logger.warning(f"‚ö†Ô∏è  CARD: Nenhum projeto manual encontrado nos dados dispon√≠veis!")
                    logger.info(f"üîç CARD: Fallback para sele√ß√£o autom√°tica")
                    top_projetos = projetos_filtrados.nlargest(5, 'horas_trabalhadas_mes')
                    criterio_usado = "Volume de horas trabalhadas no m√™s (fallback - projetos manuais n√£o encontrados)"
                
            else:
                logger.info("üîÑ CARD: Nenhuma sele√ß√£o manual encontrada, usando ranking autom√°tico por horas")
                
                # Ordena apenas por horas trabalhadas no m√™s espec√≠fico (crit√©rio principal)
                # Ordena por horas trabalhadas no m√™s e pega top 5
                top_projetos = projetos_filtrados.nlargest(5, 'horas_trabalhadas_mes')
                criterio_usado = "Volume de horas trabalhadas no m√™s"
                logger.info(f"üîÑ CARD: Sele√ß√£o autom√°tica: {len(top_projetos)} projetos por ranking")
            
            # === BUSCAR INFORMA√á√ïES COMPLEMENTARES (DE-PARA) ===
            top_projetos_enriquecido = self._enriquecer_projetos_com_historico(top_projetos, mes_referencia)
            
            # Formata dados para o template
            projetos_principais = []
            for _, projeto in top_projetos_enriquecido.iterrows():
                # Usa andamento da coluna Conclusao
                andamento = projeto.get('Conclusao', 0)
                if pd.isna(andamento):
                    andamento = 0
                andamento = round(float(andamento), 1)
                
                # Formata data brasileira sem hor√°rio
                data_prevista = self._formatar_data_brasileira(projeto.get('VencimentoEm'))
                
                # Nome do cliente com m√∫ltiplas tentativas de extra√ß√£o
                nome_cliente = projeto.get('nome_cliente_enriquecido', projeto.get('Cliente', 'N/A'))
                nome_projeto = projeto.get('Projeto', 'N/A')
                
                # Se n√£o conseguiu obter do hist√≥rico ou coluna Cliente, tenta extrair do nome do projeto
                if nome_cliente == 'N/A' and nome_projeto and nome_projeto != 'N/A':
                    # TENTATIVA ESPECIAL: Projetos internos da SOU.cloud
                    # Mais espec√≠fico para evitar falsos positivos como PBSF que cont√©m "SOU PLUS"
                    projeto_upper = nome_projeto.upper()
                    is_sou_internal = (
                        'COPILOT' in projeto_upper or
                        'SHAREPOINT' in projeto_upper or 
                        'REESTRUTURA' in projeto_upper or
                        'INTERNO' in projeto_upper or
                        'INTERNAL' in projeto_upper or
                        (projeto_upper.startswith('SOU ') or projeto_upper.endswith(' SOU') or projeto_upper == 'SOU') or
                        ('PMO' in projeto_upper and 'SOU' in projeto_upper) or
                        ('CONTROL' in projeto_upper and 'SOU' in projeto_upper)
                    )
                    
                    if is_sou_internal:
                        nome_cliente = 'SOU.cloud'
                        logger.debug(f"Projeto interno detectado: {nome_projeto} -> Cliente: SOU.cloud")
                    # Tentativa 1: separador " - "
                    elif ' - ' in nome_projeto:
                        partes = nome_projeto.split(' - ', 1)
                        if len(partes) >= 2:
                            nome_cliente = partes[0].strip()
                            nome_projeto = partes[1].strip()
                    # Tentativa 2: separador " | "
                    elif ' | ' in nome_projeto:
                        partes = nome_projeto.split(' | ', 1)
                        if len(partes) >= 2:
                            nome_cliente = partes[0].strip()
                            nome_projeto = partes[1].strip()
                    # Tentativa 3: separador ": "
                    elif ': ' in nome_projeto:
                        partes = nome_projeto.split(': ', 1)
                        if len(partes) >= 2:
                            nome_cliente = partes[0].strip()
                            nome_projeto = partes[1].strip()
                    # Se chegou at√© aqui, tenta extrair as duas primeiras palavras se houver espa√ßos
                    elif ' ' in nome_projeto:
                        palavras = nome_projeto.split()
                        if len(palavras) >= 2:
                            nome_cliente = ' '.join(palavras[:2])
                            logger.debug(f"Cliente extra√≠do das primeiras palavras: {nome_cliente}")
                
                # Aplica truncamento para nomes muito longos (exceto SOU.cloud)
                if nome_cliente != 'N/A' and nome_cliente != 'SOU.cloud':
                    nome_cliente = self._truncar_nome_cliente(nome_cliente)
                
                projeto_info = {
                    'numero': projeto.get('Numero', ''),
                    'nome_cliente': nome_cliente,
                    'nome_projeto': nome_projeto,
                    'data_prevista': data_prevista,
                    'squad': projeto.get('Squad', 'N/A'),
                    'andamento': andamento,
                    'horas_estimadas': round(projeto.get('Horas', 0), 1),
                    'horas_trabalhadas_mes': round(projeto.get('horas_trabalhadas_mes', 0), 1),
                    'posicao': len(projetos_principais) + 1,  # Posi√ß√£o no ranking
                    'status': projeto.get('Status', 'N/A')
                }
                projetos_principais.append(projeto_info)
            
            logger.info(f"‚úÖ CARD: Top {len(projetos_principais)} projetos principais calculados: {[p['nome_projeto'] for p in projetos_principais]}")
            logger.info(f"üìä CARD: Crit√©rio usado: {criterio_usado}")
            logger.info(f"üìä CARD: Total projetos retornados: {len(projetos_principais)}")
            
            resultado = {
                'projetos': projetos_principais,
                'total_encontrados': len(projetos_filtrados),
                'criterios': criterio_usado
            }
            
            logger.info(f"üéØ CARD: Retornando resultado final com {len(resultado['projetos'])} projetos")
            return resultado
            
        except Exception as e:
            logger.error(f"Erro ao calcular projetos principais do m√™s: {str(e)}", exc_info=True)
            return {'projetos': [], 'total_encontrados': 0}

    def _calcular_horas_trabalhadas_no_mes(self, dados, mes_referencia):
        """
        Calcula as horas trabalhadas especificamente no m√™s analisado.
        F√≥rmula: Horas_Atual - Horas_Ultimo_Mes_Encontrado
        
        Busca o projeto nos √∫ltimos 6 meses para encontrar a base de compara√ß√£o mais recente.
        """
        try:
            if mes_referencia is None:
                logger.warning("M√™s de refer√™ncia n√£o fornecido para c√°lculo de horas do m√™s")
                dados['horas_trabalhadas_mes'] = dados.get('HorasTrabalhadas', 0)
                return dados
            
            logger.info(f"Calculando horas trabalhadas especificamente no m√™s: {mes_referencia.strftime('%B/%Y')}")
            
            # Prepara resultado
            dados_resultado = dados.copy()
            dados_resultado['horas_trabalhadas_mes'] = 0.0
            
            # Para cada projeto, busca nos √∫ltimos 6 meses para encontrar a base de compara√ß√£o
            for index, projeto_atual in dados.iterrows():
                numero_projeto = projeto_atual.get('Numero')
                horas_atuais = float(projeto_atual.get('HorasTrabalhadas', 0) or 0)
                
                if pd.isna(numero_projeto):
                    # Sem n√∫mero do projeto, n√£o consegue comparar
                    dados_resultado.at[index, 'horas_trabalhadas_mes'] = horas_atuais
                    continue
                
                # Busca o projeto nos √∫ltimos 6 meses
                horas_base_encontrada = None
                mes_base_encontrado = None
                
                for i in range(1, 7):  # Busca nos √∫ltimos 6 meses
                    try:
                        # Calcula m√™s a verificar
                        if mes_referencia.month - i <= 0:
                            mes_busca = mes_referencia.replace(
                                year=mes_referencia.year - 1, 
                                month=12 + (mes_referencia.month - i)
                            )
                        else:
                            mes_busca = mes_referencia.replace(month=mes_referencia.month - i)
                        
                        # Tenta carregar dados desse m√™s
                        fonte_busca = self._obter_fonte_historica(mes_busca.year, mes_busca.month)
                        if not fonte_busca:
                            continue
                            
                        dados_busca = self.carregar_dados(fonte=fonte_busca)
                        if dados_busca.empty:
                            continue
                            
                        # Procura o projeto neste m√™s
                        projeto_encontrado = dados_busca[dados_busca['Numero'] == numero_projeto]
                        if not projeto_encontrado.empty:
                            horas_base_encontrada = float(projeto_encontrado.iloc[0].get('HorasTrabalhadas', 0) or 0)
                            mes_base_encontrado = mes_busca.strftime('%B/%Y')
                            logger.debug(f"Projeto {numero_projeto}: encontrado base em {mes_base_encontrado} com {horas_base_encontrada}h")
                            break
                            
                    except Exception as e:
                        logger.debug(f"Erro ao buscar projeto {numero_projeto} em m√™s anterior: {str(e)}")
                        continue
                
                # Calcula horas trabalhadas no m√™s espec√≠fico
                if horas_base_encontrada is not None:
                    horas_do_mes = max(0, horas_atuais - horas_base_encontrada)
                    dados_resultado.at[index, 'horas_trabalhadas_mes'] = horas_do_mes
                    logger.debug(f"Projeto {numero_projeto}: {horas_atuais}h atual - {horas_base_encontrada}h base ({mes_base_encontrado}) = {horas_do_mes}h no m√™s")
                else:
                    # Projeto n√£o encontrado em nenhum m√™s anterior - pode ser novo
                    # Para ser conservador, considera apenas 10% das horas como do m√™s atual
                    horas_conservadoras = horas_atuais * 0.1
                    dados_resultado.at[index, 'horas_trabalhadas_mes'] = horas_conservadoras
                    logger.debug(f"Projeto {numero_projeto}: N√£o encontrado em meses anteriores, usando {horas_conservadoras}h conservadoras (10% de {horas_atuais}h)")
            
            total_horas_mes = dados_resultado['horas_trabalhadas_mes'].sum()
            logger.info(f"Total de horas trabalhadas especificamente no m√™s: {total_horas_mes:.1f}h")
            
            return dados_resultado
            
        except Exception as e:
            logger.error(f"Erro ao calcular horas trabalhadas no m√™s: {str(e)}", exc_info=True)
            dados['horas_trabalhadas_mes'] = dados.get('HorasTrabalhadas', 0)
            return dados

    def _enriquecer_projetos_com_historico(self, projetos, mes_referencia):
        """
        Tenta enriquecer os projetos com informa√ß√µes de arquivos hist√≥ricos
        para capturar nome do cliente e outras informa√ß√µes complementares.
        """
        try:
            # Lista de meses para buscar informa√ß√µes hist√≥ricas (√∫ltimos 6 meses)
            meses_busca = []
            mes_atual = mes_referencia
            
            for i in range(6):  # Busca nos √∫ltimos 6 meses
                if mes_atual.month == 1:
                    mes_anterior = mes_atual.replace(year=mes_atual.year - 1, month=12)
                else:
                    mes_anterior = mes_atual.replace(month=mes_atual.month - 1)
                
                fonte = self._obter_fonte_historica(mes_anterior.year, mes_anterior.month)
                if fonte:
                    meses_busca.append((mes_anterior, fonte))
                mes_atual = mes_anterior
            
            projetos_enriquecido = projetos.copy()
            projetos_enriquecido['nome_cliente_enriquecido'] = 'N/A'
            
            # Para cada projeto, busca informa√ß√µes hist√≥ricas
            for index, projeto in projetos.iterrows():
                numero_projeto = projeto.get('Numero')
                
                for mes_hist, fonte_hist in meses_busca:
                    try:
                        dados_hist = self.carregar_dados(fonte=fonte_hist)
                        
                        if not dados_hist.empty and numero_projeto in dados_hist['Numero'].values:
                            projeto_hist = dados_hist[dados_hist['Numero'] == numero_projeto].iloc[0]
                            
                            # Tenta extrair nome do cliente do hist√≥rico
                            nome_projeto_hist = projeto_hist.get('Projeto', '')
                            nome_cliente_encontrado = None
                            
                            # Primeira tentativa: projetos internos SOU.cloud
                            # Mais espec√≠fico para evitar falsos positivos
                            if nome_projeto_hist:
                                projeto_hist_upper = nome_projeto_hist.upper()
                                is_sou_internal_hist = (
                                    'COPILOT' in projeto_hist_upper or
                                    'SHAREPOINT' in projeto_hist_upper or 
                                    'REESTRUTURA' in projeto_hist_upper or
                                    'INTERNO' in projeto_hist_upper or
                                    'INTERNAL' in projeto_hist_upper or
                                    (projeto_hist_upper.startswith('SOU ') or projeto_hist_upper.endswith(' SOU') or projeto_hist_upper == 'SOU') or
                                    ('PMO' in projeto_hist_upper and 'SOU' in projeto_hist_upper) or
                                    ('CONTROL' in projeto_hist_upper and 'SOU' in projeto_hist_upper)
                                )
                                
                                if is_sou_internal_hist:
                                    nome_cliente_encontrado = 'SOU.cloud'
                                    logger.debug(f"Projeto interno SOU.cloud encontrado no hist√≥rico: {nome_projeto_hist}")
                            # Segunda tentativa: separador " - "
                            elif nome_projeto_hist and ' - ' in nome_projeto_hist:
                                partes = nome_projeto_hist.split(' - ', 1)
                                if len(partes) >= 2:
                                    nome_cliente_encontrado = partes[0].strip()
                            # Terceira tentativa: coluna Cliente diretamente
                            elif projeto_hist.get('Cliente'):
                                nome_cliente_encontrado = projeto_hist.get('Cliente').strip()
                            
                            if nome_cliente_encontrado:
                                projetos_enriquecido.at[index, 'nome_cliente_enriquecido'] = nome_cliente_encontrado
                                logger.debug(f"Cliente encontrado para projeto {numero_projeto}: {nome_cliente_encontrado}")
                                break  # Para de buscar se encontrou
                                    
                    except Exception as e:
                        logger.debug(f"Erro ao buscar dados hist√≥ricos em {fonte_hist}: {str(e)}")
                        continue
            
            return projetos_enriquecido
            
        except Exception as e:
            logger.error(f"Erro ao enriquecer projetos com hist√≥rico: {str(e)}", exc_info=True)
            projetos['nome_cliente_enriquecido'] = 'N/A'
            return projetos

    def _truncar_nome_cliente(self, nome_cliente):
        """
        Trunca nomes de clientes muito longos para as duas primeiras palavras
        """
        try:
            if not nome_cliente or nome_cliente == 'N/A':
                return nome_cliente
            
            palavras = nome_cliente.strip().split()
            if len(palavras) <= 2:
                return nome_cliente
            
            # Retorna apenas as duas primeiras palavras
            nome_truncado = ' '.join(palavras[:2])
            logger.debug(f"Nome do cliente truncado: '{nome_cliente}' -> '{nome_truncado}'")
            return nome_truncado
            
        except Exception as e:
            logger.debug(f"Erro ao truncar nome do cliente: {str(e)}")
            return nome_cliente

    def carregar_projetos_principais_selecionados(self, mes_referencia):
        """
        Carrega a lista de projetos principais selecionados manualmente para um m√™s
        """
        try:
            import json
            import os
            
            # Arquivo de configura√ß√£o baseado no m√™s
            config_dir = os.path.join('instance', 'config')
            os.makedirs(config_dir, exist_ok=True)
            
            mes_str = mes_referencia.strftime('%Y-%m')
            config_file = os.path.join(config_dir, f'projetos_principais_{mes_str}.json')
            
            logger.info(f"üîç CARREGAR: Procurando configura√ß√£o em: {config_file}")
            logger.info(f"üîç CARREGAR: Caminho absoluto: {os.path.abspath(config_file)}")
            logger.info(f"üîç CARREGAR: Arquivo existe: {os.path.exists(config_file)}")
            
            if os.path.exists(config_file):
                try:
                    logger.info(f"üìñ CARREGAR: Abrindo arquivo para leitura...")
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config_content = f.read()
                        logger.info(f"üìñ CARREGAR: Conte√∫do bruto lido: {config_content[:200]}...")
                        
                        config = json.loads(config_content)
                        logger.info(f"üìñ CARREGAR: JSON parseado: {config}")
                        
                        projetos_selecionados = config.get('projetos_selecionados', [])
                        logger.info(f"‚úÖ CARREGAR: {len(projetos_selecionados)} projetos extra√≠dos para {mes_str}: {projetos_selecionados}")
                        return projetos_selecionados
                        
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå CARREGAR: Erro JSON decode: {str(e)}")
                    return []
                except Exception as e:
                    logger.error(f"‚ùå CARREGAR: Erro ao ler arquivo: {str(e)}")
                    return []
            else:
                logger.info(f"üìÅ Nenhuma configura√ß√£o de projetos principais encontrada para {mes_str} em {config_file}")
                
                # Listar arquivos dispon√≠veis para debug
                try:
                    arquivos_disponiveis = os.listdir(config_dir)
                    logger.info(f"üìã Arquivos de configura√ß√£o dispon√≠veis: {arquivos_disponiveis}")
                except Exception as list_error:
                    logger.warning(f"Erro ao listar arquivos de configura√ß√£o: {str(list_error)}")
                
                return []
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar projetos principais selecionados: {str(e)}", exc_info=True)
            return []

    def salvar_projetos_principais_selecionados(self, projetos_selecionados, mes_referencia):
        """
        Salva a lista de projetos principais selecionados manualmente para um m√™s
        """
        try:
            import json
            import os
            from datetime import datetime
            
            # Arquivo de configura√ß√£o baseado no m√™s
            config_dir = os.path.join('instance', 'config')
            os.makedirs(config_dir, exist_ok=True)
            
            mes_str = mes_referencia.strftime('%Y-%m')
            config_file = os.path.join(config_dir, f'projetos_principais_{mes_str}.json')
            
            logger.info(f"üíæ Salvando {len(projetos_selecionados)} projetos para {mes_str}: {projetos_selecionados}")
            logger.info(f"üìÅ Arquivo de destino: {config_file}")
            
            config_data = {
                'mes_referencia': mes_str,
                'projetos_selecionados': projetos_selecionados,
                'data_configuracao': datetime.now().isoformat(),
                'total_selecionados': len(projetos_selecionados)
            }
            
            # Verificar se diret√≥rio existe
            if not os.path.exists(config_dir):
                logger.info(f"üìÅ Criando diret√≥rio: {config_dir}")
                os.makedirs(config_dir, exist_ok=True)
            
            # Salvar arquivo
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            # Verificar se arquivo foi criado
            if os.path.exists(config_file):
                file_size = os.path.getsize(config_file)
                logger.info(f"‚úÖ Arquivo salvo com sucesso: {config_file} ({file_size} bytes)")
                
                # Verificar conte√∫do
                with open(config_file, 'r', encoding='utf-8') as f:
                    saved_data = json.load(f)
                    logger.info(f"üîç Conte√∫do salvo: {saved_data}")
                
                return True
            else:
                logger.error(f"‚ùå Arquivo n√£o foi criado: {config_file}")
                return False
            
        except PermissionError as e:
            logger.error(f"‚ùå PERMISS√ÉO: Erro de permiss√£o ao salvar arquivo: {str(e)}")
            logger.error(f"‚ùå PERMISS√ÉO: Verifique se o processo tem permiss√£o para escrever em: {config_dir}")
            return False
        except IOError as e:
            logger.error(f"‚ùå IO: Erro de I/O ao salvar arquivo: {str(e)}")
            return False
        except Exception as e:
            logger.error(f"‚ùå GERAL: Erro ao salvar projetos principais selecionados: {str(e)}", exc_info=True)
            return False

    def _formatar_data_brasileira(self, data):
        """
        Formata data para o padr√£o brasileiro DD/MM/YYYY
        """
        try:
            if pd.isna(data) or not data:
                return 'N/A'
            
            # Se j√° √© string, tenta converter
            if isinstance(data, str):
                # Remove hor√°rio se presente
                data_clean = data.split(' ')[0]
                
                # Tenta diferentes formatos
                formatos = ['%Y-%m-%d', '%d/%m/%Y', '%m/%d/%Y', '%Y/%m/%d']
                
                for formato in formatos:
                    try:
                        data_obj = datetime.strptime(data_clean, formato)
                        return data_obj.strftime('%d/%m/%Y')
                    except ValueError:
                        continue
                        
                return data_clean  # Retorna original se n√£o conseguir converter
                
            # Se √© datetime
            elif hasattr(data, 'strftime'):
                return data.strftime('%d/%m/%Y')
                
            return str(data)
            
        except Exception as e:
            logger.debug(f"Erro ao formatar data {data}: {str(e)}")
            return 'N/A'

    def calcular_projetos_previstos_encerramento(self, dados, mes_referencia=None):
        """
        Projetos com vencimento no pr√≥ximo m√™s - VERS√ÉO CORRIGIDA
        """
        logger.info(f"‚úÖ Calculando projetos previstos para encerramento")
        
        try:
            # Define m√™s seguinte
            if mes_referencia is None:
                mes_referencia = datetime.now().replace(day=1)
            
            mes_seguinte = mes_referencia.replace(month=mes_referencia.month + 1) if mes_referencia.month < 12 else mes_referencia.replace(year=mes_referencia.year + 1, month=1)
            
            # Mapear m√™s para portugu√™s
            meses_pt = {
                1: 'Janeiro', 2: 'Fevereiro', 3: 'Mar√ßo', 4: 'Abril', 5: 'Maio', 6: 'Junho',
                7: 'Julho', 8: 'Agosto', 9: 'Setembro', 10: 'Outubro', 11: 'Novembro', 12: 'Dezembro'
            }
            
            mes_nome = meses_pt.get(mes_seguinte.month, str(mes_seguinte.month))
            mes_previsto = f"{mes_nome}/{mes_seguinte.year}"
            
            logger.info(f"‚úÖ Buscando projetos para: {mes_previsto}")
            
            # Prepara dados
            dados_work = dados.copy()
            
            # Converte datas
            dados_work['VencimentoEm_dt'] = pd.to_datetime(dados_work['VencimentoEm'], format='%d/%m/%Y %H:%M', errors='coerce')
            
            # Filtra projetos do m√™s seguinte
            inicio = datetime(mes_seguinte.year, mes_seguinte.month, 1)
            if mes_seguinte.month == 12:
                fim = datetime(mes_seguinte.year + 1, 1, 1) - pd.Timedelta(days=1)
            else:
                fim = datetime(mes_seguinte.year, mes_seguinte.month + 1, 1) - pd.Timedelta(days=1)
            
            projetos_mes = dados_work[
                (dados_work['VencimentoEm_dt'] >= inicio) &
                (dados_work['VencimentoEm_dt'] <= fim) &
                (dados_work['Status'] != 'CANCELADO')  # Exclui apenas cancelados
            ].copy()
            
            logger.info(f"‚úÖ Encontrados {len(projetos_mes)} projetos para {mes_previsto}")
            
            # Processa projetos
            projetos_lista = []
            for idx, projeto in projetos_mes.iterrows():
                nome_completo = projeto.get('Cliente (Completo)', 'N/A')
                squad = projeto.get('Servi√ßo (2¬∫ N√≠vel)', 'N/A')
                
                # Extrai nome do cliente (mais inteligente)
                if ' - ' in nome_completo:
                    cliente = nome_completo.split(' - ')[0].strip()
                elif len(nome_completo) > 25:
                    cliente = nome_completo[:22] + '...'
                else:
                    cliente = nome_completo
                
                projetos_lista.append({
                    'cliente': cliente,
                    'projeto': nome_completo,
                    'squad': squad
                })
            
            # Ordena por cliente
            projetos_lista.sort(key=lambda x: x['cliente'])
            
            resultado = {
                'projetos': projetos_lista,
                'mes_previsto': mes_previsto,
                'total_encontrados': len(projetos_lista),
                'periodo_analise': f"01/{mes_seguinte.month:02d} a {fim.day:02d}/{mes_seguinte.month:02d}/{mes_seguinte.year}"
            }
            
            logger.info(f"‚úÖ Retornando {len(projetos_lista)} projetos para {mes_previsto}")
            return resultado
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao calcular projetos previstos: {str(e)}")
            import traceback
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return {
                'projetos': [],
                'mes_previsto': 'Julho/2025',
                'total_encontrados': 0,
                'periodo_analise': '01/07 a 31/07/2025'
            }

    def analisar_mapeamento_tipos_servico(self, dados):
        """
        Analisa o mapeamento entre tipos de servi√ßo nos projetos vs CSV.
        Funcionalidade "DexPra" para identificar n√£o mapeados.
        
        Args:
            dados (pd.DataFrame): DataFrame com os projetos
            
        Returns:
            dict: An√°lise completa do mapeamento
        """
        try:
            from .typeservice_reader import type_service_reader
            
            logger.info("üîÑ Analisando mapeamento DexPra...")
            
            # Carrega mapeamento do CSV
            mapeamento_csv = type_service_reader.carregar_tipos_servico()
            if not mapeamento_csv:
                return {'erro': 'Erro ao carregar arquivo CSV', 'status': 'erro'}
            
            # Verifica coluna TipoServico nos dados
            if 'TipoServico' not in dados.columns:
                return {'erro': 'Coluna TipoServico n√£o encontrada', 'status': 'erro'}
            
            # Prepara dados
            dados_limpos = dados[dados['TipoServico'].notna() & (dados['TipoServico'] != '')].copy()
            if dados_limpos.empty:
                return {'erro': 'Nenhum projeto com tipo de servi√ßo v√°lido', 'status': 'erro'}
            
            # Fun√ß√£o auxiliar para normalizar strings
            def normalizar_string(s):
                """Normaliza string removendo espa√ßos extras, acentos e padronizando case"""
                if pd.isna(s) or s == '':
                    return ''
                import unicodedata
                # Remove acentos
                s = unicodedata.normalize('NFD', str(s)).encode('ascii', 'ignore').decode('ascii')
                # Remove espa√ßos extras e converte para lowercase
                return ' '.join(str(s).strip().lower().split())
            
            # Analisa tipos nos projetos
            tipos_projetos = dados_limpos['TipoServico'].value_counts().to_dict()
            
            # DEBUG: Log dos tipos encontrados nos projetos
            logger.info(f"üîç Tipos encontrados nos projetos ({len(tipos_projetos)}):")
            for tipo, qtd in list(tipos_projetos.items())[:5]:
                logger.info(f"  - '{tipo}' ({qtd} projetos)")
            
            # Fun√ß√£o auxiliar para normalizar strings
            def normalizar_string(s):
                """Normaliza string removendo espa√ßos extras, acentos e padronizando case"""
                if pd.isna(s) or s == '':
                    return ''
                import unicodedata
                # Remove acentos
                s = unicodedata.normalize('NFD', str(s)).encode('ascii', 'ignore').decode('ascii')
                # Remove espa√ßos extras e converte para lowercase
                return ' '.join(str(s).strip().lower().split())
            
            # DEBUG: Log dos tipos do CSV
            logger.info(f"üîç Tipos encontrados no CSV ({len(mapeamento_csv)}):")
            for tipo, categoria in list(mapeamento_csv.items())[:5]:
                logger.info(f"  - '{tipo}' -> '{categoria}'")
            
            # Cria mapeamento normalizado para compara√ß√£o
            csv_normalizado = {}
            for tipo_original, categoria in mapeamento_csv.items():
                tipo_norm = normalizar_string(tipo_original)
                if tipo_norm:  # S√≥ adiciona se n√£o estiver vazio ap√≥s normaliza√ß√£o
                    csv_normalizado[tipo_norm] = {
                        'original': tipo_original,
                        'categoria': categoria
                    }
            
            # DEBUG: Log dos tipos normalizados do CSV
            logger.info(f"üîç Tipos normalizados do CSV ({len(csv_normalizado)}):")
            for tipo_norm, info in list(csv_normalizado.items())[:5]:
                logger.info(f"  - '{tipo_norm}' -> '{info['categoria']}'")
            
            # Cria sets para an√°lise (usando vers√µes normalizadas)
            tipos_projetos_norm = {normalizar_string(tipo): tipo for tipo in tipos_projetos.keys()}
            tipos_csv_norm = set(csv_normalizado.keys())
            tipos_reais_norm = set(tipos_projetos_norm.keys())
            
            # Remove strings vazias
            tipos_csv_norm.discard('')
            tipos_reais_norm.discard('')
            
            # DEBUG: Verifica tipos espec√≠ficos problem√°ticos
            tipos_problema = ['Migra√ß√£o de tenant CSP para EA', 'Assessment for Rapid Migration']
            for tipo in tipos_problema:
                tipo_norm = normalizar_string(tipo)
                logger.info(f"üîç Verificando '{tipo}':")
                logger.info(f"  - Normalizado: '{tipo_norm}'")
                logger.info(f"  - No CSV normalizado: {tipo_norm in csv_normalizado}")
                logger.info(f"  - Nos projetos: {tipo in tipos_projetos}")
                
                # Procura por vers√µes similares nos projetos
                tipos_similares = [t for t in tipos_projetos.keys() if tipo.lower() in t.lower() or t.lower() in tipo.lower()]
                if tipos_similares:
                    logger.info(f"  - Tipos similares nos projetos: {tipos_similares}")
            
            # Identifica mapeamentos usando vers√µes normalizadas
            tipos_mapeados_norm = tipos_reais_norm.intersection(tipos_csv_norm)
            tipos_nao_mapeados_norm = tipos_reais_norm - tipos_csv_norm
            tipos_csv_nao_usados_norm = tipos_csv_norm - tipos_reais_norm
            
            # Constr√≥i listas detalhadas usando tipos originais
            nao_mapeados = []
            for tipo_norm in tipos_nao_mapeados_norm:
                tipo_original = tipos_projetos_norm[tipo_norm]
                qtd_projetos = tipos_projetos.get(tipo_original, 0)
                categoria_atual = type_service_reader.obter_categoria(tipo_original)  # Retorna "Outros"
                
                # Sugere a√ß√£o baseada no nome do tipo
                acao_sugerida = self._sugerir_acao_tipo(tipo_original)
                
                nao_mapeados.append({
                    'tipo': tipo_original,
                    'qtd_projetos': qtd_projetos,
                    'categoria_atual': categoria_atual,
                    'acao_sugerida': acao_sugerida
                })
            
            # Ordena por quantidade de projetos (mais cr√≠ticos primeiro)
            nao_mapeados.sort(key=lambda x: x['qtd_projetos'], reverse=True)
            
            mapeados = []
            for tipo_norm in tipos_mapeados_norm:
                tipo_original = tipos_projetos_norm[tipo_norm]
                qtd_projetos = tipos_projetos.get(tipo_original, 0)
                categoria = csv_normalizado[tipo_norm]['categoria']
                
                mapeados.append({
                    'tipo': tipo_original,
                    'qtd_projetos': qtd_projetos,
                    'categoria': categoria
                })
            
            mapeados.sort(key=lambda x: x['qtd_projetos'], reverse=True)
            
            csv_nao_usados = []
            for tipo_norm in tipos_csv_nao_usados_norm:
                info_csv = csv_normalizado[tipo_norm]
                tipo_original = info_csv['original']
                categoria = info_csv['categoria']
                
                csv_nao_usados.append({
                    'tipo': tipo_original,
                    'categoria': categoria,
                    'status': 'N√£o utilizado nos projetos atuais'
                })
            
            csv_nao_usados.sort(key=lambda x: x['tipo'])
            
            # Log para debug
            logger.info(f"üìä An√°lise normalizada:")
            logger.info(f"  - Tipos nos projetos: {len(tipos_reais_norm)}")
            logger.info(f"  - Tipos no CSV: {len(tipos_csv_norm)}")
            logger.info(f"  - Mapeados: {len(tipos_mapeados_norm)}")
            logger.info(f"  - N√£o mapeados: {len(tipos_nao_mapeados_norm)}")
            logger.info(f"  - CSV n√£o usados: {len(tipos_csv_nao_usados_norm)}")
            
            # Monta resultado
            resultado = {
                'nao_mapeados': nao_mapeados,
                'mapeados': mapeados,
                'csv_nao_usados': csv_nao_usados,
                'resumo': {
                    'total_tipos_projetos': len(tipos_reais_norm),
                    'total_tipos_csv': len(tipos_csv_norm),
                    'total_nao_mapeados': len(tipos_nao_mapeados_norm),
                    'total_mapeados': len(tipos_mapeados_norm),
                    'total_csv_nao_usados': len(tipos_csv_nao_usados_norm),
                    'percentual_mapeado': round((len(tipos_mapeados_norm) / len(tipos_reais_norm)) * 100, 1) if tipos_reais_norm else 0
                },
                'status': 'sucesso'
            }
            
            logger.info(f"‚úÖ Mapeamento analisado: {len(tipos_nao_mapeados_norm)} n√£o mapeados, {len(tipos_mapeados_norm)} mapeados")
            return resultado
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao analisar mapeamento: {str(e)}", exc_info=True)
            return {
                'erro': str(e),
                'status': 'erro'
            }

    def aplicar_filtros_relatorio(self, dados, filtros):
        """
        Aplica filtros avan√ßados nos dados do relat√≥rio geral.
        
        Args:
            dados (DataFrame): Dados a serem filtrados
            filtros (dict): Dicion√°rio com os filtros a aplicar
            
        Returns:
            DataFrame: Dados filtrados
        """
        try:
            logger.info(f"Aplicando filtros ao relat√≥rio: {filtros}")
            dados_filtrados = dados.copy()
            
            # Filtro por Categoria
            if 'categoria' in filtros and filtros['categoria']:
                try:
                    from .typeservice_reader import TypeServiceReader
                    reader = TypeServiceReader()
                    
                    # Obt√©m todos os tipos de servi√ßo da categoria selecionada
                    tipos_por_categoria = reader.obter_tipos_por_categoria()
                    tipos_da_categoria = tipos_por_categoria.get(filtros['categoria'], [])
                    
                    if tipos_da_categoria and 'TipoServico' in dados_filtrados.columns:
                        # Filtra projetos que t√™m tipos de servi√ßo pertencentes √† categoria
                        dados_filtrados = dados_filtrados[dados_filtrados['TipoServico'].isin(tipos_da_categoria)]
                        logger.info(f"Filtro Categoria aplicado: {filtros['categoria']} ({len(tipos_da_categoria)} tipos) - Registros restantes: {len(dados_filtrados)}")
                    else:
                        logger.warning(f"Categoria '{filtros['categoria']}' n√£o possui tipos de servi√ßo ou coluna TipoServico n√£o encontrada")
                except Exception as e:
                    logger.error(f"Erro ao aplicar filtro de categoria: {str(e)}")
            
            # Filtro por Squad
            if 'squad' in filtros and filtros['squad']:
                dados_filtrados = dados_filtrados[dados_filtrados['Squad'].str.upper() == filtros['squad'].upper()]
                logger.info(f"Filtro Squad aplicado: {filtros['squad']} - Registros restantes: {len(dados_filtrados)}")
            
            # Filtro por Servi√ßo
            if 'servico' in filtros and filtros['servico']:
                if 'TipoServico' in dados_filtrados.columns:
                    dados_filtrados = dados_filtrados[dados_filtrados['TipoServico'].str.upper() == filtros['servico'].upper()]
                    logger.info(f"Filtro Servi√ßo aplicado: {filtros['servico']} - Registros restantes: {len(dados_filtrados)}")
            
            # Filtro por Status
            if 'status' in filtros and filtros['status']:
                dados_filtrados = dados_filtrados[dados_filtrados['Status'].str.upper() == filtros['status'].upper()]
                logger.info(f"Filtro Status aplicado: {filtros['status']} - Registros restantes: {len(dados_filtrados)}")
            
            # Filtro por Faturamento
            if 'faturamento' in filtros and filtros['faturamento']:
                if 'Faturamento' in dados_filtrados.columns:
                    dados_filtrados = dados_filtrados[dados_filtrados['Faturamento'].str.upper() == filtros['faturamento'].upper()]
                    logger.info(f"Filtro Faturamento aplicado: {filtros['faturamento']} - Registros restantes: {len(dados_filtrados)}")
            
            # Filtros por Data de Abertura
            if 'data_abertura_inicio' in filtros and filtros['data_abertura_inicio']:
                try:
                    data_inicio = pd.to_datetime(filtros['data_abertura_inicio'])
                    if 'DataInicio' in dados_filtrados.columns:
                        dados_filtrados = dados_filtrados[pd.to_datetime(dados_filtrados['DataInicio']) >= data_inicio]
                        logger.info(f"Filtro Data Abertura In√≠cio aplicado: {filtros['data_abertura_inicio']} - Registros restantes: {len(dados_filtrados)}")
                except Exception as e:
                    logger.warning(f"Erro ao aplicar filtro de data de abertura in√≠cio: {e}")
            
            if 'data_abertura_fim' in filtros and filtros['data_abertura_fim']:
                try:
                    data_fim = pd.to_datetime(filtros['data_abertura_fim'])
                    if 'DataInicio' in dados_filtrados.columns:
                        dados_filtrados = dados_filtrados[pd.to_datetime(dados_filtrados['DataInicio']) <= data_fim]
                        logger.info(f"Filtro Data Abertura Fim aplicado: {filtros['data_abertura_fim']} - Registros restantes: {len(dados_filtrados)}")
                except Exception as e:
                    logger.warning(f"Erro ao aplicar filtro de data de abertura fim: {e}")
            
            # Filtros por Data de Fechamento
            if 'data_fechamento_inicio' in filtros and filtros['data_fechamento_inicio']:
                try:
                    data_inicio = pd.to_datetime(filtros['data_fechamento_inicio'])
                    if 'DataTermino' in dados_filtrados.columns:
                        # Filtra apenas projetos que foram fechados no per√≠odo
                        dados_fechados = dados_filtrados[dados_filtrados['Status'].str.upper().isin(['FECHADO', 'ENCERRADO', 'RESOLVIDO'])]
                        dados_fechados = dados_fechados[pd.to_datetime(dados_fechados['DataTermino']) >= data_inicio]
                        # Mant√©m tamb√©m projetos que n√£o foram fechados (DataTermino nula)
                        dados_nao_fechados = dados_filtrados[~dados_filtrados['Status'].str.upper().isin(['FECHADO', 'ENCERRADO', 'RESOLVIDO'])]
                        dados_filtrados = pd.concat([dados_fechados, dados_nao_fechados], ignore_index=True)
                        logger.info(f"Filtro Data Fechamento In√≠cio aplicado: {filtros['data_fechamento_inicio']} - Registros restantes: {len(dados_filtrados)}")
                except Exception as e:
                    logger.warning(f"Erro ao aplicar filtro de data de fechamento in√≠cio: {e}")
            
            if 'data_fechamento_fim' in filtros and filtros['data_fechamento_fim']:
                try:
                    data_fim = pd.to_datetime(filtros['data_fechamento_fim'])
                    if 'DataTermino' in dados_filtrados.columns:
                        # Filtra apenas projetos que foram fechados no per√≠odo
                        dados_fechados = dados_filtrados[dados_filtrados['Status'].str.upper().isin(['FECHADO', 'ENCERRADO', 'RESOLVIDO'])]
                        dados_fechados = dados_fechados[pd.to_datetime(dados_fechados['DataTermino']) <= data_fim]
                        # Mant√©m tamb√©m projetos que n√£o foram fechados (DataTermino nula)
                        dados_nao_fechados = dados_filtrados[~dados_filtrados['Status'].str.upper().isin(['FECHADO', 'ENCERRADO', 'RESOLVIDO'])]
                        dados_filtrados = pd.concat([dados_fechados, dados_nao_fechados], ignore_index=True)
                        logger.info(f"Filtro Data Fechamento Fim aplicado: {filtros['data_fechamento_fim']} - Registros restantes: {len(dados_filtrados)}")
                except Exception as e:
                    logger.warning(f"Erro ao aplicar filtro de data de fechamento fim: {e}")
            
            logger.info(f"Filtros aplicados com sucesso. Registros finais: {len(dados_filtrados)}")
            return dados_filtrados
            
        except Exception as e:
            logger.error(f"Erro ao aplicar filtros: {e}")
            return dados  # Retorna dados originais em caso de erro

    def _traduzir_categoria(self, categoria):
        """
        Traduz categorias do ingl√™s para portugu√™s.
        """
        traducoes = {
            'decision': 'Decis√£o',
            'impediment': 'Impedimento',
            'general': 'Geral',
            'risk': 'Risco',
            'meeting': 'Reuni√£o',
            'update': 'Atualiza√ß√£o'
        }
        return traducoes.get(categoria, categoria.title() if categoria else 'Geral')

    def _traduzir_prioridade(self, prioridade):
        """
        Traduz prioridades do ingl√™s para portugu√™s.
        """
        traducoes = {
            'high': 'Alta',
            'medium': 'M√©dia',
            'low': 'Baixa',
            'urgent': 'Urgente',
            'normal': 'Normal'
        }
        return traducoes.get(prioridade.lower() if prioridade else '', prioridade.title() if prioridade else 'Normal')

    def _calcular_percentual_por_tarefas(self, project_id):
        """
        Calcula o percentual de conclus√£o baseado nas tarefas do backlog.
        Usado especificamente para projetos de "Demandas Internas".
        """
        try:
            logger.info(f"Calculando percentual por tarefas para projeto {project_id}")
            
            # Buscar backlog_id do projeto
            backlog_id = self.get_backlog_id_for_project(project_id)
            if not backlog_id:
                logger.warning(f"Nenhum backlog encontrado para projeto {project_id}")
                return 0.0
            
            # Buscar todas as tarefas do backlog
            from app.models import Task, Column
            
            total_tarefas = Task.query.filter_by(backlog_id=backlog_id).count()
            logger.info(f"Total de tarefas no backlog {backlog_id}: {total_tarefas}")
            
            if total_tarefas == 0:
                logger.info("Nenhuma tarefa encontrada - retornando 0%")
                return 0.0
            
            # Contar tarefas conclu√≠das baseado no nome da coluna
            tarefas_concluidas = Task.query.filter_by(backlog_id=backlog_id)\
                .join(Column, Task.column_id == Column.id)\
                .filter(
                    Column.name.ilike('%conclu√≠%') |
                    Column.name.ilike('%concluido%') |
                    Column.name.ilike('%done%') |
                    Column.name.ilike('%finalizado%') |
                    Column.name.ilike('%finalizada%')
                ).count()
            
            logger.info(f"Tarefas conclu√≠das no backlog {backlog_id}: {tarefas_concluidas}")
            
            # Calcular percentual
            percentual = round((tarefas_concluidas / total_tarefas) * 100, 1)
            
            logger.info(f"Percentual calculado: {tarefas_concluidas}/{total_tarefas} = {percentual}%")
            
            return percentual
            
        except Exception as e:
            logger.error(f"Erro ao calcular percentual por tarefas para projeto {project_id}: {str(e)}")
            return 0.0

    def _calcular_esforco_por_tarefas(self, project_id):
        """
        Calcula o esfor√ßo total (horas planejadas) baseado nas tarefas do backlog.
        Usado especificamente para projetos de "Demandas Internas".
        """
        try:
            logger.info(f"Calculando esfor√ßo por tarefas para projeto {project_id}")
            
            # Buscar backlog_id do projeto
            backlog_id = self.get_backlog_id_for_project(project_id)
            if not backlog_id:
                logger.warning(f"Nenhum backlog encontrado para projeto {project_id}")
                return 0.0
            
            # Buscar todas as tarefas do backlog
            from app.models import Task
            
            all_tasks = Task.query.filter_by(backlog_id=backlog_id).all()
            
            if not all_tasks:
                logger.info(f"Nenhuma tarefa encontrada no backlog {backlog_id} - retornando 0h")
                return 0.0
            
            # Somar esfor√ßo estimado de todas as tarefas
            total_esforco = 0.0
            tarefas_com_esforco = 0
            
            for task in all_tasks:
                esforco_tarefa = float(task.estimated_effort or 0)
                total_esforco += esforco_tarefa
                if esforco_tarefa > 0:
                    tarefas_com_esforco += 1
                logger.debug(f"Tarefa '{task.title}' - Esfor√ßo: {esforco_tarefa}h")
            
            logger.info(f"Esfor√ßo total calculado: {total_esforco}h ({tarefas_com_esforco}/{len(all_tasks)} tarefas com esfor√ßo)")
            
            return total_esforco
            
        except Exception as e:
            logger.error(f"Erro ao calcular esfor√ßo por tarefas para projeto {project_id}: {str(e)}")
            return 0.0


# Fun√ß√µes auxiliares fora da classe
def normalize_status(status):
    """Normaliza o status para compara√ß√£o"""
    if pd.isna(status):
        return ''
    return str(status).strip().upper()

def map_status_concluido(status):
    """Mapeia diferentes varia√ß√µes de status conclu√≠do"""
    normalized = normalize_status(status)
    return normalized in ['CONCLU√çDO', 'CONCLUIDO', 'FINALIZADO', 'DONE', 'COMPLETED']

def format_status_frontend(status):
    """Formata o status para exibi√ß√£o no frontend"""
    if pd.isna(status):
        return 'N/A'
    return str(status).strip().title()
